<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">
      <meta name="description" content="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">
      <title>Using Big Data Spatial and Graph with Spatial Data</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="User’s Guide and Reference">
      <meta property="og:description" content="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="User’s Guide and Reference">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="oracle-big-data-spatial-and-graph-users-guide-and-reference.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2018-06-08T14:08:33-07:00">
      
      <meta name="dcterms.dateCopyrighted" content="2015, 2018">
      <meta name="dcterms.category" content="bigdata">
      <meta name="dcterms.identifier" content="E67958-15">
      
      <meta name="dcterms.product" content="en/bigdata/big-data-spatial-graph/2.5">
      
      <link rel="prev" href="big-data-spatial-overview.html" title="Previous" type="text/html">
      <link rel="next" href="integrating-big-data-spatial-graph-with-oracle-database.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"bigdata","element_name":"Big Data","display_in_url":true},"suite":{"short_name":"not-applicable","element_name":"Not Applicable","display_in_url":false},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"big-data-spatial-graph","element_name":"Big Data Spatial and Graph","display_in_url":true},"release":{"short_name":"2.5","element_name":"Release 2.5","display_in_url":true}}}</script>
      
    <meta name="dcterms.title" content="Oracle Big Data Spatial and Graph User's Guide and Reference">
    <meta name="dcterms.isVersionOf" content="BDSPA">
    <meta name="dcterms.release" content="Release 2.5">
  <script>window.ohcglobal || document.write('<script src="/en/dcommon/js/global.js">\x3C/script>')</script></head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="big-data-spatial-overview.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="integrating-big-data-spatial-graph-with-oracle-database.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">User’s Guide and Reference</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem">Using Big Data Spatial and Graph with Spatial Data</li>
            </ol>
            <a id="GUID-1FD11649-E864-4B55-BB24-8D405667E406" name="GUID-1FD11649-E864-4B55-BB24-8D405667E406"></a><a id="BDSPA122"></a>
            
            <h2 id="BDSPA-GUID-1FD11649-E864-4B55-BB24-8D405667E406" class="sect2"><span class="enumeration_chapter">2 </span>Using Big Data Spatial and Graph with Spatial Data
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.</p>
            </div>
            <div>
               <ul class="ullinks">
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14">About Big Data Spatial and Graph Support for Spatial Data</a><br>Oracle Big Data Spatial and Graph features enable spatial data to be stored, accessed, and analyzed quickly and efficiently for location-based decision making.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-2D124B6F-477B-465F-BFE5-5BEB7F0A0B39">Oracle Big Data Vector and Raster Data Processing</a><br>Oracle Big Data Spatial and Graph supports the storage and processing of both vector and raster spatial data.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D">Oracle Big Data Spatial Hadoop Image Processing Framework for Raster Data Processing</a><br>Oracle Spatial Hadoop Image Processing Framework allows the creation of new combined images resulting from a series of processing phases in parallel.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F">Loading an Image to Hadoop Using the Image Loader</a><br>The first step to process images using the Oracle Spatial and Graph Hadoop Image Processing Framework is to actually have the images in HDFS, followed by having the images separated into smart tiles.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a><br>Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-1520C09F-ED2A-44B7-8702-EB09B14AAD85">Loading and Processing an Image Using the Oracle Spatial Hadoop Raster Processing API</a><br>The framework provides a raster processing API that lets you load and process rasters without creating XML but instead using a Java application. The application can be executed inside the cluster or on a remote node.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A1D8D339-8D2A-4B18-BED8-89CE6C50F143">Using the Oracle Spatial Hadoop Raster Simulator Framework to Test Raster Processing</a><br>When you create custom processing classes. you can use the Oracle Spatial Hadoop Raster Simulator Framework to do the following by "pretending" to plug them into the Oracle Raster Processing Framework.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E">Oracle Big Data Spatial Raster Processing for Spark</a><br>Oracle Big Data Spatial Raster Processing for Apache Spark is a spatial raster processing API for Java.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3">Oracle Big Data Spatial Vector Analysis</a><br>Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00">Oracle Big Data Spatial Vector Analysis for Spark</a><br>Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2">Oracle Big Data Spatial Vector Hive Analysis</a><br>Oracle Big Data Spatial Vector Hive Analysis provides spatial functions to analyze the data using Hive.
                  </li>
                  <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6">Using the Oracle Big Data SpatialViewer Web Application</a><br>You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.
                  </li>
               </ul>
            </div>
            <a id="BDSPA123"></a><div class="props_rev_3"><a id="GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14" name="GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14"></a><h3 id="BDSPA-GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14" class="sect3"><span class="enumeration_section">2.1 </span>About Big Data Spatial and Graph Support for Spatial Data
               </h3>
               <div>
                  <p>Oracle Big Data Spatial and Graph features enable spatial data to be stored, accessed, and analyzed quickly and efficiently for location-based decision making.</p>
                  <p>Spatial data represents the location characteristics of real or conceptual objects in relation to the real or conceptual space on a Geographic Information System (GIS) or other location-based application.</p>
                  <p>The spatial features are used to geotag, enrich, visualize, transform, load, and process the location-specific two and three dimensional geographical images, and manipulate geometrical shapes for GIS functions.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-0A0989CB-F75F-42F1-8F34-B72BA175DB98">What is Big Data Spatial and Graph on Apache Hadoop?</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-82EADFCD-3FB9-48F4-8F88-7372EC1D86F8">Advantages of Oracle Big Data Spatial and Graph</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-77CAD07A-A2AA-4EF0-8C79-C89801819BEF">Oracle Big Data Spatial Features and Functions</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-34F9CE60-33BD-4D6D-81E4-C152A86BCBEB">Oracle Big Data Spatial Files, Formats, and Software Requirements</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               <a id="BDSPA124"></a><div class="props_rev_3"><a id="GUID-0A0989CB-F75F-42F1-8F34-B72BA175DB98" name="GUID-0A0989CB-F75F-42F1-8F34-B72BA175DB98"></a><h4 id="BDSPA-GUID-0A0989CB-F75F-42F1-8F34-B72BA175DB98" class="sect4"><span class="enumeration_section">2.1.1 </span>What is Big Data Spatial and Graph on Apache Hadoop?
                  </h4>
                  <div>
                     <p>Oracle Big Data Spatial and Graph on Apache Hadoop is a framework that uses the MapReduce programs and analytic capabilities in a Hadoop cluster to store, access, and analyze the spatial data. The spatial features provide a schema and functions that facilitate the storage, retrieval, update, and query of collections of spatial data. Big Data Spatial and Graph on Hadoop supports storing and processing spatial images, which could be geometric shapes, raster, or vector images and stored in one of the several hundred supported formats. </p>
                     <div class="infoboxnote" id="GUID-0A0989CB-F75F-42F1-8F34-B72BA175DB98__GUID-FFF4525A-0301-4F60-B672-A903256FA8B0">
                        <p class="notep1">Note:</p>
                        <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/bigdata/big-data-spatial-graph/2.5/bdspa&amp;id=SPATL010" target="_blank"><span class="italic">Oracle Spatial and Graph Developer's Guide</span></a> for an introduction to spatial concepts, data, and operations
                        </p>
                     </div>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14" title="Oracle Big Data Spatial and Graph features enable spatial data to be stored, accessed, and analyzed quickly and efficiently for location-based decision making.">About Big Data Spatial and Graph Support for Spatial Data</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA125"></a><div class="props_rev_3"><a id="GUID-82EADFCD-3FB9-48F4-8F88-7372EC1D86F8" name="GUID-82EADFCD-3FB9-48F4-8F88-7372EC1D86F8"></a><h4 id="BDSPA-GUID-82EADFCD-3FB9-48F4-8F88-7372EC1D86F8" class="sect4"><span class="enumeration_section">2.1.2 </span>Advantages of Oracle Big Data Spatial and Graph
                  </h4>
                  <div>
                     <p>The advantages of using Oracle Big Data Spatial and Graph include the following:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Unlike some of the GIS-centric spatial processing systems and engines, Oracle Big Data Spatial and Graph is capable of processing both structured and unstructured spatial information. </p>
                        </li>
                        <li>
                           <p>Customers are not forced or restricted to store only one particular form of data in their environment. They can have their data stored both as a spatial or nonspatial business data and still can use Oracle Big Data to do their spatial processing.</p>
                        </li>
                        <li>
                           <p>This is a framework, and therefore customers can use the available APIs to custom-build their applications or operations.</p>
                        </li>
                        <li>
                           <p>Oracle Big Data Spatial can process both vector and raster types of information and images.</p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14" title="Oracle Big Data Spatial and Graph features enable spatial data to be stored, accessed, and analyzed quickly and efficiently for location-based decision making.">About Big Data Spatial and Graph Support for Spatial Data</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA126"></a><div class="props_rev_3"><a id="GUID-77CAD07A-A2AA-4EF0-8C79-C89801819BEF" name="GUID-77CAD07A-A2AA-4EF0-8C79-C89801819BEF"></a><h4 id="BDSPA-GUID-77CAD07A-A2AA-4EF0-8C79-C89801819BEF" class="sect4"><span class="enumeration_section">2.1.3 </span>Oracle Big Data Spatial Features and Functions
                  </h4>
                  <div>
                     <p>The spatial data is loaded for query and analysis by the Spatial Server and the images are stored and processed by an Image Processing Framework. You can use the Oracle Big Data Spatial and Graph server on Hadoop for:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Cataloguing the geospatial information, such as geographical map-based footprints, availability of resources in a geography, and so on.</p>
                        </li>
                        <li>
                           <p>Topological processing to calculate distance operations, such as nearest neighbor in a map location.</p>
                        </li>
                        <li>
                           <p>Categorization to build hierarchical maps of geographies and enrich the map by creating demographic associations within the map elements.</p>
                        </li>
                     </ul>
                     <p>The following functions are built into Oracle Big Data Spatial and Graph:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Indexing function for faster retrieval of the spatial data.</p>
                        </li>
                        <li>
                           <p>Map function to display map-based footprints.</p>
                        </li>
                        <li>
                           <p>Zoom function to zoom-in and zoom-out specific geographical regions.</p>
                        </li>
                        <li>
                           <p>Mosaic and Group function to group a set of image files for processing to create a mosaic or subset operations.</p>
                        </li>
                        <li>
                           <p>Cartesian and geodetic coordinate functions to represent the spatial data in one of these coordinate systems.</p>
                        </li>
                        <li>
                           <p>Hierarchical function that builds and relates geometric hierarchy, such as country, state, city, postal code, and so on. This function can process the input data in the form of documents or latitude/longitude coordinates.</p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14" title="Oracle Big Data Spatial and Graph features enable spatial data to be stored, accessed, and analyzed quickly and efficiently for location-based decision making.">About Big Data Spatial and Graph Support for Spatial Data</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA127"></a><div class="props_rev_3"><a id="GUID-34F9CE60-33BD-4D6D-81E4-C152A86BCBEB" name="GUID-34F9CE60-33BD-4D6D-81E4-C152A86BCBEB"></a><h4 id="BDSPA-GUID-34F9CE60-33BD-4D6D-81E4-C152A86BCBEB" class="sect4"><span class="enumeration_section">2.1.4 </span>Oracle Big Data Spatial Files, Formats, and Software Requirements
                  </h4>
                  <div>
                     <p>The stored spatial data or images can be in one of these supported formats:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>GeoJSON files </p>
                        </li>
                        <li>
                           <p>Shapefiles</p>
                        </li>
                        <li>
                           <p>Both Geodetic and Cartesian data</p>
                        </li>
                        <li>
                           <p>Other GDAL supported formats</p>
                        </li>
                     </ul>
                     <p>You must have the following software, to store and process the spatial data:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Java runtime</p>
                        </li>
                        <li>
                           <p>GCC Compiler - Only when the GDAL-supported formats are used</p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-5576E9D6-E816-44F9-BACC-D705C0E19A14" title="Oracle Big Data Spatial and Graph features enable spatial data to be stored, accessed, and analyzed quickly and efficiently for location-based decision making.">About Big Data Spatial and Graph Support for Spatial Data</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="BDSPA128"></a><div class="props_rev_3"><a id="GUID-2D124B6F-477B-465F-BFE5-5BEB7F0A0B39" name="GUID-2D124B6F-477B-465F-BFE5-5BEB7F0A0B39"></a><h3 id="BDSPA-GUID-2D124B6F-477B-465F-BFE5-5BEB7F0A0B39" class="sect3"><span class="enumeration_section">2.2 </span>Oracle Big Data Vector and Raster Data Processing
               </h3>
               <div>
                  <p>Oracle Big Data Spatial and Graph supports the storage and processing of both vector and raster spatial data.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-1F406CBE-233C-4D92-A5A6-85993F21F39F">Oracle Big Data Spatial Raster Data Processing</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-FF0DD8E4-9097-4A80-B9A6-65496A029A63">Oracle Big Data Spatial Vector Data Processing</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               <a id="BDSPA129"></a><div class="props_rev_3"><a id="GUID-1F406CBE-233C-4D92-A5A6-85993F21F39F" name="GUID-1F406CBE-233C-4D92-A5A6-85993F21F39F"></a><h4 id="BDSPA-GUID-1F406CBE-233C-4D92-A5A6-85993F21F39F" class="sect4"><span class="enumeration_section">2.2.1 </span>Oracle Big Data Spatial Raster Data Processing
                  </h4>
                  <div>
                     <p>For processing the raster data, the GDAL loader loads the raster spatial data or images onto a HDFS environment. The following basic operations can be performed on a raster spatial data:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Mosaic: Combine multiple raster images to create a single mosaic image.</p>
                        </li>
                        <li>
                           <p>Subset: Perform subset operations on individual images.</p>
                        </li>
                        <li>
                           <p>Raster algebra operations: Perform algebra operations on every pixel in the rasters (for example, add, divide, multiply, log, pow, sine, sinh, and acos).</p>
                        </li>
                        <li>
                           <p>User-specified processing: Raster processing is based on the classes that user sets to be executed in mapping and reducing phases.</p>
                        </li>
                     </ul>
                     <p>This feature supports a MapReduce framework for raster analysis operations. The users have the ability to custom-build their own raster operations, such as performing an algebraic function on a raster data and so on. For example, calculate the slope at each base of a digital elevation model or a 3D representation of a spatial surface, such as a terrain. For details, see <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D" title="Oracle Spatial Hadoop Image Processing Framework allows the creation of new combined images resulting from a series of processing phases in parallel.">Oracle Big Data Spatial Hadoop Image Processing Framework for Raster Data Processing</a>.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-2D124B6F-477B-465F-BFE5-5BEB7F0A0B39" title="Oracle Big Data Spatial and Graph supports the storage and processing of both vector and raster spatial data.">Oracle Big Data Vector and Raster Data Processing</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA130"></a><div class="props_rev_3"><a id="GUID-FF0DD8E4-9097-4A80-B9A6-65496A029A63" name="GUID-FF0DD8E4-9097-4A80-B9A6-65496A029A63"></a><h4 id="BDSPA-GUID-FF0DD8E4-9097-4A80-B9A6-65496A029A63" class="sect4"><span class="enumeration_section">2.2.2 </span>Oracle Big Data Spatial Vector Data Processing
                  </h4>
                  <div>
                     <p>This feature supports the processing of spatial vector data:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Loaded and stored on to a Hadoop HDFS environment</p>
                        </li>
                        <li>
                           <p>Stored either as Cartesian or geodetic data</p>
                        </li>
                     </ul>
                     <p>The stored spatial vector data can be used for performing the following query operations and more:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Point-in-polygon</p>
                        </li>
                        <li>
                           <p>Distance calculation</p>
                        </li>
                        <li>
                           <p>Anyinteract </p>
                        </li>
                        <li>
                           <p>Buffer creation</p>
                        </li>
                     </ul>
                     <p>Sevetal data service operations are supported for the spatial vector data:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Data enrichment</p>
                        </li>
                        <li>
                           <p>Data categorization</p>
                        </li>
                        <li>
                           <p>Spatial join</p>
                        </li>
                     </ul>
                     <p>In addition, there is a limited Map Visualization API support for only the HTML5 format. You can access these APIs to create custom operations. For details, see <span class="q">"<a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a>."</span></p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-2D124B6F-477B-465F-BFE5-5BEB7F0A0B39" title="Oracle Big Data Spatial and Graph supports the storage and processing of both vector and raster spatial data.">Oracle Big Data Vector and Raster Data Processing</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="BDSPA131"></a><div class="props_rev_3"><a id="GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D" name="GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D"></a><h3 id="BDSPA-GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D" class="sect3"><span class="enumeration_section">2.3 </span>Oracle Big Data Spatial Hadoop Image Processing Framework for Raster Data Processing
               </h3>
               <div>
                  <p>Oracle Spatial Hadoop Image Processing Framework allows the creation of new combined images resulting from a series of processing phases in parallel.</p>
                  <p>It includes the following features:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>HDFS Images storage, where every block size split is stored as a separate tile, ready for future independent processing</p>
                     </li>
                     <li>
                        <p>Subset, user-defined, and map algebra operations processed in parallel using the MapReduce framework</p>
                     </li>
                     <li>
                        <p>Ability to add custom processing classes to be executed in the mapping or reducing phases in parallel in a transparent way</p>
                     </li>
                     <li>
                        <p>Fast processing of georeferenced images</p>
                     </li>
                     <li>
                        <p>Support for GDAL formats, multiple bands images, DEMs (digital elevation models), multiple pixel depths, and SRIDs</p>
                     </li>
                     <li>
                        <p>Java API providing access to framework operations; useful for web services or standalone Java applications</p>
                     </li>
                     <li>
                        <p>Framework for testing and debugging user processing classes in the local environment</p>
                     </li>
                  </ul>
                  <p>The Oracle Spatial Hadoop Image Processing Framework consists of two modules, a Loader and Processor, each one represented by a Hadoop job running on different stages in a Hadoop cluster, as represented in the following diagram. Also, you can load and process the images using the Image Server web application, and you can use the Java API to expose the framework’s capabilities.</p>
                  <div class="figure" id="GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D__GUID-9CE6A745-24A2-40D8-9591-E13B412577EE"><img src="img/image_process_framewrk.jpg" alt="Description of image_process_framewrk.jpg follows" title="Description of image_process_framewrk.jpg follows" longdesc="img_text/image_process_framewrk.html"><br><a href="img_text/image_process_framewrk.html">Description of the illustration image_process_framewrk.jpg</a></div>
                  <!-- class="figure" -->
                  <p>For installation and configuration information, see:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="big-data-spatial-overview.html#GUID-637F22DB-9327-41EC-8FD9-D6A523F14225" title="The Mammoth command-line utility for installing and configuring the Oracle Big Data Appliance software also installs the Oracle Big Data Spatial and Graph option, including the spatial, property graph, and multimedia capabilities.">Installing Oracle Big Data Spatial and Graph on an Oracle Big Data Appliance</a></p>
                     </li>
                     <li>
                        <p><a href="big-data-spatial-overview.html#GUID-9B24206D-3824-48A0-B5A9-7633930354EB" title="Installing and configuring the Image Processing Framework depends upon the distribution being used.">Installing and Configuring the Big Data Spatial Image Processing Framework</a></p>
                     </li>
                  </ul>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-BB29416A-858C-4188-A8FE-1666541BE24C">Image Loader</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-391CDE91-A138-4DAA-83C6-47D384C6A8FA">Image Processor</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               <a id="BDSPA133"></a><div class="props_rev_3"><a id="GUID-BB29416A-858C-4188-A8FE-1666541BE24C" name="GUID-BB29416A-858C-4188-A8FE-1666541BE24C"></a><h4 id="BDSPA-GUID-BB29416A-858C-4188-A8FE-1666541BE24C" class="sect4"><span class="enumeration_section">2.3.1 </span>Image Loader
                  </h4>
                  <div>
                     <p>The Image Loader is a Hadoop job that loads a specific image or a group of images into HDFS.</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>While importing, the image is tiled and stored as an HDFS block.</p>
                        </li>
                        <li>
                           <p>GDAL is used to tile the image.</p>
                        </li>
                        <li>
                           <p>Each tile is loaded by a different mapper, so reading is parallel and faster.</p>
                        </li>
                        <li>
                           <p>Each tile includes a certain number of overlapping bytes (user input), so that the tiles cover area from the adjacent tiles.</p>
                        </li>
                        <li>
                           <p>A MapReduce job uses a mapper to load the information for each tile. There are 'n' number of mappers, depending on the number of tiles, image resolution and block size.</p>
                        </li>
                        <li>
                           <p>A single reduce phase per image puts together all the information loaded by the mappers and stores the images into a special <code class="codeph">.ohif</code> format, which contains the resolution, bands, offsets, and image data. This way the file offset containing each tile and the node location is known.
                           </p>
                        </li>
                        <li>
                           <p>Each tile contains information for every band. This is helpful when there is a need to process only a few tiles; then, only the corresponding blocks are loaded.</p>
                        </li>
                     </ul>
                     <p>The following diagram represents an Image Loader process:</p>
                     <div class="figure" id="GUID-BB29416A-858C-4188-A8FE-1666541BE24C__GUID-35ACCE82-08ED-4D9A-831D-1562C0A63A7C"><img src="img/image_loader_job.png" height="426" width="468" alt="Description of image_loader_job.png follows" title="Description of image_loader_job.png follows" longdesc="img_text/image_loader_job.html"><br><a href="img_text/image_loader_job.html">Description of the illustration image_loader_job.png</a></div>
                     <!-- class="figure" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D" title="Oracle Spatial Hadoop Image Processing Framework allows the creation of new combined images resulting from a series of processing phases in parallel.">Oracle Big Data Spatial Hadoop Image Processing Framework for Raster Data Processing</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA134"></a><div class="props_rev_3"><a id="GUID-391CDE91-A138-4DAA-83C6-47D384C6A8FA" name="GUID-391CDE91-A138-4DAA-83C6-47D384C6A8FA"></a><h4 id="BDSPA-GUID-391CDE91-A138-4DAA-83C6-47D384C6A8FA" class="sect4"><span class="enumeration_section">2.3.2 </span>Image Processor
                  </h4>
                  <div>
                     <p>The Image Processor is a Hadoop job that filters tiles to be processed based on the user input and performs processing in parallel to create a new image. </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Processes specific tiles of the image identified by the user. You can identify one, zero, or multiple processing classes. These classes are executed in the mapping or reducing phase, depending on your configuration. For the mapping phase, after the execution of processing classes, a mosaic operation is performed to adapt the pixels to the final output format requested by the user. If no mosaic operation was requested, the input raster is sent to reduce phase as is. For reducer phase, all the tiles are put together into a GDAL data set that is input for user reduce processing class, where final output may be changed or analyzed according to user needs. </p>
                        </li>
                        <li>
                           <p>A mapper loads the data corresponding to one tile, conserving data locality. </p>
                        </li>
                        <li>
                           <p>Once the data is loaded, the mapper filters the bands requested by the user.</p>
                        </li>
                        <li>
                           <p>Filtered information is processed and sent to each mapper in the reduce phase, where bytes are put together and a final processed image is stored into HDFS or regular File System depending on the user request.</p>
                        </li>
                     </ul>
                     <p>The following diagram represents an Image Processor job: </p>
                     <div class="figure" id="GUID-391CDE91-A138-4DAA-83C6-47D384C6A8FA__GUID-528FA9FD-7B6E-4F23-91BD-41F61B1640B2"><img src="img/image_processor_job.png" height="468" width="501" alt="Description of image_processor_job.png follows" title="Description of image_processor_job.png follows" longdesc="img_text/image_processor_job.html"><br><a href="img_text/image_processor_job.html">Description of the illustration image_processor_job.png</a></div>
                     <!-- class="figure" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1CC83D21-4EFB-4647-AD73-D236A5A8F77D" title="Oracle Spatial Hadoop Image Processing Framework allows the creation of new combined images resulting from a series of processing phases in parallel.">Oracle Big Data Spatial Hadoop Image Processing Framework for Raster Data Processing</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="BDSPA136"></a><div class="props_rev_3"><a id="GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F" name="GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F"></a><h3 id="BDSPA-GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F" class="sect3"><span class="enumeration_section">2.4 </span>Loading an Image to Hadoop Using the Image Loader
               </h3>
               <div>
                  <p>The first step to process images using the Oracle Spatial and Graph Hadoop Image Processing Framework is to actually have the images in HDFS, followed by having the images separated into smart tiles.</p>
                  <p>This allows the processing job to work separately on each tile independently. The Image Loader lets you import a single image or a collection of them into HDFS in parallel, which decreases the load time.</p>
                  <p>The Image Loader imports images from a file system into HDFS, where each block contains data for all the bands of the image, so that if further processing is required on specific positions, the information can be processed on a single node.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A5DC7733-2F97-4D74-96B0-9E1F749B683E">Image Loading Job</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8287A93C-AE58-40C3-9C88-5BA6731B02C9">Input Parameters</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-17E1BAB7-AB93-49B6-91F0-63F05D1DA425">Output Parameters</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               <a id="BDSPA137"></a><div class="props_rev_3"><a id="GUID-A5DC7733-2F97-4D74-96B0-9E1F749B683E" name="GUID-A5DC7733-2F97-4D74-96B0-9E1F749B683E"></a><h4 id="BDSPA-GUID-A5DC7733-2F97-4D74-96B0-9E1F749B683E" class="sect4"><span class="enumeration_section">2.4.1 </span>Image Loading Job
                  </h4>
                  <div>
                     <p>The image loading job has its custom input format that splits the image into related image splits. The splits are calculated based on an algorithm that reads square blocks of the image covering a defined area, which is determined by</p>
                     <p>area = ((blockSize - metadata bytes) / number of bands) / bytes per pixel.</p>
                     <p>For those pieces that do not use the complete block size, the remaining bytes are refilled with zeros.</p>
                     <p>Splits are assigned to different mappers where every assigned tile is read using GDAL based on the <code class="codeph">ImageSplit</code> information. As a result an <code class="codeph">ImageDataWritable</code> instance is created and saved in the context.
                     </p>
                     <p>The metadata set in the <code class="codeph">ImageDataWritable</code> instance is used by the processing classes to set up the tiled image in order to manipulate and process it. Since the source images are read from multiple mappers, the load is performed in parallel and faster.
                     </p>
                     <p>After the mappers finish reading, the reducer picks up the tiles from the context and puts them together to save the file into HDFS. A special reading process is required to read the image back.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F" title="The first step to process images using the Oracle Spatial and Graph Hadoop Image Processing Framework is to actually have the images in HDFS, followed by having the images separated into smart tiles.">Loading an Image to Hadoop Using the Image Loader</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA138"></a><div class="props_rev_3"><a id="GUID-8287A93C-AE58-40C3-9C88-5BA6731B02C9" name="GUID-8287A93C-AE58-40C3-9C88-5BA6731B02C9"></a><h4 id="BDSPA-GUID-8287A93C-AE58-40C3-9C88-5BA6731B02C9" class="sect4"><span class="enumeration_section">2.4.2 </span>Input Parameters
                  </h4>
                  <div>
                     <p>The following input parameters are supplied to the Hadoop command: </p><pre class="oac_no_warn" dir="ltr">hadoop jar /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageloader.jar 
  -files &lt;SOURCE_IMGS_PATH&gt;
  -out &lt;HDFS_OUTPUT_FOLDER&gt;
  -gdal &lt;GDAL_LIB_PATH&gt;
  -gdalData &lt;GDAL_DATA_PATH&gt;
  [-overlap &lt;OVERLAPPING_PIXELS&gt;]
  [-thumbnail &lt;THUMBNAIL_PATH&gt;]
  [-expand &lt;false|true&gt;]
  [-extractLogs &lt;false|true&gt;]
  [-logFilter &lt;LINES_TO_INCLUDE_IN_LOG&gt;]
  [-pyramid &lt;OUTPUT_DIRECTORY, LEVEL, [RESAMPLING]&gt;]</pre><p>Where:</p>
                     <ul class="simple" style="list-style-type: none;padding-left:0;">
                        <li><code class="codeph">SOURCE_IMGS_PATH</code> is a path to the source image(s) or folder(s). For multiple inputs use a comma separator. This path must be accessible via NFS to all nodes in the cluster.
                        </li>
                        <li></li>
                        <li><code class="codeph">HDFS_OUTPUT_FOLDER</code> is the HDFS output folder where the loaded images are stored.
                        </li>
                        <li><code class="codeph">OVERLAPPING_PIXELS</code> is an optional number of overlapping pixels on the borders of each tile, if this parameter is not specified a default of two overlapping pixels is considered.
                        </li>
                        <li><code class="codeph">GDAL_LIB_PATH</code> is the path where GDAL libraries are located.
                        </li>
                        <li><code class="codeph">GDAL_DATA_PATH</code> is the path where GDAL data folder is located. This path must be accessible through NFS to all nodes in the cluster.
                        </li>
                        <li></li>
                        <li><code class="codeph">THUMBNAIL_PATH</code> is an optional path to store a thumbnail of the loaded image(s). This path must be accessible through NFS to all nodes in the cluster and must have write access permission for yarn users.
                        </li>
                        <li><code class="codeph">-expand</code> controls whether the HDFS path of the loaded raster expands the source path, including all directories. If you set this to <code class="codeph">false</code>, the <code class="codeph">.ohif</code> file is stored directly in the output directory (specified using the <code class="codeph">-o</code> option) without including that directory’s path in the raster.
                        </li>
                        <li><code class="codeph">-extractLogs</code> controls whether the logs of the executed application should be extracted to the system temporary directory. By default, it is not enabled. The extraction does not include logs that are not part of Oracle Framework classes.
                        </li>
                        <li><code class="codeph">-logFilter &lt;LINES_TO_INCLUDE_IN_LOG&gt;</code> is a comma-separated String that lists all the patterns to include in the extracted logs, for example, to include custom processing classes packages.
                        </li>
                        <li><code class="codeph">-pyramid &lt;OUTPUT_DIRECTORY, LEVEL, [RESAMPLING]&gt;</code> allows the creation of pyramids while making the initial raster load. An OUPUT_DIRECTORY must be provided to store the local pyramids before uploading to HDFS; pyramids are loaded in the same HDFSA directory requested for load. A pyramid LEVEL must be provided to indicate how many pyramids are required for each raster. A RESAMPLING algorithm is optional to specify the method used to execute the resampling; if none is set, then <code class="codeph">BILINEAR</code> is used.
                        </li>
                     </ul>
                     <p>For example, the following command loads all the georeferenced images under the <code class="codeph">images</code> folder and adds an overlapping of 10 pixels on every border possible. The HDFS output folder is <code class="codeph">ohiftest</code> and thumbnail of the loaded image are stored in the <code class="codeph">processtest</code> folder.
                     </p><pre class="oac_no_warn" dir="ltr">hadoop jar /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageloader.jar   -files /opt/shareddir/spatial/demo/imageserver/images/hawaii.tif -out ohiftest -overlap 10 -thumbnail /opt/shareddir/spatial/processtest &#x2013;gdal /opt/oracle/oracle-spatial-graph/spatial/raster/gdal/lib &#x2013;gdalData /opt/shareddir/data</pre><p>By default, the Mappers and Reducers are configured to get 2 GB of JVM, but users can override this settings or any other job configuration properties by adding an <code class="codeph">imagejob.prop</code> properties file in the same folder location from where the command is being executed. This properties file may list all the configuration properties that you want to override. For example, 
                     </p><pre class="oac_no_warn" dir="ltr">mapreduce.map.memory.mb=2560
mapreduce.reduce.memory.mb=2560
mapreduce.reduce.java.opts=-Xmx2684354560
mapreduce.map.java.opts=-Xmx2684354560</pre><p>Java heap memory (<code class="codeph">java.opts</code> properties) must be equal to or less than the total memory assigned to mappers and reducers (<code class="codeph">mapreduce.map.memory</code> and <code class="codeph">mapreduce.reduce.memory</code>). Thus, if you increase Java heap memory, you might also need to increase the memory for mappers and reducers.
                     </p>
                     <p>For GDAL to work properly, the libraries must be available using $LD_LIBRARY_PATH. Make sure that the shared libraries path is set properly in your shell window before executing a job. For example:</p><pre class="oac_no_warn" dir="ltr">export LD_LIBRARY_PATH=$ALLACCESSDIR/gdal/native</pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F" title="The first step to process images using the Oracle Spatial and Graph Hadoop Image Processing Framework is to actually have the images in HDFS, followed by having the images separated into smart tiles.">Loading an Image to Hadoop Using the Image Loader</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA139"></a><div class="props_rev_3"><a id="GUID-17E1BAB7-AB93-49B6-91F0-63F05D1DA425" name="GUID-17E1BAB7-AB93-49B6-91F0-63F05D1DA425"></a><h4 id="BDSPA-GUID-17E1BAB7-AB93-49B6-91F0-63F05D1DA425" class="sect4"><span class="enumeration_section">2.4.3 </span>Output Parameters
                  </h4>
                  <div>
                     <p>The reducer generates two output files per input image. The first one is the <code class="codeph">.ohif</code> file that concentrates all the tiles for the source image, each tile may be processed as a separated instance by a processing mapper. Internally each tile is stored as a HDFS block, blocks are located in several nodes, one node may contain one or more blocks of a specific <code class="codeph">.ohif</code> file. The <code class="codeph">.ohif</code> file is stored in user specified folder with -out flag, under the <code class="codeph">/user/&lt;USER_EXECUTING_JOB&gt;/OUT_FOLDER/&lt;PARENT_DIRECTORIES_OF_SOURCE_RASTER&gt;</code> if the flag <code class="codeph">&#x2013;expand</code> was not used. Otherwise, the <code class="codeph">.ohif</code> file will be located at <code class="codeph">/user/&lt;USER_EXECUTING_JOB&gt;/OUT_FOLDER/</code>, and the file can be identified as <code class="codeph">original_filename.ohif</code>.
                     </p>
                     <p>The second output is a related metadata file that lists all the pieces of the image and the coordinates that each one covers. The file is located in HDFS under the metadata location, and its name is hash generated using the name of the <code class="codeph">ohif</code> file. This file is for Oracle internal use only, and lists important metadata of the source raster. Some example lines from a metadata file:
                     </p><pre class="oac_no_warn" dir="ltr">srid:26904
datatype:1
resolution:27.90809458890406,-27.90809458890406
file:/user/hdfs/ohiftest/opt/shareddir/spatial/data/rasters/hawaii.tif.ohif
bands:3
mbr:532488.7648166901,4303164.583549625,582723.3350767174,4269619.053853762
0,532488.7648166901,4303164.583549625,582723.3350767174,4269619.053853762
thumbnailpath:/opt/shareddir/spatial/thumb/
</pre><p>If the <code class="codeph">-thumbnail</code> flag was specified, a thumbnail of the source image is stored in the related folder. This is a way to visualize a translation of the <code class="codeph">.ohif</code> file. Job execution logs can be accessed using the command <code class="codeph">yarn logs -applicationId &lt;applicationId&gt;</code>.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-7B3432E6-F79A-4B4C-AC0B-68304510C35F" title="The first step to process images using the Oracle Spatial and Graph Hadoop Image Processing Framework is to actually have the images in HDFS, followed by having the images separated into smart tiles.">Loading an Image to Hadoop Using the Image Loader</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="BDSPA140"></a><div class="props_rev_3"><a id="GUID-C379D151-8346-4038-A3F1-A10772506B7A" name="GUID-C379D151-8346-4038-A3F1-A10772506B7A"></a><h3 id="BDSPA-GUID-C379D151-8346-4038-A3F1-A10772506B7A" class="sect3"><span class="enumeration_section">2.5 </span>Processing an Image Using the Oracle Spatial Hadoop Image Processor
               </h3>
               <div>
                  <p>Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.</p>
                  <p>You specify an output, and the framework filters the tiles to fit into that output, processes them, and puts them all together to store them into a single file. Map algebra operations are also available and, if set, will be the first part of the processing phase. You can specify additional processing classes to be executed before the final output is created by the framework.</p>
                  <p>The image processor loads specific blocks of data, based on the input (mosaic description or a single raster), and selects only the bands and pixels that fit into the final output. All the specified processing classes are executed and the final output is stored into HDFS or the file system depending on the user request.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-FB7EDF2E-F164-4B14-AF79-C926FCC09806">Image Processing Job</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-CCD6ED9E-F2D4-4A49-A1E4-EBE4001E1446">Input Parameters</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-3716E38C-EEAF-4C6C-B7EC-84EA93C365F7">Job Execution</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-4E10F374-9382-4E3B-8F02-DC22F5AF2A8C">Processing Classes and ImageBandWritable</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-2B9F7E81-4FAD-435F-A266-3101AD9E3668">Map Algebra Operations</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-E418EC48-426C-423F-B2A5-3AB3A6D5556C">Multiple Raster Algebra Operations</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C21FD285-0AF7-48A7-B0FF-64581D27CC4E">Pyramids</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-10E840FE-0EA9-492D-B1E1-44E4F0C059C1">Output</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               <a id="BDSPA141"></a><div class="props_rev_3"><a id="GUID-FB7EDF2E-F164-4B14-AF79-C926FCC09806" name="GUID-FB7EDF2E-F164-4B14-AF79-C926FCC09806"></a><h4 id="BDSPA-GUID-FB7EDF2E-F164-4B14-AF79-C926FCC09806" class="sect4"><span class="enumeration_section">2.5.1 </span>Image Processing Job
                  </h4>
                  <div>
                     <p>The image processing job has different flows depending on the type of processing requested by the user. </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A320569B-0E86-4103-BCCF-48E79345EC5B">Default Image Processing Job Flow</a>: executed for processing that includes a mosaic operation, single raster operation, or basic multiple raster operation.
                           </p>
                        </li>
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-3D23657B-A703-4A6B-BA8C-7FDBAC9BF3AF">Multiple Raster Image Processing Job Flow</a>: executed for processing that includes complex multiple raster algebra operations.
                           </p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A320569B-0E86-4103-BCCF-48E79345EC5B">Default Image Processing Job Flow</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-3D23657B-A703-4A6B-BA8C-7FDBAC9BF3AF">Multiple Raster Image Processing Job Flow</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-A320569B-0E86-4103-BCCF-48E79345EC5B" name="GUID-A320569B-0E86-4103-BCCF-48E79345EC5B"></a><h5 id="BDSPA-GUID-A320569B-0E86-4103-BCCF-48E79345EC5B" class="sect5"><span class="enumeration_section">2.5.1.1 </span>Default Image Processing Job Flow
                     </h5>
                     <div>
                        <p>The default image processing job flow is executed when any of the following processing is requested:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Mosaic operation</p>
                           </li>
                           <li>
                              <p>Single raster operation</p>
                           </li>
                           <li>
                              <p>Basic multiple raster algebra operation</p>
                           </li>
                        </ul>
                        <p>The flow has its own custom <code class="codeph">FilterInputFormat</code>, which determines the tiles to be processed, based on the SRID and coordinates. Only images with same data type (pixel depth) as the mosaic input data type (pixel depth) are considered. Only the tiles that intersect with coordinates specified by the user for the mosaic output are included. For processing of a single raster or basic multiple raster algebra operation (excluding mosaic), the filter includes all the tiles of the input rasters, because the processing will be executed on the complete images. Once the tiles are selected, a custom <code class="codeph">ImageProcessSplit</code> is created for each image.
                        </p>
                        <p>When a mapper receives the <code class="codeph">ImageProcessSplit</code>, it reads the information based on what the <code class="codeph">ImageSplit</code> specifies, performs a filter to select only the bands indicated by the user, and executes the list of map operations and of processing classes defined in the request, if any.
                        </p>
                        <p>Each mapper process runs in the node where the data is located. After the map algebra operations and processing classes are executed, a validation verifies if the user is requesting mosaic operation or if analysis includes the complete image; and if a mosaic operation is requested, the final process executes the operation. The mosaic operation selects from every tile only the pixels that fit into the output and makes the necessary resolution changes to add them in the mosaic output. The single process operation just copies the previous raster tile bytes as they are. The resulting bytes are stored in NFS to be recovered by the reducer.</p>
                        <p>A single reducer picks the tiles and puts them together. If you specified any basic multiple raster algebra operation, then it is executed at the same time the tiles are merged into the final output. This operation affects only the intersecting pixels in the mosaic output, or in every pixel if no mosaic operation was requested. If you specified a reducer processing class, the GDAL data set with the output raster is sent to this class for analysis and processing. If you selected HDFS output, the <code class="codeph">ImageLoader</code> is called to store the result into HDFS. Otherwise, by default the image is prepared using GDAL and is stored in the file system (NFS).
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-FB7EDF2E-F164-4B14-AF79-C926FCC09806">Image Processing Job</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-3D23657B-A703-4A6B-BA8C-7FDBAC9BF3AF" name="GUID-3D23657B-A703-4A6B-BA8C-7FDBAC9BF3AF"></a><h5 id="BDSPA-GUID-3D23657B-A703-4A6B-BA8C-7FDBAC9BF3AF" class="sect5"><span class="enumeration_section">2.5.1.2 </span>Multiple Raster Image Processing Job Flow
                     </h5>
                     <div>
                        <p>The multiple raster image processing job flow is executed when a complex multiple raster algebra operation is requested. It applies to rasters that have the same MBR, pixel type, pixel size, and SRID, since these operations are applied pixel by pixel in the corresponding cell, where every pixel represents the same coordinates.</p>
                        <p>The flow has its own custom <code class="codeph">MultipleRasterInputFormat</code>, which determines the tiles to be processed, based on the SRID and coordinates. Only images with same MBR, pixel type, pixel size and SRID are considered. Only the rasters that match with coordinates specified by the first raster in the catalog are included. All the tiles of the input rasters are considered, because the processing will be executed on the complete images.
                        </p>
                        <p>Once the tiles are selected, a custom <code class="codeph">MultipleRasterSplit</code> is created. This split contains a small area of every original tile, depending on the block size, because now all the rasters must be included in a split, even if it is only a small area. Each of these is called an <code class="codeph">IndividualRasterSplit</code>, and they are contained in a parent <code class="codeph">MultipleRasterSplit</code>.
                        </p>
                        <p>When a mapper receives the <code class="codeph">MultipleRasterSplit</code>, it reads the information of all the raster´s tiles that are included in the parent split, performs a filter to select only the bands indicated by the user and only the small corresponding area to process in this specific mapper, and then executes the complex multiple raster algebra operation.
                        </p>
                        <p>Data locality may be lost in this part of the process, because multiple rasters are included for a single mapper that may not be in the same node. The resulting bytes for every pixel are put in the context to be recovered by the reducer.</p>
                        <p>A single reducer picks pixel values and puts them together. If you specified a reducer processing class, the GDAL data set with the output raster is sent to this class for analysis and processing. The list of tiles that this class receives is null for this scenario, and the class can only work with the output data set. If you selected HDFS output, the <code class="codeph">ImageLoader</code> is called to store the result into HDFS. Otherwise, by default the image is prepared using GDAL and is stored in the file system (NFS).
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-FB7EDF2E-F164-4B14-AF79-C926FCC09806">Image Processing Job</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="BDSPA142"></a><div class="props_rev_3"><a id="GUID-CCD6ED9E-F2D4-4A49-A1E4-EBE4001E1446" name="GUID-CCD6ED9E-F2D4-4A49-A1E4-EBE4001E1446"></a><h4 id="BDSPA-GUID-CCD6ED9E-F2D4-4A49-A1E4-EBE4001E1446" class="sect4"><span class="enumeration_section">2.5.2 </span>Input Parameters
                  </h4>
                  <div>
                     <p>The following input parameters can be supplied to the hadoop command: </p><pre class="oac_no_warn" dir="ltr">hadoop jar /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageprocessor.jar 
  -config  &lt;MOSAIC_CONFIG_PATH&gt;
  -gdal  &lt;GDAL_LIBRARIES_PATH&gt;
  -gdalData  &lt;GDAL_DATA_PATH&gt;
  [-catalog  &lt;IMAGE_CATALOG_PATH&gt;]
  [-usrlib  &lt;USER_PROCESS_JAR_PATH&gt;]
  [-thumbnail  &lt;THUMBNAIL_PATH&gt;]
  [-nativepath  &lt;USER_NATIVE_LIBRARIES_PATH&gt;]
  [-params  &lt;USER_PARAMETERS&gt;]
  [-file  &lt;SINGLE_RASTER_PATH&gt;]
</pre><p>Where:</p>
                     <ul class="simple" style="list-style-type: none;padding-left:0;">
                        <li><code class="codeph">MOSAIC_CONFIG_PATH</code> is the path to the mosaic configuration xml, that defines the features of the output.
                        </li>
                        <li><code class="codeph">GDAL_LIBRARIES_PATH</code> is the path where GDAL libraries are located.
                        </li>
                        <li><code class="codeph">GDAL_DATA_PATH</code> is the path where the GDAL data folder is located. This path must be accessible via NFS to all nodes in the cluster.
                        </li>
                        <li><code class="codeph">IMAGE_CATALOG_PATH</code> is the path to the catalog xml that lists the HDFS image(s) to be processed. This is optional because you can also specify a single raster to process using <code class="codeph">&#x2013;file</code> flag.
                        </li>
                        <li><code class="codeph">USER_PROCESS_JAR_PATH</code> is an optional user-defined jar file or comma-separated list of jar files, each of which contains additional processing classes to be applied to the source images.
                        </li>
                        <li><code class="codeph">THUMBNAIL_PATH</code> is an optional flag to activate the thumbnail creation of the loaded image(s). This path must be accessible via NFS to all nodes in the cluster and is valid only for an HDFS output.
                        </li>
                        <li><code class="codeph">USER_NATIVE_LIBRARIES_PATH</code> is an optional comma-separated list of additional native libraries to use in the analysis. It can also be a directory containing all the native libraries to load in the application.
                        </li>
                        <li><code class="codeph">USER_PARAMETERS</code> is an optional key/value list used to define input data for user processing classes. Use a semicolon to separate parameters. For example: <code class="codeph">azimuth=315;altitude=45</code></li>
                        <li><code class="codeph">SINGLE_RASTER_PATH</code> is an optional path to the <code class="codeph">.ohif</code> file that will be processed by the job. If this is set, you do not need to set a catalog.
                        </li>
                     </ul>
                     <p>For example, the following command will process all the files listed in the catalog file <code class="codeph">input.xml</code> file using the mosaic output definition set in <code class="codeph">testFS.xml</code> file.
                     </p><pre class="oac_no_warn" dir="ltr">hadoop jar /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageprocessor.jar -catalog /opt/shareddir/spatial/demo/imageserver/images/input.xml -config /opt/shareddir/spatial/demo/imageserver/images/testFS.xml -thumbnail /opt/shareddir/spatial/processtest &#x2013;gdal /opt/oracle/oracle-spatial-graph/spatial/raster/gdal/lib &#x2013;gdalData /opt/shareddir/data</pre><p>By default, the Mappers and Reducers are configured to get 2 GB of JVM, but users can override this settings or any other job configuration properties by adding an <code class="codeph">imagejob.prop</code> properties file in the same folder location from where the command is being executed.
                     </p>
                     <p>For GDAL to work properly, the libraries must be available using $LD_LIBRARY_PATH. Make sure that the shared libraries path is set properly in your shell window before executing a job. For example:</p><pre class="oac_no_warn" dir="ltr">export LD_LIBRARY_PATH=$ALLACCESSDIR/gdal/native</pre></div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-D2A73A45-A5CA-4492-B121-2F6384CD7BA2">Catalog XML Structure</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-9C3066FD-1152-47F4-A2E9-0518E6B7BE4F">Mosaic Definition XML Structure</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA143"></a><div class="props_rev_3"><a id="GUID-D2A73A45-A5CA-4492-B121-2F6384CD7BA2" name="GUID-D2A73A45-A5CA-4492-B121-2F6384CD7BA2"></a><h5 id="BDSPA-GUID-D2A73A45-A5CA-4492-B121-2F6384CD7BA2" class="sect5"><span class="enumeration_section">2.5.2.1 </span>Catalog XML Structure
                     </h5>
                     <div>
                        <p>The following is an example of input catalog XML used to list every source image considered for mosaic operation generated by the image processing job.</p><pre class="oac_no_warn" dir="ltr">-&lt;catalog&gt;
  -&lt;image&gt;
&lt;raster&gt;/user/hdfs/ohiftest/opt/shareddir/spatial/data/rasters/maui.tif.ohif&lt;/raster&gt;
&lt;bands datatype='1' config='1,2,3'&gt;3&lt;/bands&gt;
   &lt;/image&gt;
&lt;/catalog&gt;
</pre><p>A <code class="codeph">&lt;catalog&gt;</code> element contains the list of &lt;image&gt; elements to process.
                        </p>
                        <p>Each <code class="codeph">&lt;image&gt;</code> element defines a source image or a source folder within the &lt;raster&gt; element. All the images within the folder are processed.
                        </p>
                        <p>The <code class="codeph">&lt;bands&gt;</code> element specifies the number of bands of the image,  The <code class="codeph">datatype</code> attribute has the raster data type and the <code class="codeph">config</code> attribute specifies which band should appear in the mosaic output band order. For example: 3,1,2 specifies that mosaic output band number 1 will have band number 3 of this raster, mosaic band number 2 will have source band 1, and mosaic band number 3 will have source band 2. This order may change from raster to raster.
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-CCD6ED9E-F2D4-4A49-A1E4-EBE4001E1446">Input Parameters</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="BDSPA144"></a><div class="props_rev_3"><a id="GUID-9C3066FD-1152-47F4-A2E9-0518E6B7BE4F" name="GUID-9C3066FD-1152-47F4-A2E9-0518E6B7BE4F"></a><h5 id="BDSPA-GUID-9C3066FD-1152-47F4-A2E9-0518E6B7BE4F" class="sect5"><span class="enumeration_section">2.5.2.2 </span>Mosaic Definition XML Structure
                     </h5>
                     <div>
                        <p>The following is an example of a mosaic configuration XML used to define the features of the output generated by the image processing job.</p><pre class="oac_no_warn" dir="ltr">-&lt;mosaic exec="false"&gt;
  -&lt;output&gt;
   &lt;SRID&gt;26904&lt;/SRID&gt;
   &lt;directory type="FS"&gt;/opt/shareddir/spatial/processOutput&lt;/directory&gt;
   &lt;!--directory type="HDFS"&gt;newData&lt;/directory--&gt;
   &lt;tempFSFolder&gt;/opt/shareddir/spatial/tempOutput&lt;/tempFSFolder&gt;
   &lt;filename&gt;littlemap&lt;/filename&gt;
   &lt;format&gt;GTIFF&lt;/format&gt;
  &lt;width&gt;1600&lt;/width&gt;
  &lt;height&gt;986&lt;/height&gt;
  &lt;algorithm order="0"&gt;2&lt;/algorithm&gt;
  &lt;bands layers="3" config="3,1,2"/&gt;
  &lt;nodata&gt;#000000&lt;/nodata&gt;
  &lt;pixelType&gt;1&lt;/pixelType&gt;
  &lt;/output&gt;
  -&lt;crop&gt;
   -&lt;transform&gt;
    356958.985610072,280.38843650364862,0,2458324.0825054757,0,-280.38843650364862 &lt;/transform&gt;
  &lt;/crop&gt;
&lt;process&gt;&lt;classMapper params="threshold=454,2954"&gt;oracle.spatial.hadoop.twc.FarmTransformer&lt;/classMapper&gt;&lt;classReducer params="plot_size=100400"&gt;oracle.spatial.hadoop.twc.FarmAlignment&lt;/classReducer&gt;&lt;/process&gt;
   &lt;operations&gt;
        &lt;localif operator="&lt;" operand="3" newvalue="6"/&gt;
                   &lt;localadd arg="5"/&gt;
                   &lt;localsqrt/&gt;
                   &lt;localround/&gt;
   &lt;/operations&gt;
&lt;/mosaic&gt;
</pre><p>The <code class="codeph">&lt;mosaic&gt;</code> element defines the specifications of the processing output. The <code class="codeph">exec</code> attribute specifies if the processing will include mosaic operation or not. If set to <code class="codeph">“false”</code>, a mosaic operation is not executed and a single raster is processed; if set to <code class="codeph">“true”</code> or not set, a mosaic operation is performed. Some of the following elements are required only for mosaic operations and ignored for single raster processing.
                        </p>
                        <p>The <code class="codeph">&lt;output&gt;</code> element defines the features such as &lt;SRID&gt; considered for the output. All the images in different SRID are converted to the mosaic SRID in order to decide if any of its tiles fit into the mosaic or not. This element is not required for single raster processing, because the output rster has the same SRID as the input.
                        </p>
                        <p>The <code class="codeph">&lt;directory&gt;</code> element defines where the output is located. It can be in an HDFS or in regular FileSystem (FS), which is specified in the tag type.
                        </p>
                        <p>The <code class="codeph">&lt;tempFsFolder&gt;</code> element sets the path to store the mosaic output temporarily. The attribute <code class="codeph">delete=”false”</code> can be specified to keep the output of the process even if the loader was executed to store it in HDFS.
                        </p>
                        <p>The <code class="codeph">&lt;filename&gt;</code> and <code class="codeph">&lt;format&gt;</code> elements specify the output filename. <code class="codeph">&lt;filename&gt;</code> is not required for single raster process; and if it is not specified, the name of the input file (determined by the <code class="codeph">-file</code> attribute during the job call) is used for the output file. <code class="codeph">&lt;format&gt;</code> is not required for single raster processing, because the output raster has the same format as the input.
                        </p>
                        <p>The <code class="codeph">&lt;width&gt;</code> and <code class="codeph">&lt;height&gt;</code> elements set the mosaic output resolution. They are not required for single raster processing, because the output raster has the same resolution as the input.
                        </p>
                        <p>The <code class="codeph">&lt;algorithm&gt;</code> element sets the order algorithm for the images. A 1 order means, by source last modified date, and a 2 order means, by image size. The order tag represents ascendant or descendant modes. (These properties are for mosaic operations where multiple rasters may overlap.)
                        </p>
                        <p>The <code class="codeph">&lt;bands&gt;</code> element specifies the number of bands in the output mosaic. Images with fewer bands than this number are discarded. The <code class="codeph">config</code> attribute can be used for single raster processing to set the band configuration for output, because there is no catalog.
                        </p>
                        <p>The <code class="codeph">&lt;nodata&gt;</code> element specifies the color in the first three bands for all the pixels in the mosaic output that have no value.
                        </p>
                        <p>The <code class="codeph">&lt;pixelType&gt;</code> element sets the pixel type of the mosaic output. Source images that do not have the same pixel size are discarded for processing. This element is not required for single raster processing: if not specified, the pixel type will be the same as for the input.
                        </p>
                        <p>The <code class="codeph">&lt;crop&gt;</code> element defines the coordinates included in the mosaic output in the following order: <code class="codeph">startcoordinateX</code>, <code class="codeph">pixelXWidth</code>, <code class="codeph">RotationX</code>, <code class="codeph">startcoordinateY</code>, <code class="codeph">RotationY</code>, and <code class="codeph">pixelheightY</code>. This element is not required for single raster processing: if not specified, the complete image is considered for analysis.
                        </p>
                        <p>The <code class="codeph">&lt;process&gt;</code> element lists all the classes to execute before the mosaic operation. 
                        </p>
                        <p>The <code class="codeph">&lt;classMapper&gt;</code> element is used for classes that will be executed during mapping phase, and the <code class="codeph">&lt;classReducer&gt;</code> element is used for classes that will be executed during reduce phase. Both elements have the <code class="codeph">params</code> attribute, where you can send input parameters to processing classes according to your needs.
                        </p>
                        <p>The <code class="codeph">&lt;operations&gt;</code> element lists all the map algebra operations that will be processed for this request. This element can also include a request for pyramid operations; for example:
                        </p><pre class="pre codeblock"><code>&lt;operations&gt;
	&lt;pyramid resampling="NEAREST_NEIGHBOR" redLevel="6"/&gt;
&lt;/operations&gt;
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-CCD6ED9E-F2D4-4A49-A1E4-EBE4001E1446">Input Parameters</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="BDSPA145"></a><div class="props_rev_3"><a id="GUID-3716E38C-EEAF-4C6C-B7EC-84EA93C365F7" name="GUID-3716E38C-EEAF-4C6C-B7EC-84EA93C365F7"></a><h4 id="BDSPA-GUID-3716E38C-EEAF-4C6C-B7EC-84EA93C365F7" class="sect4"><span class="enumeration_section">2.5.3 </span>Job Execution
                  </h4>
                  <div>
                     <p>The first step of the job is to filter the tiles that would fit into the output. As a start, the location files that hold tile metadata are sent to the<code class="codeph">InputFormat</code>.
                     </p>
                     <p>By extracting the <code class="codeph">pixelType</code>, the filter decides whether the related source image is valid for processing or not. Based on the user definition made in the catalog xml, one of the following happens: 
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>If the image is valid for processing, then the SRID is evaluated next</p>
                        </li>
                        <li>
                           <p>If it is different from the user definition, then the MBR coordinates of every tile are converted into the user SRID and evaluated.</p>
                        </li>
                     </ul>
                     <p>This way, every tile is evaluated for intersection with the output definition.</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>For a mosaic processing request, only the intersecting tiles are selected, and a split is created for each one of them.</p>
                        </li>
                        <li>
                           <p>For a single raster processing request, all the tiles are selected, and a split is created for each one of them.</p>
                        </li>
                        <li>
                           <p>For a complex multiple raster algebra processing request, all the tiles are selected if the MBR and pixel size is the same. Depending on the number of rasters selected and the blocksize, a specific area of every tile´s raster (which does not always include the complete original raster tile) is included in a single parent split.</p>
                        </li>
                     </ul>
                     <p>A mapper processes each split in the node where it is stored. (For complex multiple raster algebra operations, data locality may be lost, because a split contains data from several rasters.) The mapper executes the sequence of map algebra operations and processing classes defined by the user, and then the mosaic process is executed if requested. A single reducer puts together the result of the mappers and, for user-specified reducing processing classes, sets the output data set to these classes for analysis or process. Finally, the process stores the image into FS or HDFS upon user request. If the user requested to store the output into HDFS, then the <code class="codeph">ImageLoader</code> job is invoked to store the image as an <code class="codeph">.ohif</code> file.
                     </p>
                     <p>By default, the mappers and reducers are configured to get 1 GB of JVM, but you can override this settings or any other job configuration properties by adding an <code class="codeph">imagejob.prop</code> properties file in the same folder location from where the command is being executed.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA147"></a><a id="BDSPA148"></a><a id="BDSPA146"></a><div class="props_rev_3"><a id="GUID-4E10F374-9382-4E3B-8F02-DC22F5AF2A8C" name="GUID-4E10F374-9382-4E3B-8F02-DC22F5AF2A8C"></a><h4 id="BDSPA-GUID-4E10F374-9382-4E3B-8F02-DC22F5AF2A8C" class="sect4"><span class="enumeration_section">2.5.4 </span>Processing Classes and ImageBandWritable
                  </h4>
                  <div>
                     <p>The processing classes specified in the catalog XML must follow a set of rules to be correctly processed by the job. All the processing classes in the mapping phase must implement the <code class="codeph">ImageProcessorInterface</code> interface. For the reducer phase, they must implement the <code class="codeph">ImageProcessorReduceInterface</code> interface.
                     </p>
                     <p>When implementing a processing class, you may manipulate the raster using its object representation <code class="codeph">ImageBandWritable</code>. An example of an processing class is provided with the framework to calculate the slope on DEMs. You can create mapping operations, for example, to transforms the pixel values to another value by a function. The <code class="codeph">ImageBandWritable</code> instance defines the content of a tile, such as resolution, size, and pixels. These values must be reflected in the properties that create the definition of the tile. The integrity of the mosaic output depends on the correct manipulation of these properties.
                     </p>
                     <p>The <code class="codeph">ImageBandWritable</code> instance defines the content of a tile, such as resolution, size, and pixels. These values must be reflected in the properties that create the definition of the tile. The integrity of the output depends on the correct manipulation of these properties.
                     </p>
                     <div class="tblformal" id="GUID-4E10F374-9382-4E3B-8F02-DC22F5AF2A8C__GUID-8432639D-E278-43E7-9058-6F29CBEC51CD">
                        <p class="titleintable">Table 2-1 ImageBandWritable Properties</p>
                        <table cellpadding="4" cellspacing="0" class="Formal" title="ImageBandWritable Properties" summary="ImageBandWritable properties" width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="31%" id="d8066e2435">Type - Property</th>
                                 <th align="left" valign="bottom" width="69%" id="d8066e2438">Description</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2443" headers="d8066e2435 ">
                                    <p>IntWritable dstWidthSize</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2443 d8066e2438 ">
                                    <p>Width size of the tile</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2450" headers="d8066e2435 ">
                                    <p>IntWritable dstHeightSize</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2450 d8066e2438 ">
                                    <p>Height size of the tile</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2457" headers="d8066e2435 ">
                                    <p>IntWritable bands</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2457 d8066e2438 ">
                                    <p>Number of bands in the tile</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2464" headers="d8066e2435 ">
                                    <p>IntWritable dType</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2464 d8066e2438 ">
                                    <p>Data type of the tile</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2471" headers="d8066e2435 ">
                                    <p>IntWritable offX</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2471 d8066e2438 ">
                                    <p>Starting X pixel, in relation to the source image</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2478" headers="d8066e2435 ">
                                    <p> IntWritable offY</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2478 d8066e2438 ">
                                    <p>Starting Y pixel, in relation to the source image</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2485" headers="d8066e2435 ">
                                    <p>IntWritable totalWidth</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2485 d8066e2438 ">
                                    <p>Width size of the source image</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2492" headers="d8066e2435 ">
                                    <p>IntWritable totalHeight</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2492 d8066e2438 ">
                                    <p>Height size of the source image</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2499" headers="d8066e2435 ">
                                    <p>IntWritable bytesNumber</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2499 d8066e2438 ">
                                    <p>Number of bytes containing the pixels of the tile and stored into baseArray</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2506" headers="d8066e2435 ">
                                    <p>BytesWritable[] baseArray</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2506 d8066e2438 ">
                                    <p>Array containing the bytes representing the tile pixels, each cell represents a band</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2513" headers="d8066e2435 ">
                                    <p>IntWritable[][] basePaletteArray</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2513 d8066e2438 ">
                                    <p>Array containing the int values representing the tile palette, each array represents a band. Each integer represents an entry for each color in the color table, there are four entries per color</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2521" headers="d8066e2435 ">
                                    <p>IntWritable[] baseColorArray</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2521 d8066e2438 ">
                                    <p>Array containing the int values representing the color interpretation, each cell represents a band</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2528" headers="d8066e2435 ">
                                    <p>DoubleWritable[] noDataArray</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2528 d8066e2438 ">
                                    <p>Array containing the NODATA values for the image, each cell contains the value for the related band</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2535" headers="d8066e2435 ">
                                    <p>ByteWritable isProjection</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2535 d8066e2438 ">
                                    <p>Specifies if the tile has projection information with Byte.MAX_VALUE</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2542" headers="d8066e2435 ">
                                    <p>ByteWritable isTransform</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2542 d8066e2438 ">
                                    <p>Specifies if the tile has the geo transform array information with Byte.MAX_VALUE</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2549" headers="d8066e2435 ">
                                    <p>ByteWritable isMetadata</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2549 d8066e2438 ">
                                    <p>Specifies if the tile has metadata information with Byte.MAX_VALUE</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2556" headers="d8066e2435 ">
                                    <p>IntWritable projectionLength </p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2556 d8066e2438 ">
                                    <p>Specifies the projection information length</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2563" headers="d8066e2435 ">
                                    <p>BytesWritable projectionRef </p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2563 d8066e2438 ">
                                    <p>Specifies the projection information in bytes</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2570" headers="d8066e2435 ">
                                    <p>DoubleWritable[] geoTransform</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2570 d8066e2438 ">
                                    <p>Contains the geo transform array</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2577" headers="d8066e2435 ">
                                    <p>IntWritable metadataSize</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2577 d8066e2438 ">
                                    <p>Number of metadata values in the tile</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2584" headers="d8066e2435 ">
                                    <p>IntWritable[] metadataLength</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2584 d8066e2438 ">
                                    <p>Array specifying the length of each metadataValue</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2591" headers="d8066e2435 ">
                                    <p>BytesWritable[] metadata</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2591 d8066e2438 ">
                                    <p>Array of metadata of the tile</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2599" headers="d8066e2435 ">
                                    <p>GeneralInfoWritable mosaicInfo</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2599 d8066e2438 ">
                                    <p>The user-defined information in the mosaic xml. Do not modify the mosaic output features. Modify the original xml file in a new name and run the process using the new xml</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d8066e2606" headers="d8066e2435 ">
                                    <p>MapWritable extraFields</p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d8066e2606 d8066e2438 ">
                                    <p>Map that lists key/value pairs of parameters specific to every tile to be passed to the reducer phase for analysis</p>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                     <div class="section">
                        <p class="subhead3">Processing Classes and Methods</p>
                     </div>
                     <!-- class="section" -->
                     <div class="section">
                        <p>When modifying the pixels of the tile, first get the band information into an array using the following method:</p>
                        <p><code class="codeph">byte [] bandData1 =(byte []) img.getBand(0);</code></p>
                        <p>The bytes representing the tile pixels of band 1 are now in the bandData1 array. The base index is zero.</p>
                        <p>The <code class="codeph">getBand(int bandId)</code> method will get the band of the raster in the specified <code class="codeph">bandId</code> position. You can cast the object retrieved to the type of array of the raster; it could be byte, short (unsigned int 16 bits, int 16 bits), int (unsigned int 32 bits, int 32 bits), float (float 32 bits), or double (float 64 bits).
                        </p>
                        <p>With the array of pixels available, it is possible now to transform them upon a user request.</p>
                        <p>After processing the pixels, if the same instance of ImageBandWritable must be used, then execute the following method:</p>
                        <p><code class="codeph">img.removeBands;</code></p>
                        <p>This removes the content of previous bands, and you can start adding the new bands. To add a new band use the following method:</p>
                        <p><code class="codeph">img.addBand(Object band);</code></p>
                        <p>Otherwise, you may want to replace a specific band by using trhe following method:</p>
                        <p><code class="codeph">img.replaceBand(Object band, int bandId)</code></p>
                        <p>In the preceding methods, <code class="codeph">band</code> is an array containing the pixel information, and <code class="codeph">bandID</code> is the identifier of the band to be replaced.. Do not forget to update the instance size, data type, bytesNumber and any other property that might be affected as a result of the processing operation. Setters are available for each property.
                        </p>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-1C873204-5716-4ED5-8585-54DFF69E778E">Location of the Classes and Jar Files</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA149"></a><div class="props_rev_3"><a id="GUID-1C873204-5716-4ED5-8585-54DFF69E778E" name="GUID-1C873204-5716-4ED5-8585-54DFF69E778E"></a><h5 id="BDSPA-GUID-1C873204-5716-4ED5-8585-54DFF69E778E" class="sect5"><span class="enumeration_section">2.5.4.1 </span>Location of the Classes and Jar Files
                     </h5>
                     <div>
                        <p>All the processing classes must be contained in a single jar file if you are using the Oracle Image Server Console. The processing classes might be placed in different jar files if you are using the command line option.</p>
                        <p>When new classes are visible in the classpath, they must be added to the mosaic XML in the <code class="codeph">&lt;process&gt;&lt;classMapper&gt;</code> or <code class="codeph">&lt;process&gt;&lt;classReducer&gt;</code> section. Every <code class="codeph">&lt;class&gt;</code> element added is executed in order of appearance: for mappers, just before the final mosaic operation is performed; and for reducers, just after all the processed tiles are put together in a single data set.
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-4E10F374-9382-4E3B-8F02-DC22F5AF2A8C">Processing Classes and ImageBandWritable</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-2B9F7E81-4FAD-435F-A266-3101AD9E3668" name="GUID-2B9F7E81-4FAD-435F-A266-3101AD9E3668"></a><h4 id="BDSPA-GUID-2B9F7E81-4FAD-435F-A266-3101AD9E3668" class="sect4"><span class="enumeration_section">2.5.5 </span>Map Algebra Operations
                  </h4>
                  <div>
                     <p>You can process local map algebra operations on the input rasters, where pixels are altered depending on the operation. The order of operations in the configuration XML determines the order in which the operations are processed. After all the map algebra operations are processed, the processing classes are run, and finally the mosaic operation is performed.</p>
                     <p>The following map algebra operations can be added in the <code class="codeph">&lt;operations&gt;</code> element in the mosaic configuration XML, with the operation name serving as an element name. (The data types for which each operation is supported are listed in parentheses.)
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">localnot</code>: Gets the negation of every pixel, inverts the bit pattern. If the result is a negative value and the data type is unsigned, then the NODATA value is set. If the raster does not have a specified NODATA value, then the original pixel is set. (Byte, Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">locallog</code>: Returns the natural logarithm (base <span class="italic">e</span>) of a pixel. If the result is NaN, then original pixel value is set; if the result is Infinite, then the NODATA value is set. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">locallog10</code>: Returns the base 10 logarithm of a pixel. If the result is NaN, then the original pixel value is set; if the result is Infinite, then the NODATA value is set. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localadd</code>: Adds the specified value as argument to the pixel .Example: <code class="codeph">&lt;localadd arg="5"/&gt;</code>. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localdivide</code>: Divides the value of each pixel by the specified value set as argument. Example: <code class="codeph">&lt;localdivide arg="5"/&gt;</code>. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localif</code>: Modifies the value of each pixel based on the condition and value specified as argument. Valid operators:   = , &lt;, &gt;, &gt;=, &lt; !=. Example:: <code class="codeph">&lt;localif operator="&lt;" operand="3" newvalue="6"/&gt;</code>, which modifies all the pixels whose value is less than 3, setting the new value to 6. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localmultiply</code>: Multiplies the value of each pixel times the value specified as argument. Example: <code class="codeph">&lt;localmultiply arg="5"/&gt;</code>. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localpow</code>: Raises the value of each pixel to the power of the value specified as argument. Example:  <code class="codeph">&lt;localpow arg="5"/&gt;</code>. If the result is infinite, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localsqrt</code>: Returns the correctly rounded positive square root of every pixel. If the result is infinite or NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localsubstract</code>: Subtracts the value specified as argument to every pixel value. Example: <code class="codeph">&lt;localsubstract arg="5"/&gt;</code>. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localacos</code>: Calculates the arc cosine of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localasin</code>: Calculates the arc sine of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localatan</code>: Calculates the arc tangent of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localcos</code>: Calculates the cosine of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localcosh</code>: Calculates the hyperbolic cosine of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localsin</code>: Calculates the sine of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localtan</code>: Calculates the tangent of a pixel. The pixel is not modified if the cosine of this pixel is 0. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localsinh</code>: Calculates the arc hyperbolic sine of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localtanh</code>: Calculates the hyperbolic tangent of a pixel. If the result is NaN, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localdefined</code>:    Maps an integer typed pixel to 1 if the cell value is not NODATA; otherwise, 0. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits, Float 32 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localundefined</code>:    Maps an integer typed Raster to 0 if the cell value is not NODATA; otherwise, 1. (Unsigned int 16 bits, Unsigned int 32 bits, Int 16 bits, Int 32 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localabs</code>: Returns the absolute value of signed pixel. If the result is Infinite, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localnegate</code>: Multiplies by -1 the value of each pixel. (Int 16 bits, Int 32 bits, Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localceil</code>: Returns the smallest value that is greater than or equal to the pixel value and is equal to a mathematical integer. If the result is Infinite, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localfloor</code>: Returns the smallest value that is less than or equal to the pixel value and is equal to a mathematical integer. If the result is Infinite, the NODATA value is set to this pixel. If the raster does not have a specified NODATA value, then the original pixel is set. (Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">localround</code>: Returns the closest integer value to every pixel. (Float 32 bits, Float 64 bits)
                           </p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-E418EC48-426C-423F-B2A5-3AB3A6D5556C" name="GUID-E418EC48-426C-423F-B2A5-3AB3A6D5556C"></a><h4 id="BDSPA-GUID-E418EC48-426C-423F-B2A5-3AB3A6D5556C" class="sect4"><span class="enumeration_section">2.5.6 </span>Multiple Raster Algebra Operations
                  </h4>
                  <div>
                     <p>You can process raster algebra operations that involve more than one raster, where pixels are altered depending on the operation and taking in consideration the pixels from all the involved rasters in the same cell. </p>
                     <p>Only one operation can be processed at a time and it is defined in the configuration XML using the <code class="codeph">&lt;multipleops&gt;</code> element. Its value is the operation to process. 
                     </p>
                     <p>There are two types of operations:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C7F38E35-D1FF-4D7B-A1AE-6ABA919F8757">Basic Multiple Raster Algebra Operations</a> are executed in the reduce phase right before the Reduce User Processing classes. 
                           </p>
                        </li>
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-6730C3A4-C932-41A9-BACE-F35FD3F8CF52">Complex Multiple Raster Algebra Operations</a> are processed in the mapping phase.
                           </p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C7F38E35-D1FF-4D7B-A1AE-6ABA919F8757">Basic Multiple Raster Algebra Operations</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-6730C3A4-C932-41A9-BACE-F35FD3F8CF52">Complex Multiple Raster Algebra Operations</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-C7F38E35-D1FF-4D7B-A1AE-6ABA919F8757" name="GUID-C7F38E35-D1FF-4D7B-A1AE-6ABA919F8757"></a><h5 id="BDSPA-GUID-C7F38E35-D1FF-4D7B-A1AE-6ABA919F8757" class="sect5"><span class="enumeration_section">2.5.6.1 </span>Basic Multiple Raster Algebra Operations
                     </h5>
                     <div>
                        <p>Basic multiple raster algebra operations are executed in the reducing phase of the job.</p>
                        <p>They can be requested along with a mosaic operation or just a process request. If requested along with a mosaic operation, the input rasters must have the same MBR, pixel size, SRID and data type.</p>
                        <p>When a mosaic operation is performed, only the intersecting pixels (pixels that are identical in both rasters) are affected.</p>
                        <p>The operation is processed at the time that mapping tiles are put together in the output dataset, the pixel values that intersect (if a mosaic operation was requested) or all the pixels (when mosaic is not requested) are altered according to the requested operation. </p>
                        <p>The order in which rasters are added to the data set is the mosaic operation order if it was requested; otherwise, it is the order of appearance in the catalog.</p>
                        <p>The following basic multiple raster algebra operations are available: </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">add</code>: Adds every pixel in the same cell for the raster sequence. 
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">substract</code>: Subtracts every pixel in the same cell for the raster sequence.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">divide</code>: Divides every pixel in the same cell for the raster sequence.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">multiply</code>: Multiplies every pixel in the same cell for the raster sequence.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">min</code>: Assigns the minimum value of the pixels in the same cell for the raster sequence. 
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">max</code>: Assigns the maximum value of the pixels in the same cell for the raster sequence.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">mean</code>: Calculates the mean value for every pixel in the same cell for the raster sequence. 
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">and</code>: Processes binary “and” operation on every pixel in the same cell for raster sequence, “and“ operation copies a bit to the result if it exists in both operands.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">or</code>: Processes binary “or” operation on every pixel in the same cell for raster sequence, “or” operation copies a bit if it exists in either operand.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">xor</code>: Processes binary “xor” operation on every pixel in the same cell for raster sequence, “xor” operation copies the bit if it is set in one operand but not both.
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E418EC48-426C-423F-B2A5-3AB3A6D5556C">Multiple Raster Algebra Operations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-6730C3A4-C932-41A9-BACE-F35FD3F8CF52" name="GUID-6730C3A4-C932-41A9-BACE-F35FD3F8CF52"></a><h5 id="BDSPA-GUID-6730C3A4-C932-41A9-BACE-F35FD3F8CF52" class="sect5"><span class="enumeration_section">2.5.6.2 </span>Complex Multiple Raster Algebra Operations
                     </h5>
                     <div>
                        <p>Complex multiple raster algebra operations are executed in the mapping phase of the job, and a job can only process this operation; any request for resizing, changing the SRID, or custom mapping must have been previously executed. The input for this job is a series of rasters with the same MBR, SRID, data type, and pixel size.</p>
                        <p>The tiles for this job include a piece of all the rasters in the catalog. Thus, every mapper has access to an area of cells in all the rasters, and the operation is processed there. The resulting pixel for every cell is written in the context, so that reducer can put results in the output data set before processing the reducer processing classes.</p>
                        <p>The order in which rasters are considered to evaluate the operation is the order of appearance in the catalog.</p>
                        <p>The following complex multiple raster algebra operations are available:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">combine</code>: Assigns a unique output value to each unique combination of input values in the same cell for the raster sequence.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">majority</code>: Assigns the value within the same cells of the rasters sequence that is the most numerous. If there is a values tie, the one on the right is selected.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">minority</code>: Assigns the value within the same cells of the raster sequence that is the least numerous. If there is a values tie, the one on the right is selected.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">variety</code>: Assigns the count of unique values at each same cell in the sequence of rasters.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">mask</code>: Generates a raster with the values from the first raster, but only includes pixels in which the corresponding pixel in the rest of rasters of the sequence is set to the specified mask values. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">inversemask</code>: Generates a raster with the values from the first raster, but only includes pixels in which the corresponding pixel in the rest of rasters of the sequence is <span class="italic">not</span> set to the specified mask values. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">equals</code>: Creates a raster with data type byte, where cell values equal 1 if the corresponding cells for all input rasters have the same value. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">unequal</code>: Creates a raster with data type byte, where cell values equal 1 if the corresponding cells for all input rasters have a different value. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">greater</code>: Creates a raster with data type byte, where cell values equal 1 if the cell value in the first raster is greater than the rest of corresponding cells for all input. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">greaterorequal</code>: Creates a raster with data type byte, where cell values equal 1 if the cell value in the first raster is greater or equal than the rest of corresponding cells for all input. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">less</code>: Creates a raster with data type byte, where cell values equal 1 if the cell value in the first raster is less than the rest of corresponding cells for all input. Otherwise, 0 is set.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">lessorequal</code>: Creates a raster with data type byte, where cell values equal 1 if the cell value in the first raster is less or equal than the rest of corresponding cells for all input. Otherwise, 0 is set.
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E418EC48-426C-423F-B2A5-3AB3A6D5556C">Multiple Raster Algebra Operations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-C21FD285-0AF7-48A7-B0FF-64581D27CC4E" name="GUID-C21FD285-0AF7-48A7-B0FF-64581D27CC4E"></a><h4 id="BDSPA-GUID-C21FD285-0AF7-48A7-B0FF-64581D27CC4E" class="sect4"><span class="enumeration_section">2.5.7 </span>Pyramids
                  </h4>
                  <div>
                     <p><span class="bold">Pyramids</span> are subobjects of a raster object that represent the raster image or raster data at differing sizes and degrees of resolution.
                     </p>
                     <p>The size is usually related to the amount of time that an application needs to retrieve and display an image, particularly over the web. That is, the smaller the image size, the faster it can be displayed; and as long as detailed resolution is not needed (for example, if the user has "zoomed out" considerably), the display quality for the smaller image is adequate.</p>
                     <p><span class="bold">Pyramid levels</span> represent reduced or increased resolution images that require less or more storage space, respectively. (Big Data Spatial and Graph supports only reduced resolution pyramids.) A pyramid level of 0 indicates the original raster data; that is, there is no reduction in the image resolution and no change in the storage space required. Values greater than 0 (zero) indicate increasingly reduced levels of image resolution and reduced storage space requirements.
                     </p>
                     <p>A single raster is processed for each pyramid request, and the following parameters apply:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Pyramid level (required): the maximum reduction level; that is, the number of pyramid levels to create at a reduced size than the original object. For example, <code class="codeph">redLevel=”6”</code> causes pyramid levels to be created for levels 0 through 5.
                           </p>
                           <p>The dimension sizes at each lower level are:<code class="codeph"> r(n) = r(n - 1)/2</code> and <code class="codeph">c(n) = c(n - 1)/2</code> where:
                           </p>
                           <p><code class="codeph">r(n)</code> and <code class="codeph">c(n)</code> are the row and column sizes for a pyramid at level <code class="codeph">n</code></p>
                           <p>The smaller of the row and column dimension sizes of the top-level overview is between 64 and 128 (maximum reduced-resolution level): <code class="codeph">(int)(log2(a/64))</code> where <code class="codeph">a</code> is the smaller of the original row or column dimension size.
                           </p>
                           <p>If an <code class="codeph">rLevel</code> value greater than the maximum reduced-resolution level is specified, the <code class="codeph">rLevel</code> value is set to the maximum reduced-resolution level.
                           </p>
                        </li>
                        <li>
                           <p>Resampling algorithm: the resampling method to use. </p>
                           <p>Must be one of the following: <code class="codeph">NEAREST_NEIGHBOR</code>, <code class="codeph">BILINEAR</code>, <code class="codeph">AVERAGE4</code>, <code class="codeph">AVERAGE16</code>. (<code class="codeph">BILINEAR</code> and <code class="codeph">AVERAGE4</code> have the same effect.) If no resampling algorithm is specified, <code class="codeph">BILINEAR</code> is used by default.
                           </p>
                        </li>
                     </ul>
                     <p>Pyramids can be created while loading multiple rasters or processing a single raster:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>While loading the rasters in HDFS, by adding the <code class="codeph">-pyramid</code> parameter to the loader command line call or by using the API <code class="codeph">loader.addPyramid()</code></p>
                        </li>
                        <li>
                           <p>For processing a single raster, by adding the operation in the user request XML or by using the API <code class="codeph">processor.addPyramid()</code></p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA150"></a><div class="props_rev_3"><a id="GUID-10E840FE-0EA9-492D-B1E1-44E4F0C059C1" name="GUID-10E840FE-0EA9-492D-B1E1-44E4F0C059C1"></a><h4 id="BDSPA-GUID-10E840FE-0EA9-492D-B1E1-44E4F0C059C1" class="sect4"><span class="enumeration_section">2.5.8 </span>Output
                  </h4>
                  <div>
                     <p>When you specify an HDFS directory in the configuration XML, the output generated is an <code class="codeph">.ohif </code>file as in the case of an <code class="codeph">ImageLoader</code> job, 
                     </p>
                     <p>When the user specifies a FS directory in the configuration XML, the output generated is an image with the filename and type specified and is stored into regular FileSystem.</p>
                     <p>In both the scenarios, the output must comply with the specifications set in the configuration XML. The job execution logs can be accessed using the command <code class="codeph">yarn logs -applicationId &lt;applicationId&gt;</code>.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C379D151-8346-4038-A3F1-A10772506B7A" title="Once the images are loaded into HDFS, they can be processed in parallel using Oracle Spatial Hadoop Image Processing Framework.">Processing an Image Using the Oracle Spatial Hadoop Image Processor</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div>
            <div class="props_rev_3"><a id="GUID-1520C09F-ED2A-44B7-8702-EB09B14AAD85" name="GUID-1520C09F-ED2A-44B7-8702-EB09B14AAD85"></a><h3 id="BDSPA-GUID-1520C09F-ED2A-44B7-8702-EB09B14AAD85" class="sect3"><span class="enumeration_section">2.6 </span>Loading and Processing an Image Using the Oracle Spatial Hadoop Raster Processing API
               </h3>
               <div>
                  <p>The framework provides a raster processing API that lets you load and process rasters without creating XML but instead using a Java application. The application can be executed inside the cluster or on a remote node.</p>
                  <p>The API provides access to the framework operations, and is useful for web service or standalone Java applications.</p>
                  <p>To execute any of the jobs, a <code class="codeph">HadoopConfiguration</code> object must be created. This object is used to set the necessary configuration information (such as the jar file name and the GDAL paths) to create the job, manipulate rasters, and execute the job. The basic logic is as follows:
                  </p><pre class="oac_no_warn" dir="ltr">     //Creates Hadoop Configuration
     HadoopConfiguration hadoopConf = new HadoopConfiguration();
     //Assigns GDAL_DATA location based on specified SHAREDDIR, this data folder is required by gdal to look for data tables that allow SRID conversions
     String gdalData = sharedDir + ProcessConstants.DIRECTORY_SEPARATOR + "data";
     hadoopConf.setGdalDataPath(gdalData);
     //Sets jar name for processor
     hadoopConf.setMapreduceJobJar("hadoop-imageprocessor.jar");
     //Creates the job
     RasterProcessorJob processor = (RasterProcessorJob) hadoopConf.createRasterProcessorJob();
</pre><p>If the API is used on a remote node, you can set properties in the Hadoop Configuration object to connect to the cluster. For example:</p><pre class="oac_no_warn" dir="ltr">        //Following config settings are required for standalone execution. (REMOTE ACCESS)
        hadoopConf.setUser("hdfs");
        hadoopConf.setHdfsPathPrefix("hdfs://den00btb.us.oracle.com:8020");
        hadoopConf.setResourceManagerScheduler("den00btb.us.oracle.com:8030");
        hadoopConf.setResourceManagerAddress("den00btb.us.oracle.com:8032");
        hadoopConf.setYarnApplicationClasspath("/etc/hadoop/conf/,/usr/lib/hadoop/*,/usr/lib/hadoop/lib/*," +
                          "/usr/lib/hadoop-hdfs/*,/usr/lib/hadoop-hdfs/lib/*,/usr/lib/hadoop-yarn/*," +
                          "/usr/lib/hadoop-yarn/lib/*,/usr/lib/hadoop-mapreduce/*,/usr/lib/hadoop-mapreduce/lib/* ");
</pre><p>After the job is created, the properties for its execution must be set depending on the job type. There are two job classes: <code class="codeph">RasterLoaderJob</code> to load the rasters into HDFS, and <code class="codeph">RasterProcessorJob</code> to process them.
                  </p>
                  <p>The following example loads a Hawaii raster into the APICALL_HDFS directory. It creates a thumbnail in a shared folder, and specifies 10 pixels overlapping on each edge of the tiles.</p><pre class="oac_no_warn" dir="ltr">    private static void executeLoader(HadoopConfiguration hadoopConf){
        hadoopConf.setMapreduceJobJar("hadoop-imageloader.jar");
        RasterLoaderJob loader = (RasterLoaderJob) hadoopConf.createRasterLoaderJob();
        loader.setFilesToLoad("/net/den00btb/scratch/zherena/hawaii/hawaii.tif");
        loader.setTileOverlap("10");
        loader.setOutputFolder("APICALL");
        loader.setRasterThumbnailFolder("/net/den00btb/scratch/zherena/processOutput");
        try{
        loader.setGdalPath("/net/den00btb/scratch/zherena/gdal/lib");
         
        boolean loaderSuccess = loader.execute();
            if(loaderSuccess){
                System.out.println("Successfully executed loader job");
            }
            else{
                System.out.println("Failed to execute loader job");
            }
        }catch(Exception e ){
        System.out.println("Problem when trying to execute raster loader " + e.getMessage());
        }
    }
}</pre><p>The following example processes the loaded raster.</p><pre class="oac_no_warn" dir="ltr">private static void executeProcessor(HadoopConfiguration hadoopConf){
    hadoopConf.setMapreduceJobJar("hadoop-imageprocessor.jar");
    RasterProcessorJob processor = (RasterProcessorJob) hadoopConf.createRasterProcessorJob();
     
    try{
    processor.setGdalPath("/net/den00btb/scratch/zherena/gdal/lib");
    MosaicConfiguration mosaic = new MosaicConfiguration();
        mosaic.setBands(3);
        mosaic.setDirectory("/net/den00btb/scratch/zherena/processOutput");
        mosaic.setFileName("APIMosaic");
        mosaic.setFileSystem(RasterProcessorJob.FS);
        mosaic.setFormat("GTIFF");
        mosaic.setHeight(3192);
        mosaic.setNoData("#FFFFFF");
        mosaic.setOrderAlgorithm(ProcessConstants.ALGORITMH_FILE_LENGTH);
        mosaic.setOrder("1");
        mosaic.setPixelType("1");
        mosaic.setPixelXWidth(67.457513);
        mosaic.setPixelYWidth(-67.457513);
        mosaic.setSrid("26904");
        mosaic.setUpperLeftX(830763.281336);
        mosaic.setUpperLeftY(2259894.481403);
        mosaic.setWidth(1300);
    processor.setMosaicConfigurationObject(mosaic.getCompactMosaic()); 
        RasterCatalog catalog = new RasterCatalog();
        Raster raster = new Raster();
        raster.setBands(3);
        raster.setBandsOrder("1,2,3");
        raster.setDataType(1);
        raster.setRasterLocation("/user/hdfs/APICALL/net/den00btb/scratch/zherena/hawaii/hawaii.tif.ohif");
        catalog.addRasterToCatalog(raster);
           
        processor.setCatalogObject(catalog.getCompactCatalog());
    boolean processorSuccess = processor.execute();
        if(processorSuccess){
            System.out.println("Successfully executed processor job");
        }
        else{
            System.out.println("Failed to execute processor job");
        }
    }catch(Exception e ){
    System.out.println("Problem when trying to execute raster processor " + e.getMessage());
    }
}</pre><p>In the preceding example, the thumbnail is optional if the mosaic results will be stored in HDFS. If a processing jar file is specified (used when the additional user processing classes are specified), the location of the jar file containing these lasses must be specified. The other parameters are required for the mosaic to be generated successfully.</p>
                  <p>Several examples of using the processing API are provided <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/src</code>. Review the Java classes to understand their purpose. You may execute them using the scripts provided for each example located under <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/cmd</code>.
                  </p>
                  <p>After you have executed the scripts and validated the results, you can modify the Java source files to experiment on them and compile them using the provided script <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/build.xml</code>. Ensure that you have write access on the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/jlib directory</code>.
                  </p>
               </div>
               <div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               
            </div>
            <div class="props_rev_3"><a id="GUID-A1D8D339-8D2A-4B18-BED8-89CE6C50F143" name="GUID-A1D8D339-8D2A-4B18-BED8-89CE6C50F143"></a><h3 id="BDSPA-GUID-A1D8D339-8D2A-4B18-BED8-89CE6C50F143" class="sect3"><span class="enumeration_section">2.7 </span>Using the Oracle Spatial Hadoop Raster Simulator Framework to Test Raster Processing
               </h3>
               <div>
                  <p>When you create custom processing classes. you can use the Oracle Spatial Hadoop Raster Simulator Framework to do the following by "pretending" to plug them into the Oracle Raster Processing Framework.</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>Develop user processing classes on a local computer </p>
                     </li>
                     <li>
                        <p>Avoid the need to deploy user processing classes in a cluster or in Big Data Lite to verify their correct functioning</p>
                     </li>
                     <li>
                        <p>Debug user processing classes </p>
                     </li>
                     <li>
                        <p>Use small local data sets </p>
                     </li>
                     <li>
                        <p>Create local debug outputs</p>
                     </li>
                     <li>
                        <p>Automate unit tests</p>
                     </li>
                  </ul>
                  <p>The Simulator framework will emulate the loading and processing processes in your local environment, as if they were being executed in a cluster. You only need to create a Junit test case that loads one or more rasters and processes them according to your specification in XML or  a configuration object.</p>
                  <p>Tiles are generated according to specified block size, so you must set a block size. The number of mappers and reducers to execute depends on the number of tiles, just as in regular cluster execution. OHIF files generated during the loading process are stored in local directory, because no HDFS is required.</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>Simulator (“Mock”) Objects</p>
                     </li>
                     <li>
                        <p>User Local Environment Requirements</p>
                     </li>
                     <li>
                        <p>Sample Test Cases to Load and Process Rasters</p>
                     </li>
                  </ul>
                  <div class="section">
                     <p class="subhead2">Simulator (“Mock”) Objects</p>
                     <p>To load rasters and convert them into .OHIF files that can be processed, a <code class="codeph">RasterLoaderJobMock</code> must be executed. This class constructor receives the <code class="codeph">HadoopConfiguration</code> that must include the block size, the directory or rasters to load, the output directory to store the OHIF files, and the gdal directory.  The parameters representing the input files and the user configuration vary in terms of how you specify them:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Location Strings for catalog and user configuration XML file</p>
                        </li>
                        <li>
                           <p>Catalog object  (<code class="codeph">CatalogMock</code>)
                           </p>
                        </li>
                        <li>
                           <p>Configuration objects (<code class="codeph">MosaicProcessConfigurationMock</code> or <code class="codeph">SingleProcessConfigurationMock</code>) 
                           </p>
                        </li>
                        <li>
                           <p>Location for a single raster processing and a user configuration (<code class="codeph">MosaicProcessConfigurationMock</code> or <code class="codeph">SingleProcessConfigurationMock</code>)
                           </p>
                        </li>
                     </ul>
                  </div>
                  <!-- class="section" -->
                  <div class="section">
                     <p class="subhead2">User Local Environment Requirements</p>
                     <p>Before you create test cases, you need to configure your local environment.</p>
                     <ol>
                        <li>
                           <p>1.	Ensure that a directory has the native gdal libraries, <code class="codeph">gdal-data</code> and <code class="codeph">libproj</code>.
                           </p>
                           <p>For Linux:</p>
                           <ol type="a">
                              <li>
                                 <p>Follow the steps in <a href="big-data-spatial-overview.html#GUID-2DC0ACEE-2922-46FD-9D84-9C774CBF232A">Getting and Compiling the Cartographic Projections Library</a> to obtain <code class="codeph">libproj.so</code>.
                                 </p>
                              </li>
                              <li>
                                 <p>Get the gdal distribution from the Spatial installation on your cluster or BigDataLite VM at <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/gdal</code>.
                                 </p>
                              </li>
                              <li>
                                 <p>Move <code class="codeph">libproj.so</code> to your local gdal directory under <code class="codeph">gdal/lib</code> with the rest of the native gdal libraries.
                                 </p>
                              </li>
                           </ol>
                           <p>For Windows:</p>
                           <ol type="a">
                              <li>
                                 <p>Get the gdal distribution from your Spatial install on your cluster or BigDataLite VM at <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/mock/lib/gdal_windows.x64.zip</code>.
                                 </p>
                              </li>
                              <li>
                                 <p>Be sure that Visual Studio installed. When you install it, make sure you select the <span class="italic">Common Tools for Visual C++</span>.
                                 </p>
                              </li>
                              <li>
                                 <p>Download the PROJ 4 source code, version branch 4.9 from <a href="https://trac.osgeo.org/proj4j" target="_blank">https://trac.osgeo.org/proj4j</a>.
                                 </p>
                              </li>
                              <li>
                                 <p>Open the Visual Studio Development Command Prompt and type:</p><pre class="pre codeblock"><code>cd PROJ4/src_dir
nmake /f makefile.vc
</code></pre></li>
                              <li>
                                 <p>Move <code class="codeph">proj.dll</code> to your local gdal directory under <code class="codeph">gdal/bin</code> with the rest of the native gdal libraries.
                                 </p>
                              </li>
                           </ol>
                        </li>
                        <li>
                           <p>Add GDAL native libraries to system path.</p>
                           <p>For Linux: Export <span class="bold">LD_LIBRARY_PATH</span> with corresponding native gdal  libraries directory 
                           </p>
                           <p>For Windows: Add to the <span class="bold">Path</span> environment variable the native gdal libraries directory.
                           </p>
                        </li>
                        <li>
                           <p>Ensure that the Java project has Junit libraries.</p>
                        </li>
                        <li>
                           <p>Ensure that the Java project has the following Hadoop jar and Oracle Image Processing Framework files in the classpath You may get them from the Oracle BigDataLite VM or from your cluster; these are all jars included in the Hadoop distribution, and for specific framework jars, go to <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/jlib</code>:
                           </p>
                           <p>(In the following list, <code class="codeph">VERSION_INCLUDED</code> refers to the version number from the Hadoop installation containing the files; it can be a BDA cluster or a BigDataLite VM.)
                           </p><pre class="oac_no_warn" dir="ltr">commons-collections-VERSION_INCLUDED.jar
commons-configuration-VERSION_INCLUDED.jar
commons-lang-VERSION_INCLUDED.jar
commons-logging-VERSION_INCLUDED.jar
commons-math3-VERSION_INCLUDED.jar
gdal.jar
guava-VERSION_INCLUDED.jar
hadoop-auth-VERSION_INCLUDED-cdhVERSION_INCLUDED.jar
hadoop-common-VERSION_INCLUDED-cdhVERSION_INCLUDED.jar
hadoop-imageloader.jar
hadoop-imagemocking-fwk.jar
hadoop-imageprocessor.jar
hadoop-mapreduce-client-core-VERSION_INCLUDED-cdhVERSION_INCLUDED.jar
hadoop-raster-fwk-api.jar
jackson-core-asl-VERSION_INCLUDED.jar
jackson-mapper-asl-VERSION_INCLUDED.jar
log4j-VERSION_INCLUDED.jar
slf4j-api-VERSION_INCLUDED.jar
slf4j-log4j12-VERSION_INCLUDED.jar
</pre></li>
                     </ol>
                  </div>
                  <!-- class="section" -->
                  <div class="section">
                     <p class="subhead2">Sample Test Cases to Load and Process Rasters</p>
                     <p>After your Java project is prepared for your test cases, you can test the loading and processing of rasters.</p>The following example creates a class with a <code class="codeph">setUp</code> method to configure the directories for gdal, the rasters to load, your configuration XML files, the output thumbnails, ohif files, and process results. It also configures the block size (8 MB). (A small block size is recommended for single computers.)<pre class="oac_no_warn" dir="ltr">	/**
	 * Set the basic directories before starting the test execution
	 */
	@Before
	public void setUp(){
		String sharedDir = "C:\\Users\\zherena\\Oracle Stuff\\Hadoop\\Release 4\\MockTest";
		String allAccessDir = sharedDir +  "/out/";
		gdalDir = sharedDir + "/gdal";
		directoryToLoad = allAccessDir + "rasters";
		xmlDir = sharedDir + "/xmls/";
		outputDir = allAccessDir;
		blockSize = 8;
	}
</pre><p>The following example creates a RasterLoaderJobMock object, and sets the rasters to load and the output path for OHIF files:</p><pre class="oac_no_warn" dir="ltr">/**
	 * Loads a directory of rasters, and generate ohif files and thumbnails
       * for all of them
	 * @throws Exception if there is a problem during load process
	 */
	@Test
	public void basicLoad() throws Exception {
		System.out.println("***LOAD OF DIRECTORY WITHOUT EXPANSION***");
		HadoopConfiguration conf = new HadoopConfiguration();
		conf.setBlockSize(blockSize);
		System.out.println("Set block size of: " +  
                                conf.getProperty("dfs.blocksize"));
		RasterLoaderJobMock loader = new RasterLoaderJobMock(conf, 
                                    outputDir, directoryToLoad, gdalDir);
		//Puts the ohif file directly in the specified output directory
		loader.dontExpandOutputDir();
		System.out.println("Starting execution");
	    System.out.println("------------------------------------------------------------------------------------------------------------");
	    loader.waitForCompletion();
		System.out.println("Finished loader");
		System.out.println("LOAD OF DIRECTORY WITHOUT EXPANSION ENDED");
		System.out.println();
		System.out.println();
	}
</pre><p>The following example specifies catalog and user configuration XML files to the <code class="codeph">RasterProcessorJobMock</code> object. Make sure your <code class="codeph">catalog xml</code> points to the correct location of your local OHIF files.
                     </p><pre class="oac_no_warn" dir="ltr">	/**
	 * Creates a mosaic raster by using configuration and catalog xmls.    
         * Only two bands are selected per raster.
	 * @throws Exception	if there is a problem during mosaic process.
	 */
	@Test
	public void mosaicUsingXmls() throws Exception {
		System.out.println("***MOSAIC PROCESS USING XMLS***");
		HadoopConfiguration conf = new HadoopConfiguration();
		conf.setBlockSize(blockSize);
		System.out.println("Set block size of: " +   
               conf.getProperty("dfs.blocksize"));
               String catalogXml = xmlDir + "catalog.xml";
	       String configXml = xmlDir + "config.xml";
	RasterProcessorJobMock processor = new  RasterProcessorJobMock(conf, configXml, catalogXml, gdalDir);
		System.out.println("Starting execution");
              System.out.println("------------------------------------------------------------------------------------------------------------");
	        processor.waitForCompletion();
		System.out.println("Finished processor");
		System.out.println("***********************************************MOSAIC PROCESS USING XMLS ENDED***********************************************");
		System.out.println();
		System.out.println();
</pre><p>Additional examples using the different supported configurations for <code class="codeph">RasterProcessorJobMock</code> are provided in <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/mock/src</code>.They include an example using an external processing class, which is also included and can be debugged.
                     </p>
                  </div>
                  <!-- class="section" -->
               </div>
               <div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               
            </div>
            <div class="props_rev_3"><a id="GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E" name="GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E"></a><h3 id="BDSPA-GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E" class="sect3"><span class="enumeration_section">2.8 </span>Oracle Big Data Spatial Raster Processing for Spark
               </h3>
               <div>
                  <p>Oracle Big Data Spatial Raster Processing for Apache Spark is a spatial raster processing API for Java.</p>
                  <p>This API allows the creation of new combined images resulting from a series of user-defined processing phases, with the following features:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>HDFS images storage, where every block size split is stored as a separate tile, ready for future independent processing</p>
                     </li>
                     <li>
                        <p>Subset, mosaic, and raster algebra operations processed in parallel using Spark to divide the processing.</p>
                     </li>
                     <li>
                        <p>Support for GDAL formats, multiple bands images, DEMs (digital elevation models), multiple pixel depths, and SRIDs</p>
                     </li>
                  </ul>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-0785EFD7-6FC9-45A8-85DF-92486F336E38">Spark Raster Loader</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-F04B19CD-B139-4AF1-BEFA-DA272E8652B6">Spark SQL Raster Processor</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722">Using the Spark Raster Processing API</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="props_rev_3"><a id="GUID-0785EFD7-6FC9-45A8-85DF-92486F336E38" name="GUID-0785EFD7-6FC9-45A8-85DF-92486F336E38"></a><h4 id="BDSPA-GUID-0785EFD7-6FC9-45A8-85DF-92486F336E38" class="sect4"><span class="enumeration_section">2.8.1 </span>Spark Raster Loader
                  </h4>
                  <div>
                     <p>The first step in using the raster processing for Spark Java API is to have the images in HDFS, followed by having the images separated into smart tiles. This allows the processor to work on each tile independently. The Spark raster loader lets you import a single image or a collection of them into HDFS in parallel, which decreases the load time. Each block contains data for all the raster bands, so that if further processing is required on specific pixels, the information can be processed on a single node.</p>
                     <p>The basic workflow for the Spark raster loader is as follows.</p>
                     <ol>
                        <li>
                           <p>GDAL is used to import the rasters, tiling them according to block size and then storing each tile as an HDFS block.</p>
                        </li>
                        <li>
                           <p>The set of rasters to be loaded is read into a <code class="codeph">SpatialRasterJavaRDD</code>, which is an extension of <code class="codeph">JavaRDD</code>. This RDD is a collection of <code class="codeph">ImagePieceWritable</code> objects that represent the information of the tiles to create per raster, based on the number of bands, pixel size, HDFS block size, and raster resolution. This is accomplished by using the custom input format used in the spatial Hadoop loader.
                           </p>
                        </li>
                        <li>
                           <p>The raster information for each tile is loaded. This load is performed by an executor for each tile, so reading is performed parallel. Each tile includes a certain number of overlapping bytes (user input), so that the tiles cover area from the adjacent tiles. There are “n” number of Spark executors, depending on the number of tiles, image resolution, and block size.</p>
                        </li>
                        <li>
                           <p>The RDD is grouped by key, so that all the tiles that correspond to the same raster are part of the same record. This RDD is saved as OHIF using the <code class="codeph">OhifOutputFormat</code>, which puts together all the information loaded by the executors and stores the images into a special <code class="codeph">.ohif</code> format, which contains the resolution, bands, offsets, and image data. In this way, the file offset containing each tile and the node location is known. A special reading process is required to read the image back and is included in the Spark SQL raster processor.
                           </p>
                        </li>
                     </ol>
                     <p>Each tile contains information for every band. This is helpful when there is a need to process only a few tiles; then, only the corresponding blocks are loaded.</p>
                     <p>The loader can be configured by setting parameters on the command line or by using the Spark API.</p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-187EC77F-6E06-4CC6-8590-6A62E449C1E9">Input Parameters to the Spark Raster Loader</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-B1C1DE27-E527-45EF-81E3-AF35B13436DF">Expected Output of the Spark Raster Loader</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E" title="Oracle Big Data Spatial Raster Processing for Apache Spark is a spatial raster processing API for Java.">Oracle Big Data Spatial Raster Processing for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-187EC77F-6E06-4CC6-8590-6A62E449C1E9" name="GUID-187EC77F-6E06-4CC6-8590-6A62E449C1E9"></a><h5 id="BDSPA-GUID-187EC77F-6E06-4CC6-8590-6A62E449C1E9" class="sect5"><span class="enumeration_section">2.8.1.1 </span>Input Parameters to the Spark Raster Loader
                     </h5>
                     <div>
                        <p>The following example shows input parameters supplied using the spark-submit command:</p><pre class="pre codeblock"><code>spark-submit
	--class &lt;DRIVER_CLASS&gt;
	--driver-memory &lt;DRIVER_JVM&gt;
	--driver-class-path &lt;DRIVER_CLASSPATH&gt;
	--jars &lt;EXECUTORS_JARS&gt;
	&lt;DRIVER_JAR&gt;
	-files &lt;SOURCE_IMGS_PATH&gt;
	-out &lt;HDFS_OUTPUT_FOLDER&gt;
	-gdal &lt;GDAL_LIB_PATH&gt;
	-gdalData &lt;GDAL_DATA_PATH&gt;
	[-overlap &lt;OVERLAPPING_PIXELS&gt;]
	[-thumbnail &lt;THUMBNAIL_PATH&gt;]
	[-expand &lt;false|true&gt;]
</code></pre><p>Where:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">DRIVER_CLASS</code> is the class that has the driver code and that Spark will execute.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">DRIVER_JVM</code> is the memory to assign to driver´s JVM.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">DRIVER_CLASSPATH</code> is the classpath for driver class, jars are separated by colon.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">EXECUTOR_JARS</code> is the classpath to be distributed to executors, jars are separated by comma.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">DRIVER_JAR</code> is the jar that contains the &lt;DRIVER_CLASS&gt; to execute by Spark.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">SOURCE_IMGS_PATH</code> is a path to the source raster(s) or folder(s). For multiple inputs use a comma separator. This path must be accessible via NFS to all nodes in the cluster.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">HDFS_OUTPUT_FOLDER</code> is the HDFS output folder where the loaded images are stored.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">OVERLAPPING_PIXELS</code> is an optional number of overlapping pixels on the borders of each tile, if this parameter is not specified a default of two overlapping pixels is considered.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">GDAL_LIB_PATH</code> is the path where GDAL libraries are located.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">GDAL_DATA_PATH</code> is the path where GDAL data folder is located. This path must be accessible through NFS to all nodes in the cluster.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">THUMBNAIL_PATH</code> is an optional path to store a thumbnail of the loaded image(s). This path must be accessible through NFS to all nodes in the cluster and must have write access permission for yarn users.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">-expand</code> controls whether the HDFS path of the loaded raster expands the source path, including all directories. If you set this to <code class="codeph">false</code>, the <code class="codeph">.ohif</code> file is stored directly in the output directory (specified using the <code class="codeph">-o</code> option) without including that directory’s path in the raster.
                              </p>
                           </li>
                        </ul>
                        <p>Each tile contains information for every band. This is helpful when there is a need to process only a few tiles; then, only the corresponding blocks are loaded.</p>
                        <p>The loader can be configured by setting parameters on the command line or by using the Spark API.</p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-0785EFD7-6FC9-45A8-85DF-92486F336E38">Spark Raster Loader</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-B1C1DE27-E527-45EF-81E3-AF35B13436DF" name="GUID-B1C1DE27-E527-45EF-81E3-AF35B13436DF"></a><h5 id="BDSPA-GUID-B1C1DE27-E527-45EF-81E3-AF35B13436DF" class="sect5"><span class="enumeration_section">2.8.1.2 </span>Expected Output of the Spark Raster Loader
                     </h5>
                     <div>
                        <p>For each input image to the Spark raster loader, there are two output files per input image.</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The <code class="codeph">.ohif</code> file that concentrates all the tiles for the source image. Each tile (stored as a HDFS block) may be processed as a separated instance by a processing executor. The <code class="codeph">.ohif</code> file is stored in a user-specified folder with <code class="codeph">-out</code> flag, under <code class="codeph">/user/&lt;USER_EXECUTING_JOB&gt;/OUT_FOLDER/&lt;PARENT_DIRECTORIES_OF_SOURCE_RASTER&gt;</code> if the flag<code class="codeph"> &#x2013;expand</code> was not used. Otherwise, the <code class="codeph">.ohif</code> file will be located at <code class="codeph">/user/&lt;USER_EXECUTING_JOB&gt;/OUT_FOLDER/</code>, and the file can be identified as <code class="codeph">original_filename.ohif</code>.
                              </p>
                           </li>
                           <li>
                              <p>A related metadata file that lists all the pieces of the image and the coordinates that each one covers. This file is located in HDFS under the <code class="codeph">spatial_raster/metadata</code> location, and its name is hash-generated using the name of the <code class="codeph">.ohif</code> file. This file is for Oracle internal use only, and lists important metadata of the source raster. Some example lines from a metadata file:
                              </p><pre class="pre codeblock"><code>size:3200,2112
srid:26904
datatype:1
resolution:27.90809458890406,-27.90809458890406
file:/user/hdfs/ohiftest/opt/shareddir/spatial/data/rasters/hawaii.tif.ohif
bands:3
mbr:532488.7648166901,4303164.583549625,582723.3350767174,4269619.053853762
0,532488.7648166901,4303164.583549625,582723.3350767174,4269619.053853762
thumbnailpath:/opt/shareddir/spatial/thumb/
</code></pre></li>
                        </ul>
                        <p>If the <code class="codeph">-thumbnail</code> flag was specified, a thumbnail of the source image is stored in the related folder. This is a way to visualize a translation of the <code class="codeph">.ohif</code> file. Execution logs can be accessed using the command <code class="codeph">yarn logs -applicationId &lt;applicationId&gt;</code>.
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-0785EFD7-6FC9-45A8-85DF-92486F336E38">Spark Raster Loader</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-F04B19CD-B139-4AF1-BEFA-DA272E8652B6" name="GUID-F04B19CD-B139-4AF1-BEFA-DA272E8652B6"></a><h4 id="BDSPA-GUID-F04B19CD-B139-4AF1-BEFA-DA272E8652B6" class="sect4"><span class="enumeration_section">2.8.2 </span>Spark SQL Raster Processor
                  </h4>
                  <div>
                     <p>Once the images are loaded into HDFS, they can be processed using Spark SQL Raster Processor. You specify the expected raster output features using the <a href="using-big-data-spatial-graph-spatial-data.html#GUID-9C3066FD-1152-47F4-A2E9-0518E6B7BE4F">Mosaic Definition XML Structure</a> or the Spark API, and the mosaic UDF filters the tiles to fit into that output and processes them. Raster algebra operations are also available in UDF.
                     </p>
                     <p>A custom <code class="codeph">InputFormat</code>, which is also used in the Hadoop raster processing framework, loads specific blocks of data, based on the input (mosaic description or a single raster) using raster SRID and coordinates, and selects only the bands and pixels that fit into the final output before accepting processing operations:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>For a mosaic processing request, only the intersecting tiles are selected, and a split is created for each one of them.</p>
                        </li>
                        <li>
                           <p>For a single raster processing request, all the tiles are selected, and a split is created for each one of them.</p>
                        </li>
                     </ul>
                     <p>The Spark SQL Raster Processor allows you to filter the OHIF tiles based on input catalog or raster into a Dataframe, with every row representing a tile, and to use Spatial UDF Spark functions to process them.</p>
                     <p>A simplified pseudocode representation of Spark SQL raster processing is:</p><pre class="pre codeblock"><code>sqlContext.udf().register("localop", new LocalOperationsFunction(),DataTypes.createStructType(SpatialRasterJavaRDD.createSimpleTileStructField(dataTypeOfTileToProcess)));
tileRows.registerTempTable("tiles");
String query = "SELECT localop(tileInfo, userRequest,  \"localnot\"), userRequest FROM tiles";
DataFrame processedTiles = sqlContext.sql(query);
</code></pre><p>The basic workflow if the Spark SQL raster processor is as follows.</p>
                     <ol>
                        <li>
                           <p>The rasters to process are first loaded in tiles metadata as RDD. These tiles may be filtered if the user set a configuration for mosaic operation. The RDD is later converted to a Spark DataFrame of two complex rows: the first row is <code class="codeph">tileInfo</code>, which has all the metadata for the tiles, and the second row is the <code class="codeph">userRequest</code>, which has the user input configuration listing the expected features of the raster output.
                           </p>
                        </li>
                        <li>
                           <p>Once the DataFrame is created, the driver must register the “localop” UDF, and also register the DataFrame as a table before executing a query to process. The mosaic UDF can only be executed if the user configured all the required parameters correctly. If no XML is used and the configuration is set using the API, then by default a mosaic operation configuration is expected unless the <code class="codeph">setExecuteMosaic(false)</code> method is set.
                           </p>
                        </li>
                        <li>
                           <p>The mosaic operation selects from every tile only the pixels that fit into the output, and makes the necessary resolution changes to add them in the mosaic output.</p>
                        </li>
                        <li>
                           <p>Once the query is executed, an executor loads the data corresponding tile, conserving data locality, and the specified local raster algebra operation is executed.</p>
                        </li>
                        <li>
                           <p>The row in the DataFrame is updated with the new pixel data and returned to the driver for further processing if required. </p>
                        </li>
                        <li>
                           <p>Once the processing is done, the DataFrame is converted to a list of <code class="codeph">ImageBandWritable</code> objects, which are the MapReduce representation of processed tiles. These are input to the <code class="codeph">ProcessedRasterCreator</code>, where resulting bytes of local raster algebra and/or mosaic operations are put together, and a final raster is stored into HDFS or the regular file system depending on the user request.
                           </p>
                        </li>
                     </ol>
                     <p>Only images with same data type (pixel depth) as the user configuration input data type (pixel depth) are considered. Only the tiles that intersect with coordinates specified by the user for the mosaic output are included. For processing of a single raster, the filter includes all the tiles of the input rasters, because the processing will be executed on the complete images.</p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-EB15D16E-9923-4B83-9D82-E9A0A1055D02">Input Parameters to the Spark SQL Raster Processor</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-851AAEF6-5A30-49D7-AB72-157A2C04F8E5">Expected Output of the Spark SQL Raster Processor</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E" title="Oracle Big Data Spatial Raster Processing for Apache Spark is a spatial raster processing API for Java.">Oracle Big Data Spatial Raster Processing for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-EB15D16E-9923-4B83-9D82-E9A0A1055D02" name="GUID-EB15D16E-9923-4B83-9D82-E9A0A1055D02"></a><h5 id="BDSPA-GUID-EB15D16E-9923-4B83-9D82-E9A0A1055D02" class="sect5"><span class="enumeration_section">2.8.2.1 </span>Input Parameters to the Spark SQL Raster Processor
                     </h5>
                     <div>
                        <p>The following example shows input parameters supplied using the spark-submit command:</p><pre class="pre codeblock"><code>spark-submit 
	--class &lt;DRIVER_CLASS&gt;
	--driver-memory &lt;DRIVER_JVM&gt;
	--driver-class-path &lt;DRIVER_CLASSPATH&gt;
	--jars &lt;EXECUTORS_JARS&gt;
	&lt;DRIVER_JAR&gt;
	-config  &lt;MOSAIC_CONFIG_PATH&gt;
	-gdal  &lt;GDAL_LIBRARIES_PATH&gt;
	-gdalData  &lt;GDAL_DATA_PATH&gt;
	[-catalog  &lt;IMAGE_CATALOG_PATH&gt;]
	[-file  &lt;SINGLE_RASTER_PATH&gt;]
</code></pre><p>Where:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">DRIVER_CLASS</code> is the class that has the driver code and that Spark will execute.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">DRIVER_JVM</code> is the memory to assign to driver´s JVM.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">DRIVER_CLASSPATH</code> is the classpath for driver class, jars are separated by colon.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">EXECUTOR_JARS</code> is the classpath to be distributed to executors, jars are separated by comma.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">DRIVER_JAR</code> is the jar that contains the &lt;DRIVER_CLASS&gt; to execute by Spark.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">MOSAIC_CONFIG_PATH</code> is the path to the mosaic configuration XML, which defines the features of the output.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">GDAL_LIBRARIES_PATH</code> is the path where GDAL libraries are located.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">GDAL_DATA_PATH</code> is the path where the GDAL data folder is located. This path must be accessible via NFS to all nodes in the cluster.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">IMAGE_CATALOG_PATH</code> is the path to the catalog xml that lists the HDFS image(s) to be processed. This is optional because you can also specify a single raster to process using &#x2013;file flag.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">SINGLE_RASTER_PATH</code> is an optional path to the .ohif file that will be processed by the job. If this is set, you do not need to set a catalog.
                              </p>
                           </li>
                        </ul>
                        <p>The following example command will process all the files listed in the catalog file <code class="codeph">inputSPARK.xml</code> using the mosaic output definition set in the <code class="codeph">testFS.xml</code> file.
                        </p><pre class="pre codeblock"><code>spark-submit --class oracle.spatial.spark.raster.test.SpatialRasterTest --driver-memory 2048m  --driver-class-path /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-raster-fwk-api.jar:/opt/oracle/oracle-spatial-graph/spatial/raster/jlib/gdal.jar:/opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageloader.jar:/opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageprocessor.jar --jars /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageloader.jar,/opt/oracle/oracle-spatial-graph/spatial/raster/jlib/hadoop-imageprocessor.jar,/opt/oracle/oracle-spatial-graph/spatial/raster/jlib/gdal.jar /opt/oracle/oracle-spatial-graph/spatial/raster/jlib/spark-raster-fwk-api.jar -taskType algebra -catalog /opt/shareddir/spatial/data/xmls/inputSPARK.xml -config /opt/shareddir/spatial/data/xmls/testFS.xml -gdal /opt/oracle/oracle-spatial-graph/spatial/raster/gdal/lib &#x2013;gdalData /opt/shareddir/data</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-F04B19CD-B139-4AF1-BEFA-DA272E8652B6">Spark SQL Raster Processor</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-851AAEF6-5A30-49D7-AB72-157A2C04F8E5" name="GUID-851AAEF6-5A30-49D7-AB72-157A2C04F8E5"></a><h5 id="BDSPA-GUID-851AAEF6-5A30-49D7-AB72-157A2C04F8E5" class="sect5"><span class="enumeration_section">2.8.2.2 </span>Expected Output of the Spark SQL Raster Processor
                     </h5>
                     <div>
                        <p>For Spark processing, only file system output is supported, which means that the output generated is an image with the file name and type specified and is stored in a regular FileSystem.</p>
                        <p>The job execution logs can be accessed using the command <code class="codeph">yarn logs -applicationId &lt;applicationId&gt;</code>.
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-F04B19CD-B139-4AF1-BEFA-DA272E8652B6">Spark SQL Raster Processor</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722" name="GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722"></a><h4 id="BDSPA-GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722" class="sect4"><span class="enumeration_section">2.8.3 </span>Using the Spark Raster Processing API
                  </h4>
                  <div>
                     <p>You can use the Spark raster API to load and process rasters by creating the driver class.</p>
                     <p>Some example classes are provided under <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/src</code>. The <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/cmd</code> directory also contains scripts to execute these examples from command line.
                     </p>
                     <p>After executing the scripts and validated the results, you can modify the Java source files to experiment on them and compile them using the provided script <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/examples/java/build.xml</code>. Ensure that there is write access on the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/raster/jlib</code> directory.
                     </p>
                     <p>For GDAL to work properly, the libraries must be available using $LD_LIBRARY_PATH. Make sure that the shared libraries path is set properly in your shell window before executing a job. For example:</p><pre class="oac_no_warn" dir="ltr">export LD_LIBRARY_PATH=$ALLACCESSDIR/gdal/native</pre></div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-79124F91-AC7C-4E1B-9189-C0B6699F5368">Using the Spark Raster Loader API</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-CEBB55C6-DEC2-4AF4-A90A-E7A8E663894D">Configuring for Using the Spark SQL Processor API</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-11CAAA95-E1DC-4E69-AC93-C15FD9DEA086">Creating the DataFrame</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-9C5DEF8E-7912-4FDF-9C0F-D370DE356367">Using the Spark SQL UDF for Raster Algebra Operations</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8E2FE2C2-7189-4D80-8DFB-16910A50921E" title="Oracle Big Data Spatial Raster Processing for Apache Spark is a spatial raster processing API for Java.">Oracle Big Data Spatial Raster Processing for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-79124F91-AC7C-4E1B-9189-C0B6699F5368" name="GUID-79124F91-AC7C-4E1B-9189-C0B6699F5368"></a><h5 id="BDSPA-GUID-79124F91-AC7C-4E1B-9189-C0B6699F5368" class="sect5"><span class="enumeration_section">2.8.3.1 </span>Using the Spark Raster Loader API
                     </h5>
                     <div>
                        <p>To perform image loading, you must create a <code class="codeph">SpatialRasterLoader</code> object. This object is used to set the necessary configuration information for the execution. There are two ways of creating an instance:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <div class="p">Send as a parameter the array of arguments received from the command line. For example: <pre class="pre codeblock"><code>   //args is the String[] received from command line
   SpatialRasterLoader core = new SpatialRasterLoaderCore(args);
</code></pre></div>
                           </li>
                           <li>
                              <p>Configure directly in the driver class using the API, which is the subject of this topic</p>
                           </li>
                        </ul>
                        <p>Using the Loader API, set the GDAL library path, since it will internally initialize the <code class="codeph">SparkContext</code> and its corresponding Hadoop configuration. For example:
                        </p><pre class="pre codeblock"><code>	SpatialRasterLoader core = new SpatialRasterLoader();
	core.setGdalLibrary("/opt/sharedddir/spatial/gdal");
	core.setFilesToLoad("/opt/shareddir/spatial/rasters");
	core.setHDFSOutputDirectory("ohifsparktest");	
	core.setGdalData("/opt/shareddir/data");
	core.setOverlap("20");
	core.setThumbnailDirectory("/opt/shareddir/spatial/");
</code></pre><p>You can optionally change the block size, depending on the most common size of rasters involved. For example, if the cluster HDFS block size is by default too big (such as 256 MB) and the average size of the user rasters is 64 MB in average, you should avoid using HDFS space that contains no real data, because every tile occupies a block in HDFS even if the pixels do not fill it. In this scenario, you can change the block side to 64 MB, as in this example:</p><pre class="pre codeblock"><code>	JavaSparkContext sc = core.getRasterSparkContext();
	core.getHadoopConfiguration().set("dfs.blocksize", "67108864");
</code></pre><p>To execute the loader, use the <code class="codeph">loadRasters</code> method, which returns <code class="codeph">true</code> if rasters were loaded with success and <code class="codeph">false</code> otherwise. For example:
                        </p><pre class="pre codeblock"><code>        if (core.loadRasters(sc, StorageLevel.DISK_ONLY())) {
        	LOG.info("Successfully loaded raster files");
        }
</code></pre><p>If the processing finished successfully, the OHIF files are in HDFS and the corresponding thumbnails are in the specified directory for user validation.</p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722">Using the Spark Raster Processing API</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-CEBB55C6-DEC2-4AF4-A90A-E7A8E663894D" name="GUID-CEBB55C6-DEC2-4AF4-A90A-E7A8E663894D"></a><h5 id="BDSPA-GUID-CEBB55C6-DEC2-4AF4-A90A-E7A8E663894D" class="sect5"><span class="enumeration_section">2.8.3.2 </span>Configuring for Using the Spark SQL Processor API
                     </h5>
                     <div>
                        <p>To execute a processor, you must create a <code class="codeph">SpatialRasterProcessor</code> object to set the necessary configuration information for the execution. There are two ways to create an instance: 
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Send as a parameter the array of arguments received from the command line. For example:</p><pre class="pre codeblock"><code>//args is the String[] received from command line
SpatialRasterProcessor processor = new SpatialRasterProcessor(args);</code></pre></li>
                           <li>
                              <p>Configure directly in the driver class using the API, which is the subject of this topic.</p>
                           </li>
                        </ul>
                        <p>Using the Loader API, set the GDAL library path, because it will internally initialize the <code class="codeph">SparkContext</code> and its corresponding Hadoop configuration. For example:
                        </p><pre class="pre codeblock"><code>SpatialRasterProcessor processor = new SpatialRasterProcessor();
processor.setGdalLibrary("/opt/sharedddir/spatial/gdal");
processor.setGdalData("/opt/sharedddir/spatial/data");
</code></pre><p>Specify the rasters that will be processed.</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>For adding a catalog of rasters to process, especially if a mosaic operation will be performed, consider the following example:</p><pre class="pre codeblock"><code>String ohifPath = "ohifsparktest/opt/shareddir/spatial/data/rasters");
//Creates a catalog to list the rasters to process
RasterCatalog catalog = new RasterCatalog();

//Creates a raster object for the catalog
Raster raster = new Raster();
//raster of 3 bands
raster.setBands(3);
//the tree bands will appear in order 1,2,3. You may list less bands here.
raster.setBandsOrder("1,2,3");
//raster data type is byte
raster.setDataType(1);

raster.setRasterLocation(ohifPath + "hawaii.tif.ohif");
//Add raster to catalog
//catalog.addRasterToCatalog(raster);

Raster rasterKahoolawe = new Raster();
rasterKahoolawe.setBands(3);
rasterKahoolawe.setBandsOrder("1,2,3");
rasterKahoolawe.setDataType(1);
rasterKahoolawe.setRasterLocation(ohifPath + "kahoolawe.tif.ohif");
catalog.addRasterToCatalog(rasterKahoolawe);

//Sets the catalog to the job
processor.setCatalogObject(catalog.getCompactCatalog());
</code></pre></li>
                           <li>
                              <p>For processing a single raster, consider the following example: </p><pre class="pre codeblock"><code>String ohifPath = "ohifsparktest/opt/shareddir/spatial/data/rasters");
//Set the file to process to the job
processor.setFileToProcess(ohifPath + "NapaDEM.tif.ohif");*/
</code></pre></li>
                        </ul>
                        <p>Set the user configuration request, which  defines details for the output raster.</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>If a mosaic operation will be performed, then all the features of the expected output must be set in a MosaicConfiguration object, including the coordinates. the following example creates a raster that includes both Hawaii rasters added to the catalog previously: </p><pre class="pre codeblock"><code>MosaicConfiguration mosaic = new MosaicConfiguration();
mosaic.setFormat("GTIFF");
mosaic.setBands(3);
mosaic.setFileSystem(RasterProcessorJob.FS);
mosaic.setDirectory("/opt/shareddir/spatial/processtest");
mosaic.setFileName("HawaiiIslands");
mosaic.setHeight(986);
//value for pixels where there is no data, starts with #, followed by 
//two characters per band
mosaic.setNoData("#FFFFFF");
//byte datatype
mosaic.setPixelType("1");
//width for pixels in X and Y
mosaic.setPixelXWidth(280.388143);
mosaic.setPixelYWidth(-280.388143);
mosaic.setSrid("26904");
//upper left coordinates
mosaic.setUpperLeftX(556958.985610);
mosaic.setUpperLeftY(2350324.082505);
mosaic.setWidth(1600);
mosaic.setOrderAlgorithm(ProcessConstants.ALGORITHM_FILE_LENGTH);
mosaic.setOrder(RasterProcessorJob.DESC);
//mosaic configuration must be set to the job
processor.setUserRequestConfigurationObject(mosaic.getCompactMosaic());
</code></pre></li>
                           <li>
                              <p>If a mosaic operation will not be performed, then a much simpler configuration is required. For example:</p><pre class="pre codeblock"><code>MosaicConfiguration mosaic = new MosaicConfiguration();
mosaic.setExecuteMosaic(false);
mosaic.setBands(1);
mosaic.setLayers("1");
mosaic.setDirectory("/opt/shareddir/spatial/processtest");
mosaic.setFileSystem(RasterProcessorJob.FS);
mosaic.setNoData("#00");
</code></pre></li>
                        </ul>
                        <p>At this point, all required configuration is done. You can now start processing.</p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722">Using the Spark Raster Processing API</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-11CAAA95-E1DC-4E69-AC93-C15FD9DEA086" name="GUID-11CAAA95-E1DC-4E69-AC93-C15FD9DEA086"></a><h5 id="BDSPA-GUID-11CAAA95-E1DC-4E69-AC93-C15FD9DEA086" class="sect5"><span class="enumeration_section">2.8.3.3 </span>Creating the DataFrame
                     </h5>
                     <div>
                        <p>Before running queries against the rasters, you must load them into a DataFrame where every row represents a split. The splits are created into a <code class="codeph">SpatialJavaRDD</code> of tiles, which are then converted to a DataFrame. Depending on your available JVM runtime memory, it is recommended that you cache the DataFrame in memory or on disk. For disk caching, your Spark installation must have Kryo.
                        </p>
                        <p>The DataFrame consists of two complex columns: <code class="codeph">tileInfo</code> and <code class="codeph">userRequest</code>.
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">tileInfo</code>: Data for every tile, including not only pixel information but also metadata details. 
                              </p>
                              <div class="tblformal" id="GUID-11CAAA95-E1DC-4E69-AC93-C15FD9DEA086__GUID-F81771E7-DF85-4A85-B4B3-39A5B207D6DE">
                                 <p class="titleintable">Table 2-2 tileInfo Column Data</p>
                                 <table cellpadding="4" cellspacing="0" class="Formal" title="tileInfo Column Data" summary="Data for every tile in the DataFrame. For each “row” of data, contains the column name, the data type, whether it is nullable (can be null), and a short description." frame="hsides" border="1" rules="rows">
                                    <thead>
                                       <tr align="left" valign="top">
                                          <th align="left" valign="bottom" width="20%" id="d8066e5004">Column </th>
                                          <th align="left" valign="bottom" width="20%" id="d8066e5009">DataType </th>
                                          <th align="left" valign="bottom" width="20%" id="d8066e5014">Nullable </th>
                                          <th align="left" valign="bottom" width="20%" id="d8066e5019">Description </th>
                                       </tr>
                                    </thead>
                                    <tbody>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5026" headers="d8066e5004 ">
                                             <p>dstWidthSize</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5026 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5026 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5026 d8066e5019 ">
                                             <p>Width</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5039" headers="d8066e5004 ">
                                             <p>dstHeightSize</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5039 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5039 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5039 d8066e5019 ">
                                             <p>Height</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5052" headers="d8066e5004 ">
                                             <p>bands</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5052 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5052 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5052 d8066e5019 ">
                                             <p>Number of bands</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5065" headers="d8066e5004 ">
                                             <p>dType</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5065 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5065 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5065 d8066e5019 ">
                                             <p>Data type</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5078" headers="d8066e5004 ">
                                             <p>piece</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5078 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5078 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5078 d8066e5019 ">
                                             <p>Piece number of total pieces in source raster</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5091" headers="d8066e5004 ">
                                             <p>offX</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5091 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5091 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5091 d8066e5019 ">
                                             <p>Offset in X</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5104" headers="d8066e5004 ">
                                             <p>offY</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5104 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5104 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5104 d8066e5019 ">
                                             <p>Offset in Y</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5117" headers="d8066e5004 ">
                                             <p>sourceWidth</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5117 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5117 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5117 d8066e5019 ">
                                             <p>Source raster width</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5130" headers="d8066e5004 ">
                                             <p>sourceHeight</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5130 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5130 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5130 d8066e5019 ">
                                             <p>Source raster height</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5143" headers="d8066e5004 ">
                                             <p>bytesNumber</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5143 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5143 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5143 d8066e5019 ">
                                             <p>Number of bytes</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5156" headers="d8066e5004 ">
                                             <p>baseArray</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5156 d8066e5009 ">
                                             <p>[[Pixel DataType]]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5156 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5156 d8066e5019 ">
                                             <p>Array of pixels, one per band</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5170" headers="d8066e5004 ">
                                             <p>basePaletteArray</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5170 d8066e5009 ">
                                             <p>[[Integer]]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5170 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5170 d8066e5019 ">
                                             <p>Array of palette interpretation, if the raster has it, one per band</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5183" headers="d8066e5004 ">
                                             <p>baseColorArray</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5183 d8066e5009 ">
                                             <p>[Integer]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5183 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5183 d8066e5019 ">
                                             <p>Array of colors, one per band</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5196" headers="d8066e5004 ">
                                             <p>noDataArray</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5196 d8066e5009 ">
                                             <p>[Double]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5196 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5196 d8066e5019 ">
                                             <p>Array of NODATA value, one per band</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5209" headers="d8066e5004 ">
                                             <p>Overlap</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5209 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5209 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5209 d8066e5019 ">
                                             <p>Number of overlapping pixels</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5222" headers="d8066e5004 ">
                                             <p>leftOv</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5222 d8066e5009 ">
                                             <p>Byte</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5222 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5222 d8066e5019 ">
                                             <p>Flag to indicate if there are any overlapping pixels on the left</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5235" headers="d8066e5004 ">
                                             <p>rightOv</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5235 d8066e5009 ">
                                             <p>Byte</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5235 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5235 d8066e5019 ">
                                             <p>Flag to indicate if there are any overlapping pixels on the right</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5248" headers="d8066e5004 ">
                                             <p>upOv</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5248 d8066e5009 ">
                                             <p>Byte</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5248 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5248 d8066e5019 ">
                                             <p>Flag to indicate if there are any overlapping pixels on the top</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5261" headers="d8066e5004 ">
                                             <p>downOv</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5261 d8066e5009 ">
                                             <p>Byte</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5261 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5261 d8066e5019 ">
                                             <p>Flag to indicate if there are any overlapping pixels on the bottom</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5274" headers="d8066e5004 ">
                                             <p>projectionRef</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5274 d8066e5009 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5274 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5274 d8066e5019 ">
                                             <p>Projection reference</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5287" headers="d8066e5004 ">
                                             <p>geoTransform</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5287 d8066e5009 ">
                                             <p>[Double]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5287 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5287 d8066e5019 ">
                                             <p>Geo Transformation array</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5300" headers="d8066e5004 ">
                                             <p>Metadata</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5300 d8066e5009 ">
                                             <p>[String]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5300 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5300 d8066e5019 ">
                                             <p>Location metadata</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5314" headers="d8066e5004 ">
                                             <p>lastModified</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5314 d8066e5009 ">
                                             <p>Long</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5314 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5314 d8066e5019 ">
                                             <p>Source raster last modification date</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5327" headers="d8066e5004 ">
                                             <p>imageLength</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5327 d8066e5009 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5327 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5327 d8066e5019 ">
                                             <p>Source raster length</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5340" headers="d8066e5004 ">
                                             <p>dataLength</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5340 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5340 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5340 d8066e5019 ">
                                             <p>Number of bytes after mosaic</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5353" headers="d8066e5004 ">
                                             <p>xCropInit</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5353 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5353 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5353 d8066e5019 ">
                                             <p>Pixel start in X after mosaic</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5366" headers="d8066e5004 ">
                                             <p>yCropInit</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5366 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5366 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5366 d8066e5019 ">
                                             <p>Pixel start in Y after mosaic</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5379" headers="d8066e5004 ">
                                             <p>xCropLast</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5379 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5379 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5379 d8066e5019 ">
                                             <p>Pixel end in X after mosaic</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5392" headers="d8066e5004 ">
                                             <p>yCropLast</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5392 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5392 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5392 d8066e5019 ">
                                             <p>Pixel end in Y after mosaic</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5405" headers="d8066e5004 ">
                                             <p>catalogOrder</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5405 d8066e5009 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5405 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5405 d8066e5019 ">
                                             <p>Order in the catalog</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5418" headers="d8066e5004 ">
                                             <p>baseMountPoint</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5418 d8066e5009 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5418 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5418 d8066e5019 ">
                                             <p>Source raster path</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5431" headers="d8066e5004 ">
                                             <p>sourceResolution</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5431 d8066e5009 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5431 d8066e5014 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5431 d8066e5019 ">
                                             <p>Source raster resolution</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5444" headers="d8066e5004 ">
                                             <p>extraFields</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5444 d8066e5009 ">
                                             <p>[String]</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5444 d8066e5014 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5444 d8066e5019 ">
                                             <p>Extra fields map, NA</p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                              <!-- class="inftblhruleinformal" -->
                           </li>
                           <li>
                              <p><code class="codeph">userRequest</code>: User request configuration, where expected output raster features are defined.
                              </p>
                              <div class="tblformal" id="GUID-11CAAA95-E1DC-4E69-AC93-C15FD9DEA086__GUID-8658D245-0B50-4DE6-A039-12FA50F16212">
                                 <p class="titleintable">Table 2-3 userRequest Column Data</p>
                                 <table cellpadding="4" cellspacing="0" class="Formal" title="userRequest Column Data" summary="Data for the user request configuration. For each “row” of data, contains the column name, the data type, whether it is nullable (can be null), and a short description." frame="hsides" border="1" rules="rows">
                                    <thead>
                                       <tr align="left" valign="top">
                                          <th align="left" valign="bottom" width="20%" id="d8066e5473">Column </th>
                                          <th align="left" valign="bottom" width="20%" id="d8066e5478">DataType </th>
                                          <th align="left" valign="bottom" width="20%" id="d8066e5483">Nullable </th>
                                          <th align="left" valign="bottom" width="20%" id="d8066e5488">Description </th>
                                       </tr>
                                    </thead>
                                    <tbody>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5495" headers="d8066e5473 ">
                                             <p>offset</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5495 d8066e5478 ">
                                             <p>Long</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5495 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5495 d8066e5488 ">
                                             <p>Offset</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5508" headers="d8066e5473 ">
                                             <p>piece</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5508 d8066e5478 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5508 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5508 d8066e5488 ">
                                             <p>Piece number</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5521" headers="d8066e5473 ">
                                             <p>splitSize</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5521 d8066e5478 ">
                                             <p>Long</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5521 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5521 d8066e5488 ">
                                             <p>Split size</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5534" headers="d8066e5473 ">
                                             <p>bandsToAdd </p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5534 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5534 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5534 d8066e5488 ">
                                             <p>Bands to include in output i.e. “1,2,3”</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5547" headers="d8066e5473 ">
                                             <p>upperLeftX</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5547 d8066e5478 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5547 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5547 d8066e5488 ">
                                             <p>Coordinate of output in X upper left, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5560" headers="d8066e5473 ">
                                             <p>upperLeftY</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5560 d8066e5478 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5560 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5560 d8066e5488 ">
                                             <p>Coordinate of output in Y upper left, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5573" headers="d8066e5473 ">
                                             <p>lowerRightX</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5573 d8066e5478 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5573 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5573 d8066e5488 ">
                                             <p>Coordinate of output in X lower right, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5586" headers="d8066e5473 ">
                                             <p>lowerRightY</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5586 d8066e5478 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5586 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5586 d8066e5488 ">
                                             <p>Coordinate of output in Y lower right, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5599" headers="d8066e5473 ">
                                             <p>width</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5599 d8066e5478 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5599 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5599 d8066e5488 ">
                                             <p>Output width, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5612" headers="d8066e5473 ">
                                             <p>height</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5612 d8066e5478 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5612 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5612 d8066e5488 ">
                                             <p>Output height, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5625" headers="d8066e5473 ">
                                             <p>srid</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5625 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5625 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5625 d8066e5488 ">
                                             <p>Output SRID, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5639" headers="d8066e5473 ">
                                             <p>order</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5639 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5639 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5639 d8066e5488 ">
                                             <p>Output order , Ascendant or Descendant, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5652" headers="d8066e5473 ">
                                             <p>format</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5652 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5652 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5652 d8066e5488 ">
                                             <p>Output GDALformat, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5665" headers="d8066e5473 ">
                                             <p>noData</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5665 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5665 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5665 d8066e5488 ">
                                             <p>Output  NODATA value, a # followed by two digits per band, i.e. for  3 band output “#000000”</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5678" headers="d8066e5473 ">
                                             <p>pixelType</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5678 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5678 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5678 d8066e5488 ">
                                             <p>Output GDAL Data type, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5691" headers="d8066e5473 ">
                                             <p>Directory</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5691 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5691 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5691 d8066e5488 ">
                                             <p>Output directory</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5704" headers="d8066e5473 ">
                                             <p>pixelXWidth</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5704 d8066e5478 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5704 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5704 d8066e5488 ">
                                             <p>Output pixel width, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5717" headers="d8066e5473 ">
                                             <p>pixelYWidth</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5717 d8066e5478 ">
                                             <p>Double</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5717 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5717 d8066e5488 ">
                                             <p>Output pixel height, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5730" headers="d8066e5473 ">
                                             <p>wkt</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5730 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5730 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5730 d8066e5488 ">
                                             <p>Source projection reference</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5743" headers="d8066e5473 ">
                                             <p>mosaicWkt</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5743 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5743 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5743 d8066e5488 ">
                                             <p>Output projection reference, used when mosaic is requested</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5756" headers="d8066e5473 ">
                                             <p>processingClasses</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5756 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5756 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5756 d8066e5488 ">
                                             <p>User processing classes to execute, still not supported in Spark</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5769" headers="d8066e5473 ">
                                             <p>reducingClasses</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5769 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5769 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5769 d8066e5488 ">
                                             <p>User reducing classes to execute, still not supported in Spark</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5783" headers="d8066e5473 ">
                                             <p>tempOut</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5783 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5783 d8066e5483 ">
                                             <p>True</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5783 d8066e5488 ">
                                             <p>Temporary output folder when HDFS output is requested, still not supported in Spark</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5796" headers="d8066e5473 ">
                                             <p>filename</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5796 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5796 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5796 d8066e5488 ">
                                             <p>Output filename</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5809" headers="d8066e5473 ">
                                             <p>contextId</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5809 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5809 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5809 d8066e5488 ">
                                             <p>Execution context Id</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5822" headers="d8066e5473 ">
                                             <p>sourceResolution</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5822 d8066e5478 ">
                                             <p>String</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5822 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5822 d8066e5488 ">
                                             <p>Source raster resolution</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5835" headers="d8066e5473 ">
                                             <p>catalogOrder</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5835 d8066e5478 ">
                                             <p>Integer</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5835 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5835 d8066e5488 ">
                                             <p>Source raster order in catalog</p>
                                          </td>
                                       </tr>
                                       <tr align="left" valign="top">
                                          <td rowspan="1" colspan="1" align="left" valign="top" id="d8066e5848" headers="d8066e5473 ">
                                             <p>executeMosaic</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5848 d8066e5478 ">
                                             <p>Boolean</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5848 d8066e5483 ">
                                             <p>False</p>
                                          </td>
                                          <td rowspan="1" colspan="1" align="left" valign="top" headers="d8066e5848 d8066e5488 ">
                                             <p>Flag to indicate if mosaic operation is requested or not</p>
                                          </td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                              <!-- class="inftblhruleinformal" -->
                           </li>
                        </ul>
                        <p>The following example creates a DataFrame and displays information about it: </p><pre class="pre codeblock"><code>JavaSparkContext sc = processor.getRasterSparkContext();
SpatialRasterJavaRDD&lt;GeneralInfoWritable&gt; spatialRDD = processor.getProcessSplits();
HiveContext sqlContext = new HiveContext(sc.sc());
DataFrame tileRows = spatialRDD.createSpatialTileDataFrame(sqlContext, StorageLevel.DISK_ONLY());

Row[] rows = tileRows.collect();
System.out.println("First Tile info: ");
System.out.println("Width " + rows[0].getStruct(0).getInt(0));
System.out.println("Height " + rows[0].getStruct(0).getInt(1));
System.out.println("Total width " + rows[0].getStruct(0).getInt(7));
System.out.println("Total height " + rows[0].getStruct(0).getInt(8));
System.out.println("File " + rows[0].getStruct(0).getString(30));

System.out.println("First Tile User request data: ");

System.out.println("Bands to add " + rows[0].getStruct(1).getString(3));</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722">Using the Spark Raster Processing API</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-9C5DEF8E-7912-4FDF-9C0F-D370DE356367" name="GUID-9C5DEF8E-7912-4FDF-9C0F-D370DE356367"></a><h5 id="BDSPA-GUID-9C5DEF8E-7912-4FDF-9C0F-D370DE356367" class="sect5"><span class="enumeration_section">2.8.3.4 </span>Using the Spark SQL UDF for Raster Algebra Operations
                     </h5>
                     <div>
                        <p>A Spark UDF <code class="codeph">localop</code> allows the execution of the raster algebra operations described in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-2B9F7E81-4FAD-435F-A266-3101AD9E3668">Map Algebra Operations</a> for processing images using the Hadoop image processor. The operation names and supported data types for the Spark SQL UDF are the same as for Hadoop
                        </p>
                        <p>Before any query is executed, the driver class must register the UDF and must register the tiles' DataFrame as a temporary table. For example:</p><pre class="pre codeblock"><code>sqlContext.udf().register("localop", new LocalOperationsFunction(), 
              DataTypes.createStructType(SpatialRasterJavaRDD.createSimpleTileStructField(dataTypeOfTileToProcess)));
tileRows.registerTempTable("tiles");
</code></pre><p>Now that localop UDF is registered, it is ready to be used. This function accepts two parameters:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>A <code class="codeph">tileInfo</code> row
                              </p>
                           </li>
                           <li>
                              <p>A string with the raster algebra operations to execute. Multiple operations may be executed in the same query, and they must be separated by a semicolon. For operations that receive parameters, they must be separated by commas.</p>
                           </li>
                        </ul>
                        <p>The function returns the <code class="codeph">tileInfo</code> that was sent to query, but with the pixel data updated based on the executed operations.
                        </p>
                        <p>Following are some examples for the execution of different operations.</p><pre class="pre codeblock"><code>String query = "SELECT localop(tileInfo, \"localnot\"),
                       userRequest FROM tiles";

String query = "SELECT localop(tileInfo,\"localadd,456;localdivide,2;
                                     localif,&gt;,0,12;localmultiply,20;
                                     localpow,2;localsubstract,4;
                                     localsqrt;localacos\"), 
                                     userRequest FROM tiles";
String query = "SELECT localop(tileInfo,\"localnot;localatan;localcos;
                                     localasin;localtan;localcosh;
                                     localtanh\"), userRequest FROM tiles";
</code></pre><p>To execute the query, enter the following: </p><pre class="pre codeblock"><code>DataFrame cachedTiles = processor.queryAndCache(query, sqlContext);</code></pre><p>This new DataFrame has the updated pixels. You can optionally save the content of a specific tile as a TIF file, in which it will be stored in the configured output directory. For example:</p><pre class="pre codeblock"><code>Row[] pRows = cachedTiles.collect();
processor.debugTileBySavingTif(pRows[0], 
                               processor.getHadoopConfiguration());
</code></pre><p>To execute the mosaic operation, first perform any raster algebra processing, and then perform the mosaic operation. A new Spark UDF is used for the mosaic operation; it receives the <code class="codeph">tileInfo</code> and <code class="codeph">userRequest</code> columns, and returns the updated <code class="codeph">tileInfo</code> that fits in the mosaic. For example:
                        </p><pre class="pre codeblock"><code>sqlContext.udf().register("mosaic", new MosaicFunction(),
              DataTypes.createStructType(SpatialRasterJavaRDD.createSimpleTileStructField(dataTypeOfTileToProcess)));
cachedTiles.registerTempTable("processedTiles");
String queryMosaic = "SELECT mosaic(tileInfo, userRequest), userRequest 
                             FROM processedTiles";
DataFrame mosaicTiles = processor.queryAndCache(queryMosaic,  
                                                sqlContext);
</code></pre><p>After the processing is done, you can put together the tiles into the output raster by using <code class="codeph">ProcessedRasterCreator</code>, which receives a temporary HDFS directory for internal work, the DataFrame to merge, and the Spark Context from the Hadoop configuration. This will create the expected output raster in the specified output directory. For example:
                        </p><pre class="pre codeblock"><code>try {
		ProcessedRasterCreator creator = new ProcessedRasterCreator();
     creator.create(new Text("createOutput"), mosaicTiles, 
                    sc.hadoopConfiguration());
     LOG.info("Finished");
} catch (Exception e) {
            LOG.error("Failed processor job due to " + e.getMessage());
            throw e;
     }

</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-F1C6A006-72E7-4098-B6BF-D44DF8693722">Using the Spark Raster Processing API</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
            </div><a id="BDSPA170"></a><div class="props_rev_3"><a id="GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" name="GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3"></a><h3 id="BDSPA-GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" class="sect3"><span class="enumeration_section">2.9 </span>Oracle Big Data Spatial Vector Analysis
               </h3>
               <div>
                  <p>Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.</p>
                  <p>These components make use of the Spatial Java API to perform spatial analysis tasks. There is a web console provided along with the API.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-52F24F14-A7FE-4199-AA46-2F5756B375B2">Multiple Hadoop API Support</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-78AD7453-D7ED-48F9-A531-E93353B8F800">Using MVSuggest</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C">Spatial Filtering</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292">Classifying Data Hierarchically</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8D22891E-F2C4-4D9F-81C3-ABAA9F520AA9">Generating Buffers</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C86524DB-A0C1-4A40-B4AC-DAA90D77A0F4">Spatial Binning</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-4F1ED8BC-E62B-4356-A31E-8C5FC1442922">Spatial Clustering</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-87C0B23C-C3D8-4317-863D-AC2AA9511306">Spatial Join</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C127F600-72AD-4430-841A-1BB63EB2D942">Spatial Partitioning</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C73176F7-86C7-4743-95A7-56FCB919CF04">RecordInfoProvider</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-737CAF49-D97B-47ED-BA5D-B10E1E0F82BF">HierarchyInfo</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-400F3157-36A6-4C7E-B2CB-A870DCC1E123">Using JGeometry in MapReduce Jobs</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-4FDCF66B-0136-418A-B072-E400E9844B55">Support for Different Data Sources</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A25B2252-63BF-4656-A2EB-F0A3DA0982E2">Job Registry</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-6718ACA8-E625-4A03-8895-1452402FBE1F">Tuning Performance Data of Job Running Times Using the Vector Analysis API</a><br></li>
                  </ul>
                  <div class="infoboxnotealso" id="GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3__GUID-E2E04086-F291-4EEE-B276-39B30C8092E5">
                     <p class="notep1">See Also:</p>
                     <p>See the following topics for understanding the implementation details:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C73176F7-86C7-4743-95A7-56FCB919CF04">RecordInfoProvider</a></p>
                        </li>
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-737CAF49-D97B-47ED-BA5D-B10E1E0F82BF">HierarchyInfo</a></p>
                        </li>
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-400F3157-36A6-4C7E-B2CB-A870DCC1E123">Using JGeometry in MapReduce Jobs</a></p>
                        </li>
                        <li>
                           <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-6718ACA8-E625-4A03-8895-1452402FBE1F">Tuning Performance Data of Job Running Times Using the Vector Analysis API</a></p>
                        </li>
                     </ul>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="props_rev_3"><a id="GUID-52F24F14-A7FE-4199-AA46-2F5756B375B2" name="GUID-52F24F14-A7FE-4199-AA46-2F5756B375B2"></a><h4 id="BDSPA-GUID-52F24F14-A7FE-4199-AA46-2F5756B375B2" class="sect4"><span class="enumeration_section">2.9.1 </span>Multiple Hadoop API Support
                  </h4>
                  <div>
                     <p>Oracle Big Data Spatial Vector Analysis provides classes for both the old and new (context objects) Hadoop APIs. In general, classes in the <code class="codeph">mapred</code> package are used with the old API, while classes in the <code class="codeph">mapreduce</code> package are used with the new API
                     </p>
                     <p>The examples in this guide use the old Hadoop API; however, all the old Hadoop Vector API classes have equivalent classes in the new API. For example, the old class <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapred</span>.job.SpatialIndexing</code> has the equivalent new class named <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.SpatialIndexing</code>. In general, and unless stated otherwise, only the change from <code class="codeph">mapred</code> to <code class="codeph">mapreduce</code> is needed to use the new Hadoop API Vector classes.
                     </p>
                     <p>Classes such as <code class="codeph">oracle.spatial.hadoop.vector.RecordInfo</code>, which are not in the mapred or mapreduce package, are compatible with both Hadoop APIs.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA171"></a><div class="props_rev_3"><a id="GUID-50C85114-78F7-40FE-A633-54E3352724DE" name="GUID-50C85114-78F7-40FE-A633-54E3352724DE"></a><h4 id="BDSPA-GUID-50C85114-78F7-40FE-A633-54E3352724DE" class="sect4"><span class="enumeration_section">2.9.2 </span>Spatial Indexing
                  </h4>
                  <div>
                     <p>A spatial index is in the form of a key/value pair and generated as a Hadoop MapFile. Each MapFile entry contains a spatial index for one split of the original data. The key and value pair contains the following information:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Key: a split identifier in the form: path + start offset + length.</p>
                        </li>
                        <li>
                           <p>Value: a spatial index structure containing the actual indexed records.</p>
                        </li>
                     </ul>
                     <p>The following figure depicts a spatial index in relation to the user data. The records are represented as r1, r2, and so on. The records are grouped into splits (Split 1, Split 2, Split 3, Split n). Each split has a Key-Value pair where the key identifies the split and the value identifies an Rtree index on the records in that split.</p>
                     <div class="figure" id="GUID-50C85114-78F7-40FE-A633-54E3352724DE__GUID-4E0872DF-E114-4C53-8C5B-788EF64ECDEC"><img src="img/spatial_index_rep.png" height="215" width="521" alt="Description of spatial_index_rep.png follows" title="Description of spatial_index_rep.png follows" longdesc="img_text/spatial_index_rep.html"><br><a href="img_text/spatial_index_rep.html">Description of the illustration spatial_index_rep.png</a></div>
                     <!-- class="figure" -->
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-76C29D55-F043-407D-9402-FF9DBF94BDB8">Spatial Indexing Class Structure</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-3B981CF4-BF32-436D-A69B-0969D4208F42">Configuration for Creating a Spatial Index</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-7C7624BB-80C7-4BFE-AC79-0B3FC0F40C39">Spatial Index Metadata</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C5509E8F-5F1E-4DCC-BB0A-9F7761EE3B06">Input Formats for a Spatial Index</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-00585288-5F2A-44AF-A8FD-48AE62800EAB">Support for GeoJSON and Shapefile Formats</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A5C717A7-5584-4878-8E24-DC0F43C36E37">Removing a Spatial Index</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA172"></a><div class="props_rev_3"><a id="GUID-76C29D55-F043-407D-9402-FF9DBF94BDB8" name="GUID-76C29D55-F043-407D-9402-FF9DBF94BDB8"></a><h5 id="BDSPA-GUID-76C29D55-F043-407D-9402-FF9DBF94BDB8" class="sect5"><span class="enumeration_section">2.9.2.1 </span>Spatial Indexing Class Structure
                     </h5>
                     <div>
                        <p>Records in a spatial index are represented using the class <code class="codeph">oracle.spatial.hadoop.vector.RecordInfo</code>. A <code class="codeph">RecordInfo</code> typically contains a subset of the original record data and a way to locate the record in the file where it is stored. The specific <code class="codeph">RecordInfo</code> data depends on two things:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">InputFormat</code> used to read the data
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">RecordInfoProvider</code> implementation, which provides the record's data
                              </p>
                           </li>
                        </ul>
                        <p>The fields contained within a <code class="codeph">RecordInfo</code>:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Id: Text field with the record Id.</p>
                           </li>
                           <li>
                              <p>Geometry: <code class="codeph">JGeometry</code> field with the record geometry.
                              </p>
                           </li>
                           <li>
                              <p>Extra fields: Additional optional fields of the record can be added as name-value pairs. The values are always represented as text.</p>
                           </li>
                           <li>
                              <p>Start offset: The position of the record in a file as a byte offset. This value depends on the <code class="codeph">InputFormat</code> used to read the original data.
                              </p>
                           </li>
                           <li>
                              <p>Length: The original record length in bytes.</p>
                           </li>
                           <li>
                              <p>Path: The file path can be added optionally. This is optional because the file path can be known using the spatial index entry key. However, to add the path to the <code class="codeph">RecordInfo</code> instances when a spatial index is created, the value of the configuration property <code class="codeph">oracle.spatial.recordInfo.includePathField</code> key is set to <code class="codeph">true</code>.
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="BDSPA432"></a><div class="props_rev_3"><a id="GUID-3B981CF4-BF32-436D-A69B-0969D4208F42" name="GUID-3B981CF4-BF32-436D-A69B-0969D4208F42"></a><h5 id="BDSPA-GUID-3B981CF4-BF32-436D-A69B-0969D4208F42" class="sect5"><span class="enumeration_section">2.9.2.2 </span>Configuration for Creating a Spatial Index
                     </h5>
                     <div>
                        <p>A spatial index is created using a combination of <code class="codeph">FileSplitInputFormat</code>, <code class="codeph">SpatialIndexingMapper</code>, <code class="codeph">InputFormat</code>, and <code class="codeph">RecordInfoProvider</code>, where the last two are provided by the user. The following code example shows part of the configuration needed to run a job that creates a spatial index for the data located in the HDFS folder <code class="codeph">/user/data</code>.
                        </p><pre class="oac_no_warn" dir="ltr">//input
 
conf.setInputFormat(FileSplitInputFormat.class);
FileSplitInputFormat.setInputPaths(conf, new Path("/user/data"));
FileSplitInputFormat.setInternalInputFormatClass(conf, GeoJsonInputFormat.class);
FileSplitInputFormat.setRecordInfoProviderClass(conf, GeoJsonRecordInfoProvider.class);

//output
 
conf.setOutputFormat(MapFileOutputFormat.class);
FileOutputFormat.setOutputPath(conf, new Path("/user/data_spatial_index"));
 
//mapper
 
conf.setMapperClass(SpatialIndexingMapper.class); 
conf.setOutputKeyClass(Text.class);
conf.setOutputValueClass(RTreeWritable.class);
</pre><p>In this example, </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The <code class="codeph">FileSplitInputFormat</code> is set as the job <code class="codeph">InputFormat</code>. <code class="codeph">FileSplitInputFormat</code> is a subclass of <code class="codeph">CompositeInputFormat</code> (<code class="codeph">WrapperInputFormat</code> in the new Hadoop API version), an abstract class that uses another <code class="codeph">InputFormat</code> implementation (<code class="codeph">internalInputFormat</code>) to read the data. The internal <code class="codeph">InputFormat</code> and the <code class="codeph">RecordInfoProvider</code> implementations are specified by the user and they are set to <code class="codeph">GeoJsonInputFormat</code> and <code class="codeph">GeoJsonRecordInfoProvider</code>, respectively.
                              </p>
                           </li>
                           <li>
                              <p>The <code class="codeph">MapFileOutputFormat</code> is set as the <code class="codeph">OutputFormat</code> in order to generate a <code class="codeph">MapFile</code></p>
                           </li>
                           <li>
                              <p>The mapper is set to <code class="codeph">SpatialIndexingMappper</code>. The mapper output key and value types are <code class="codeph">Text</code> (splits identifiers) and <code class="codeph">RTreeWritable</code> (the actual spatial indexes).
                              </p>
                           </li>
                           <li>
                              <p>No reducer class is specified so it runs with the default reducer. The reduce phase is needed to sort the output MapFile keys.</p>
                           </li>
                        </ul>
                        <p>Alternatively, this configuration can be set easier by using the <code class="codeph">oracle.spatial.hadoop.vector.mapred.job.SpatialIndexing</code> class. <code class="codeph">SpatialIndexing</code> is a job driver that creates a spatial index. In the following example, a <code class="codeph">SpatialIndexing</code> instance is created, set up, and used to add the settings to the job configuration by calling the <code class="codeph">configure()</code> method. Once the configuration has been set, the job is launched.
                        </p><pre class="oac_no_warn" dir="ltr">SpatialIndexing&lt;LongWritable, Text&gt; spatialIndexing = new SpatialIndexing&lt;LongWritable, Text&gt;();
 
//path to input data
 
spatialIndexing.setInput("/user/data");
 
//path of the spatial index to be generated
 
spatialIndexing.setOutput("/user/data_spatial_index");
 
//input format used to read the data
 
spatialIndexing.setInputFormatClass(TextInputFormat.class);
 
//record info provider used to extract records information
 
spatialIndexing.setRecordInfoProviderClass(TwitterLogRecordInfoProvider.class);
 
//add the spatial indexing configuration to the job configuration
 
spatialIndexing.configure(jobConf);
 
//run the job
 
JobClient.runJob(jobConf);</pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-7C7624BB-80C7-4BFE-AC79-0B3FC0F40C39" name="GUID-7C7624BB-80C7-4BFE-AC79-0B3FC0F40C39"></a><h5 id="BDSPA-GUID-7C7624BB-80C7-4BFE-AC79-0B3FC0F40C39" class="sect5"><span class="enumeration_section">2.9.2.3 </span>Spatial Index Metadata
                     </h5>
                     <div>
                        <p>A metadata file is generated for every spatial index that is created. The spatial index metadata can be used to quickly find information related to a spatial index, such as the number of indexed records, the minimum bounding rectangle (MBR) of the indexed data, and the paths of both the spatial index and the indexed source data. The spatial index metadata can be retrieved using the spatial index name.</p>
                        <p>A spatial index metadata file contains the following information:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Spatial index name</p>
                           </li>
                           <li>
                              <p>Path to the spatial index</p>
                           </li>
                           <li>
                              <p>Number of indexed records</p>
                           </li>
                           <li>
                              <p>Number of local indexes</p>
                           </li>
                           <li>
                              <p>Extra fields contained in the indexed records</p>
                           </li>
                           <li>
                              <p>Geometry layer information such as th SRID, dimensions, tolerance, dimension boundaries, and whether the geometries are geodetic or not</p>
                           </li>
                           <li>
                              <p>The following information for each of the local spatial index files: path to the indexed data, path to the local index, and MBR of the indexed data</p>
                           </li>
                        </ul>
                        <p>The following metadata proeprties can be set when creating a spatial index using the <code class="codeph">SpatialIndexing</code> class:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">indexName</code>: Name of the spatial index. If not set, the output folder name is used.
                              </p>
                           </li>
                           <li>
                              <div class="p"><code class="codeph">metadataDir</code>: Path to the directory where the metadata file will be stored. 
                                 <ul style="list-style-type: disc;">
                                    <li>
                                       <p>By default, it will be stored in the following path relative to the user directory: <code class="codeph">oracle_spatial/index_metadata</code>. If the user is <code class="codeph">hdfs</code>, it will be <code class="codeph">/user/hdfs/oracle_spatial/index_metadata</code>.
                                       </p>
                                    </li>
                                 </ul> 
                              </div>
                           </li>
                           <li>
                              <p><code class="codeph">overwriteMetadata</code>: If set to <code class="codeph">true</code>, then when a spatial index metadata file already exists for a spatial index with the same <code class="codeph">indexName</code> in the current <code class="codeph">metadataDir</code>, the spatial index metadata will be overwritten. If set to <code class="codeph">false</code> and if a spatial index metadata file already exists for a spatial index with the same <code class="codeph">indexName</code> in the current <code class="codeph">metadataDir</code>, then an error is raised.
                              </p>
                           </li>
                        </ul>
                        <p>The following example sets the metadata directory and spatial index name, and specifies to overwrite any existing metadata if the index already exists:</p><pre class="pre codeblock"><code>spatialIndexing.setMetadataDir("/user/hdfs/myIndexMetadataDir");
spatialIndexing.setIndexName("testIndex");
spatialIndexing.setOverwriteMetadata(true);
</code></pre><p>An existing spatial index can be passed to other jobs by specifying only the <code class="codeph">indexName</code> and optionally the <code class="codeph">indexMetadataDir</code> where the index metadata can be found. When the index name is provided, there is no need to specify the spatial index path and the input format.
                        </p>
                        <p>The following job drivers accept the <code class="codeph">indexName</code> as a parameter:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">oracle.spatial.hadoop.vector.mapred.job.Categorization</code></p>
                           </li>
                           <li>
                              <p><code class="codeph">oracle.spatial.hadoop.vector.mapred.job.SpatialFilter</code></p>
                           </li>
                           <li>
                              <p><code class="codeph">oracle.spatial.hadoop.vector.mapred.job.Binning</code></p>
                           </li>
                           <li>
                              <p>Any driver that accepts <code class="codeph">oracle.spatial.hadoop.vector.InputDataSet</code>, such as <code class="codeph">SpatialJoin</code> and <code class="codeph">Partitioning</code></p>
                           </li>
                        </ul>
                        <p>If the index name is not found in the <code class="codeph">indexMetadataDir</code> path, an error is thrown indicating that the spatial index could not be found.
                        </p>
                        <p>The following example shows a spatial index being set as the input data set for a binning job:</p><pre class="pre codeblock"><code>Binning binning = new Binning();
binning.setIndexName("indexExample");
binning.setIndexMetadataDir("indexMetadataDir");
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="BDSPA433"></a><div class="props_rev_3"><a id="GUID-C5509E8F-5F1E-4DCC-BB0A-9F7761EE3B06" name="GUID-C5509E8F-5F1E-4DCC-BB0A-9F7761EE3B06"></a><h5 id="BDSPA-GUID-C5509E8F-5F1E-4DCC-BB0A-9F7761EE3B06" class="sect5"><span class="enumeration_section">2.9.2.4 </span>Input Formats for a Spatial Index
                     </h5>
                     <div>
                        <p>An <code class="codeph">InputFormat</code> must meet the following requisites to be supported:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>It must be a subclass of <code class="codeph">FileInputFormat</code>.
                              </p>
                           </li>
                           <li>
                              <p>The <code class="codeph">getSplits()</code>method must return either <code class="codeph">FileSplit</code> or <code class="codeph">CombineFileSplit</code> split types.
                              </p>
                           </li>
                           <li>
                              <p>For the old Hadoop API, the <code class="codeph">RecordReader</code>’s <code class="codeph">getPos()</code> method must return the current position to track back a record in the spatial index to its original record in the user file. If the current position is not returned, then the original record cannot be found using the spatial index. 
                              </p>
                              <p>However, the spatial index still can be created and used in operations that do not require the original record to be read. For example, additional fields can be added as extra fields to avoid having to read the whole original record.</p>
                              <div class="infoboxnote" id="GUID-C5509E8F-5F1E-4DCC-BB0A-9F7761EE3B06__GUID-53337748-0C13-4D04-9A41-D757C4A226C0">
                                 <p class="notep1">Note:</p>
                                 <p>The spatial indexes are created for each split as returned by the  <code class="codeph">getSplits()</code> method. When the spatial index is used for filtering (see <a href="using-big-data-spatial-graph-spatial-data.html#GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C">Spatial Filtering</a>), it is recommended to use the same <code class="codeph">InputFormat</code> implementation than the one used to create the spatial index to ensure the splits indexes can be found. 
                                 </p>
                              </div>
                           </li>
                        </ul>
                        <p>The <code class="codeph">getPos()</code> method has been removed from the Hadoop new API; however, <code class="codeph">org.apache.hadoop.mapreduce.lib.input.TextInputFormat</code> and <code class="codeph">CombineTextInputFormat</code> are supported, and it is still possible to get the record start offsets.
                        </p>
                        <p>Other input formats from the new API are supported, but the record start offsets will not be contained in the spatial index. Therefore, it is not possible to find the original records. The requirements for a new API input format are the same as for the old API. However, they must be translated to the new APIs <code class="codeph">FileInputFormat</code>, <code class="codeph">FileSplit</code>, and <code class="codeph">CombineFileSplit</code>.
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-00585288-5F2A-44AF-A8FD-48AE62800EAB" name="GUID-00585288-5F2A-44AF-A8FD-48AE62800EAB"></a><h5 id="BDSPA-GUID-00585288-5F2A-44AF-A8FD-48AE62800EAB" class="sect5"><span class="enumeration_section">2.9.2.5 </span>Support for GeoJSON and Shapefile Formats
                     </h5>
                     <div>
                        <p>The Vector API comes with <code class="codeph">InputFormat</code> and <code class="codeph">RecordInfoProvider</code> implementations for GeoJSON and Shapefile file formats.
                        </p>
                        <p>The following <code class="codeph">InputFormat/RecordInfoProvider</code> pairs can be used to read and interpret GeoJSON and ShapeFiles, respectively:
                        </p><pre class="oac_no_warn" dir="ltr">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat / oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider

oracle.spatial.hadoop.vector.shapefile.mapred.ShapeFileInputFormat / oracle.spatial.hadoop.vector.shapefile.ShapeFileRecordInfoProvider
</pre><p>More information about the usage and properties is available in the Javadoc.</p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-A5C717A7-5584-4878-8E24-DC0F43C36E37" name="GUID-A5C717A7-5584-4878-8E24-DC0F43C36E37"></a><h5 id="BDSPA-GUID-A5C717A7-5584-4878-8E24-DC0F43C36E37" class="sect5"><span class="enumeration_section">2.9.2.6 </span>Removing a Spatial Index
                     </h5>
                     <div>
                        <p>A previously generated spatial index can be removed by executing the following.</p><pre class="oac_no_warn" dir="ltr">oracle.spatial.hadoop.vector.util.Tools removeSpatialIndex indexName=&lt;INDEX_NAME&gt; [indexMetadataDir=&lt;PATH&gt;] [removeIndexFiles=&lt;true|false*&gt;]</pre><p>Where:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">indexName</code>: Name of a previously generated index.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">indexMetadataDir</code> (optional): Path to the index metadata directory. If not specified, the following path relative to the user directory will be used: oracle_spatial/index_metadata
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">removeIndexFiles</code> (optional): <code class="codeph">true</code> if generated index map files need to be removed in addition to the index metadata file. By default, it is <code class="codeph">false</code>.
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-78AD7453-D7ED-48F9-A531-E93353B8F800" name="GUID-78AD7453-D7ED-48F9-A531-E93353B8F800"></a><h4 id="BDSPA-GUID-78AD7453-D7ED-48F9-A531-E93353B8F800" class="sect4"><span class="enumeration_section">2.9.3 </span>Using MVSuggest
                  </h4>
                  <div>
                     <p><code class="codeph">MVSuggest</code> can be used at the time of spatial indexing to get an approximate location for records that do not have geometry but have some text field. This text field can be used to determine the record location. The geometry returned by <code class="codeph">MVSuggest</code> is used to include the record in the spatial index. 
                     </p>
                     <p>Because it is important to know the field containing the search text for every record, the <code class="codeph">RecordInfoProvider</code> implementation must also implement <code class="codeph">LocalizableRecordInfoProvider</code>. Alternatively, the configuration parameter <code class="codeph">oracle.spatial.recordInfo.locationField</code> can be set with the name of the field containing the search text. For more information, see the Javadoc for <code class="codeph">LocalizableRecordInfoProvider</code>.
                     </p>
                     <p>A standalone version of <code class="codeph">MVSuggest</code> is shipped with the Vector API and it can be used in some jobs that accept the <code class="codeph">MVSConfig</code> as an input parameter.
                     </p>
                     <p>The following job drivers can work with <code class="codeph">MVSuggest</code> and all of them have the <code class="codeph">setMVSConfig()</code> method which accepts an instance of <code class="codeph">MVSConfig</code>:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>oracle.spatial.hadoop.vector.mapred.job.SpatialIndexing: has the option of using <code class="codeph">MVSuggest</code> to get approximate spatial location for records which do not contain geometry.
                           </p>
                        </li>
                        <li>
                           <p>oracle.spatial.hadoop.vector.mapred.job.Categorization: <code class="codeph">MVSuggest</code> can be used to assign a record to a specific feature in a layer, for example, the feature California in the USA states layer.
                           </p>
                        </li>
                        <li>
                           <p>oracle.spatial.hadoop.vector.mapred.job.SuggestService: A simple job that generates a file containing a search text and its match per input record.</p>
                        </li>
                     </ul>
                     <p>The MVSuggest configuration is passed to a job using the MVSConfig or the LocalMVSConfig classes. The basic MVSuggest properties are:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">serviceLocation</code>: It is the minimum property required in order to use <code class="codeph">MVSuggest</code>. It contains the path or URL where the <code class="codeph">MVSuggest</code> directory is located or in the case of a URL, where the <code class="codeph">MVSuggest</code> service is deployed.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">serviceInterfaceType</code>: the type of <code class="codeph">MVSuggest</code> implementation used. It can be LOCAL(default) for a standalone version and WEB for the web service version.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">matchLayers</code>: an array of layer names used to perform the searches.
                           </p>
                        </li>
                     </ul>
                     <p>When using the standalone version of <code class="codeph">MVSuggest</code>, you must specify an <code class="codeph">MVSuggest</code> directory or repository as the <code class="codeph">serviceLocation</code>. An <code class="codeph">MVSuggest</code> directory must have the following structure:
                     </p><pre class="oac_no_warn" dir="ltr">mvsuggest_config.json
repository folder
   one or more layer template files in .json format
   optionally, a _config_ directory
   optionally, a _geonames_ directory</pre><p>The <code class="codeph">examples</code> folder comes with many layer template files and a <code class="codeph">_config_</code> directory with the configuration for each template.
                     </p>
                     <p>It is possible to set the repository folder (the one that contains the templates) as the mvsLocation instead of the whole <code class="codeph">MVSuggest</code> directory. In order to do that, the class <code class="codeph">LocalMVSConfig</code> can be used instead of <code class="codeph">MVSConfig</code> and the <code class="codeph">repositoryLocation</code> property must be set to <code class="codeph">true</code> as shown in the following example: 
                     </p><pre class="oac_no_warn" dir="ltr">LocalMVSConfig lmvsConf = new LocalMVSConfig();
lmvsConf.setServiceLocation(“file:///home/user/mvs_dir/repository/”);
lmvsConf.setRepositoryLocation(true);
lmvsConf.setPersistentServiceLocation(“/user/hdfs/hdfs_mvs_dir”);
spatialIndexingJob.setMvsConfig(lmvsConf);
</pre><p>The preceding example sets a repository folder as the MVS service location. <code class="codeph">setRepositoryLocation</code> is set to <code class="codeph">true</code> to indicate that the service location is a repository instead of the whole <code class="codeph">MVSuggest</code> directory. When the job runs, a whole <code class="codeph">MVSuggest</code> directory will be created using the given repository location; the repository will be indexed and will be placed in a temporary folder while the job finishes. The previously indexed <code class="codeph">MVSuggest</code> directory can be persisted so it can be used later. The preceding example saves the generated <code class="codeph">MVSuggest</code> directory in the HDFS path  <code class="codeph">/user/hdfs/hdfs_mvs_dir</code>. Use the MVSDirectory if the <code class="codeph">MVSuggest</code> directory already exists.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA365"></a><div class="props_rev_3"><a id="GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C" name="GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C"></a><h4 id="BDSPA-GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C" class="sect4"><span class="enumeration_section">2.9.4 </span>Spatial Filtering
                  </h4>
                  <div>
                     <p>Once the spatial index has been generated, it can be used to spatially filter the data. The filtering is performed before the data reaches the mapper and while it is being read. The following sample code example demonstrates how the <code class="codeph">SpatialFilterInputFormat</code> is used to spatially filter the data.
                     </p><pre class="oac_no_warn" dir="ltr">//set input path and format
 
FileInputFormat.setInputPaths(conf, new Path("/user/data/"));
conf.setInputFormat(SpatialFilterInputFormat.class);
 
//set internal input format
 
SpatialFilterInputFormat.setInternalInputFormatClass(conf, TextInputFormat.class);
if( spatialIndexPath != null )  
{
 
     //set the path to the spatial index and put it in the distributed cache
 
     boolean useDistributedCache = true;
     SpatialFilterInputFormat.setSpatialIndexPath(conf, spatialIndexPath, useDistributedCache);
} 
else 
{
     //as no spatial index is used a RecordInfoProvider is needed
 
     SpatialFilterInputFormat.setRecordInfoProviderClass(conf, TwitterLogRecordInfoProvider.class);
}
 
//set spatial operation used to filter the records
 
SpatialOperationConfig spatialOpConf = new SpatialOperationConfig();
spatialOpConf.setOperation(SpatialOperation.IsInside);
spatialOpConf.setJsonQueryWindow("{\"type\":\"Polygon\", \"coordinates\":[[-106.64595, 25.83997, -106.64595, 36.50061, -93.51001, 36.50061, -93.51001, 25.83997 , -106.64595, 25.83997]]}");
spatialOpConf.setSrid(8307);
spatialOpConf.setTolerance(0.5);
spatialOpConf.setGeodetic(true);

</pre><p><code class="codeph">SpatialFilterInputFormat</code> has to be set as the job's <code class="codeph">InputFormat</code>. The <code class="codeph">InputFormat</code> that actually reads the data must be set as the internal <code class="codeph">InputFormat</code>. In this example, the internal <code class="codeph">InputFormat</code> is <code class="codeph">TextInputFormat</code>.
                     </p>
                     <p>If a spatial index is specified, it is used for filtering. Otherwise, a <code class="codeph">RecordInfoProvider</code> must be specified in order to get the records geometries, in which case the filtering is performed record by record.
                     </p>
                     <p>As a final step, the spatial operation and query window to perform the spatial filter are set. It is recommended to use the same internal <code class="codeph">InputFormat</code> implementation used when the spatial index was created or, at least, an implementation that uses the same criteria to generate the splits. For details see <span class="q">"<a href="using-big-data-spatial-graph-spatial-data.html#GUID-C5509E8F-5F1E-4DCC-BB0A-9F7761EE3B06">Input Formats for a Spatial Index</a>."</span></p>
                     <p>If a simple spatial filtering needs to be performed (that is, only retrieving records that interact with a query window), the built-in job driver <code class="codeph">oracle.spatial.hadoop.vector.mapred.job.SpatialFilter</code> can be used instead. This job driver accepts indexed or non-indexed input and a <code class="codeph">SpatialOperationConfig</code> to perform the filtering.
                     </p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-6AF02715-ECC6-4C91-BBA2-DEB2C2A4727B">Filtering Records</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-2B0EC628-B93D-4B14-9690-635C5960CFE1">Filtering Using the Input Format</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA435"></a><div class="props_rev_3"><a id="GUID-6AF02715-ECC6-4C91-BBA2-DEB2C2A4727B" name="GUID-6AF02715-ECC6-4C91-BBA2-DEB2C2A4727B"></a><h5 id="BDSPA-GUID-6AF02715-ECC6-4C91-BBA2-DEB2C2A4727B" class="sect5"><span class="enumeration_section">2.9.4.1 </span>Filtering Records
                     </h5>
                     <div>
                        <p>The following steps are executed when records are filtered using the <code class="codeph">SpatialFilterInputFormat</code> and a spatial index.
                        </p>
                        <ol>
                           <li>
                              <p><code class="codeph">SpatialFilterInputFormat getRecordReader()</code> method is called when the mapper requests a <code class="codeph">RecordReader</code> for the current split.
                              </p>
                           </li>
                           <li>
                              <p>The spatial index for the current split is retrieved.</p>
                           </li>
                           <li>
                              <p>A spatial query is performed over the records contained in it using the spatial index. </p>
                              <p>As a result, the ranges in the split that contains records meeting the spatial filter are known. For example, if a split goes from the file position 1000 to 2000, upon executing the spatial filter it can be determined that records that fulfill the spatial condition are in the ranges 1100-1200, 1500-1600 and 1800-1950. So the result of performing the spatial filtering at this stage is a subset of the original filter containing smaller splits.</p>
                           </li>
                           <li>
                              <p>An Internal<code class="codeph">InputFormat</code> <code class="codeph">RecordReader</code> is requested for every small split from the resulting split subset.
                              </p>
                           </li>
                           <li>
                              <p>A RecordReader is returned to the caller mapper. The returned RecordReader is actually a wrapper RecordReader with one or more RecordReaders returned by the internal <code class="codeph">InputFormat</code>.
                              </p>
                           </li>
                           <li>
                              <p>Every time the mapper calls the RecordReader, the call to next method to read a record is delegated to the internal RecordReader.</p>
                           </li>
                        </ol>
                        <p>These steps are shown in the following spatial filter interaction diagram.</p>
                        <div class="figure" id="GUID-6AF02715-ECC6-4C91-BBA2-DEB2C2A4727B__GUID-C2DDC4E0-4E98-4C37-A534-B36B08009184"><img src="img/spatial_interact_diag.png" height="417" width="566" alt="Description of spatial_interact_diag.png follows" title="Description of spatial_interact_diag.png follows" longdesc="img_text/spatial_interact_diag.html"><br><a href="img_text/spatial_interact_diag.html">Description of the illustration spatial_interact_diag.png</a></div>
                        <!-- class="figure" -->
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C">Spatial Filtering</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-2B0EC628-B93D-4B14-9690-635C5960CFE1" name="GUID-2B0EC628-B93D-4B14-9690-635C5960CFE1"></a><h5 id="BDSPA-GUID-2B0EC628-B93D-4B14-9690-635C5960CFE1" class="sect5"><span class="enumeration_section">2.9.4.2 </span>Filtering Using the Input Format
                     </h5>
                     <div>
                        <p>A previously generated Spatial Index can be read using the input format implementation <code class="codeph">oracle.spatial.hadoop.vector.mapred.input.SpatialIndexInputFormat </code>(or its new Hadoop API equivalent with the <code class="codeph">mapreduce</code> package instead of <code class="codeph">mapred</code>). <code class="codeph">SpatialIndexInputFormat</code> is used just like any other <code class="codeph">FileInputFormat</code> subclass in that it takes an input path and it is set as the job’s input format. The key and values returned are the id <code class="codeph">(Text)</code> and record information <code class="codeph">(RecordInfo)</code> of the records stored in the spatial index.
                        </p>
                        <p>Aditionally, a spatial filter opertion can be performed by specifying a spatial operation configuration to the input format, so that only the records matching some spatial interaction will be returned to a mapper. The following example shows how to configure a job to read a spatial index to retrieve all the records that are inside a specific area.</p><pre class="pre codeblock"><code>JobConf conf = new JobConf();
conf.setMapperClass(MyMapper.class);
conf.setInputFormat(SpatialIndexInputFormat.class);
SpatialOperationConfig spatialOpConf = new SpatialOperationConfig();
spatialOpConf.setOperation(SpatialOperation.IsInside);
spatialOpConf.setQueryWindow(JGeometry.createLinearPolygon(new double[]{47.70, -124.28, 47.70,  -95.12, 35.45, -95.12, 35.45, -124.28, 47.70, -124.28}, 2, 8307));
SpatialIndexInputFormat.setFilterSpatialOperationConfig(spatialOpConf, conf);
</code></pre><p>The mapper in the preceding example can add a nonspatial filter by using the <code class="codeph">RecordInfo</code> extra fields, as shown in the following example.
                        </p><pre class="pre codeblock"><code>public class MyMapper extends MapReduceBase implements Mapper&lt;Text, RecordInfo, Text, RecordInfo&gt;{
	@Override
	public void map(Text key, RecordInfo value, OutputCollector&lt;Text, RecordInfo&gt; output, Reporter reporter)
			throws IOException {
		if( Integer.valueOf(value.getField("followers_count")) &gt; 0){
			output.collect(key, value);
		}
	}
}
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-0D7DDDF0-0D98-4557-9E93-0BF00C2A764C">Spatial Filtering</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="BDSPA366"></a><div class="props_rev_3"><a id="GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292" name="GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292"></a><h4 id="BDSPA-GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292" class="sect4"><span class="enumeration_section">2.9.5 </span>Classifying Data Hierarchically
                  </h4>
                  <div>
                     <p>The Vector Analysis API provides a way to classify the data into hierarchical entities. For example, in a given set of catalogs with a defined level of administrative boundaries such as continents, countries and states, it is possible to join a record of the user data to a record of each level of the hierarchy data set. The following example generates a summary count for each hierarchy level, containing the number of user records per continent, country, and state or province:</p><pre class="oac_no_warn" dir="ltr">Categorization catJob = new Categorization();
//set a spatial index as the input
				 
catJob.setIndexName("indexExample");
 
//set the job's output
				 
catJob.setOutput("hierarchy_count");
				 
//set HierarchyInfo implementation which describes the world administrative boundaries hierarchy
			
catJob.setHierarchyInfoClass( WorldDynaAdminHierarchyInfo.class );
				 
//specify the paths of the hierarchy data
				 
Path[] hierarchyDataPaths = {
				new Path("file:///home/user/catalogs/world_continents.json"), 
				new Path("file:///home/user/catalogs/world_countries.json"), 
				new Path("file:///home/user/catalogs/world_states_provinces.json")};
catJob.setHierarchyDataPaths(hierarchyDataPaths);
				 
//set the path where the index for the previous hierarchy data will be generated
				 
catJob.setHierarchyIndexPath(new Path("/user/hierarchy_data_index/"));
				 
//setup the spatial operation which will be used to join records from the two datasets (spatial index and hierarchy data).
SpatialOperationConfig spatialOpConf = new SpatialOperationConfig();			 
spatialOpConf.setOperation(SpatialOperation.IsInside);
spatialOpConf.setSrid(8307);
spatialOpConf.setTolerance(0.5);
spatialOpConf.setGeodetic(true);
catJob.setSpatialOperationConfig(spatialOpConf);
				 
//add the previous setup to the job configuration
				 
catJob.configure(conf);
				 
//run the job 
RunningJob rj = JobClient.runJob(conf);
</pre><p>The preceding example uses the <code class="codeph">Categorization</code> job driver. The configuration can be divided into the following categories:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Input data: A previously generated spatial index (received as the job input).</p>
                        </li>
                        <li>
                           <p>Output data: A folder that contains the summary counts for each hierarchy level.</p>
                        </li>
                        <li>
                           <p>Hierarchy data configuration: This contains the following:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><code class="codeph">HierarchyInfo</code> class: This is an implementation of <code class="codeph">HierarchyInfo</code> class in charge of describing the current hierarchy data. It provides the number of hierarchy levels, level names, and the data contained at each level.
                                 </p>
                              </li>
                              <li>
                                 <p>Hierarchy data paths: This is the path to each one of the hierarchy catalogs. These catalogs are read by the <code class="codeph">HierarchyInfo</code> class.
                                 </p>
                              </li>
                              <li>
                                 <p>Hierarchy index path: This is the path where the hierarchy data index is stored. Hierarchy data needs to be preprocessed to know the parent-child relationships between hierarchy levels. This information is processed once and saved at the hierarchy index, so it can be used later by the current job or even by any other jobs.</p>
                              </li>
                           </ul>
                        </li>
                        <li>
                           <p>Spatial operation configuration: This is the spatial operation to be performed between records of the user data and the hierarchy data in order to join both datasets. The parameters to set here are the Spatial Operation type (IsInside), SRID (8307), Tolerance (0.5 meters), and whether the geometries are Geodetic (true).</p>
                        </li>
                     </ul>
                     <p>Internally, the&nbsp;<code class="codeph">Categorization.configure()</code>&nbsp;method sets the mapper and reducer to be <code class="codeph">SpatialHierarchicalCountMapper</code>&nbsp;and&nbsp;<code class="codeph">SpatialHierarchicalCountReducer</code>,&nbsp;respectively.&nbsp;<code class="codeph">SpatialHierarchicalCountMapper</code>'s&nbsp;output key is a hierarchy entry identifier in the form&nbsp;<code class="codeph">hierarchy_level</code>&nbsp;+&nbsp;<code class="codeph">hierarchy_entry_id</code>. The mapper output value is a single count for each output key. The reducer sums up all the counts for each key.
                     </p>
                     <div class="infoboxnote" id="GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292__GUID-AACB541D-31C8-4C1C-9F8C-2C52E9018C4A">
                        <p class="notep1">Note:</p>
                        <p>The entire hierarchy data may be read into memory and hence the total size of all the catalogs is expected to be significantly less than the user data. The hierarchy data size should not be larger than a couple of gigabytes.</p>
                     </div>
                     <p>If you want another type of output instead of counts, for example, a list of user records according to the hierarchy entry. In this case, the <code class="codeph">SpatialHierarchicalJoinMapper</code> can be used. The <code class="codeph">SpatialHierarchicalJoinMapper</code> output value is a <code class="codeph">RecordInfo</code> instance, which can be gathered in a user-defined reducer to produce a different output. The following user-defined reducer generates a MapFile for each hierarchy level using the <code class="codeph">MultipleOutputs</code> class. Each MapFile has the hierarchy entry ids as keys and <code class="codeph">ArrayWritable</code> instances containing the matching records for each hierarchy entry as values. The following is an user-defined reducer that returns a list of records by hierarchy entry:
                     </p><pre class="oac_no_warn" dir="ltr">public class HierarchyJoinReducer extends MapReduceBase implements Reducer&lt;Text, RecordInfo, Text, ArrayWritable&gt; {
 
       private MultipleOutputs mos = null;
       private Text outKey = new Text();
       private ArrayWritable outValue = new ArrayWritable( RecordInfo.class );
 
       @Override
       public void configure(JobConf conf) 
       {
         super.configure(conf);
 
         //use MultipleOutputs to generate different outputs for each hierarchy level
    
         mos = new MultipleOutputs(conf);
        }
        @Override
        public void reduce(Text key, Iterator&lt;RecordInfo&gt; values,
                          OutputCollector&lt;Text, RecordInfoArrayWritable&gt; output, Reporter reporter)
                          throws IOException 
        {
 
          //Get the hierarchy level name and the hierarchy entry id from the key
 
          String[] keyComponents = HierarchyHelper.getMapRedOutputKeyComponents(key.toString());
          String hierarchyLevelName = keyComponents[0];
          String entryId = keyComponents[1];
          List&lt;Writable&gt; records = new LinkedList&lt;Writable&gt;();
 
          //load the values to memory to fill output ArrayWritable
      
          while(values.hasNext())
          {
            RecordInfo recordInfo = new RecordInfo( values.next() );
            records.add( recordInfo );		
          }
          if(!records.isEmpty())
          {
 
            //set the hierarchy entry id as key
 
            outKey.set(entryId);
 
            //list of records matching the hierarchy entry id
 
            outValue.set( records.toArray(new Writable[]{} ) );
 
            //get the named output for the given hierarchy level
 
            hierarchyLevelName = FileUtils.toValidMONamedOutput(hierarchyLevelName);
            OutputCollector&lt;Text, ArrayWritable&gt; mout = mos.getCollector(hierarchyLevelName, reporter);
 
           //Emit key and value
 
           mout.collect(outKey, outValue);
          }
}
 
        @Override
        public void close() throws IOException 
        {
          mos.close();
        }
}
</pre><p>The same reducer can be used in a job with the following configuration to generate a list of records according to the hierarchy levels:</p><pre class="oac_no_warn" dir="ltr">JobConf conf = new JobConf(getConf());
 
//input path
 
FileInputFormat.setInputPaths(conf, new Path("/user/data_spatial_index/") );
 
//output path
 
FileOutputFormat.setOutputPath(conf, new Path("/user/records_per_hier_level/") );
 
//input format used to read the spatial index
 
conf.setInputFormat( SequenceFileInputFormat.class);
 
//output format: the real output format will be configured for each multiple output later
 
conf.setOutputFormat(NullOutputFormat.class);
 
//mapper
 
conf.setMapperClass( SpatialHierarchicalJoinMapper.class );
conf.setMapOutputKeyClass(Text.class);
conf.setMapOutputValueClass(RecordInfo.class);
 
//reducer
 
conf.setReducerClass( HierarchyJoinReducer.class );
conf.setOutputKeyClass(Text.class);
conf.setOutputValueClass(ArrayWritable.class);
 
////////////////////////////////////////////////////////////////////
 
//hierarchy data setup
 
//set HierarchyInfo class implementation
 
conf.setClass(ConfigParams.HIERARCHY_INFO_CLASS, WorldAdminHierarchyInfo.class, HierarchyInfo.class);
 
//paths to hierarchical catalogs
 
Path[] hierarchyDataPaths = {
new Path("file:///home/user/catalogs/world_continents.json"), 
new Path("file:///home/user/catalogs/world_countries.json"), 
new Path("file:///home/user/catalogs/world_states_provinces.json")};
 
//path to hierarchy index
 
Path hierarchyDataIndexPath = new Path("/user/hierarchy_data_index/");
 
//instantiate the HierarchyInfo class to index the data if needed.
 
HierarchyInfo hierarchyInfo = new WorldAdminHierarchyInfo();
hierarchyInfo.initialize(conf);
 
//Create the hierarchy index if needed. If it already exists, it will only load the hierarchy index to the distributed cache
 
HierarchyHelper.setupHierarchyDataIndex(hierarchyDataPaths, hierarchyDataIndexPath, hierarchyInfo, conf);
 
///////////////////////////////////////////////////////////////////
 
//setup the multiple named outputs:
 
int levels = hierarchyInfo.getNumberOfLevels();
for(int i=1; i&lt;=levels; i++)
{
    String levelName = hierarchyInfo.getLevelName(i);
 
    //the hierarchy level name is used as the named output
 
    String namedOutput = FileUtils.toValidMONamedOutput(levelName);
    MultipleOutputs.addNamedOutput(conf, namedOutput, MapFileOutputFormat.class, Text.class, ArrayWritable.class);
}
 
//finally, setup the spatial operation
 
SpatialOperationConfig spatialOpConf = new SpatialOperationConfig();			 
spatialOpConf.setOperation(SpatialOperation.IsInside);
spatialOpConf.setSrid(8307);
spatialOpConf.setTolerance(0.5);
spatialOpConf.setGeodetic(true);
spatialOpConf.store(conf);
 
//run job
 
JobClient.runJob(conf);
</pre><p>Supposing the output value should be an array of record ids instead of an array of <code class="codeph">RecordInfo</code> instances, it would be enough to perform a couple of changes in the previously defined reducer.
                     </p>
                     <p>The line where <code class="codeph">outValue</code> is declared, in the previous example, changes to: 
                     </p><pre class="oac_no_warn" dir="ltr">private ArrayWritable outValue = new ArrayWritable(Text.class);
</pre><p>The loop where the input values are retrieved, in the previous example, is changed. Therefore, the record ids are got instead of the whole records:</p><pre class="oac_no_warn" dir="ltr">while(values.hasNext())
{
  records.add( new Text(values.next().getId()) );
}
</pre><p>While only the record id is needed the mapper emits the whole <code class="codeph">RecordInfo</code> instance. Therefore, a better approach is to change the mappers output value. The mappers output value can be changed by extending <code class="codeph">AbstractSpatialJoinMapper</code>. In the following example, the mapper emits only the record ids instead of the whole <code class="codeph">RecorInfo</code> instance every time a record matches some of the hierarchy entries:
                     </p><pre class="oac_no_warn" dir="ltr">public class IdSpatialHierarchicalMapper extends AbstractSpatialHierarchicalMapper&lt; Text &gt; 
{
       Text outValue = new Text();
 
       @Override
       protected Text getOutValue(RecordInfo matchingRecordInfo) 
       {
 
         //the out value is the record's id
 
         outValue.set(matchingRecordInfo.getId());
         return outValue;
       }
}</pre></div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-D70E9B59-4AB0-4934-AE53-1143282CFC0F">Changing the Hierarchy Level Range</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A660962A-5D46-47AC-B2E5-92D3B092159C">Controlling the Search Hierarchy</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-E1CB00BA-1D24-41D7-936A-F34F2CED9711">Using MVSuggest to Classify the Data</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA436"></a><div class="props_rev_3"><a id="GUID-D70E9B59-4AB0-4934-AE53-1143282CFC0F" name="GUID-D70E9B59-4AB0-4934-AE53-1143282CFC0F"></a><h5 id="BDSPA-GUID-D70E9B59-4AB0-4934-AE53-1143282CFC0F" class="sect5"><span class="enumeration_section">2.9.5.1 </span>Changing the Hierarchy Level Range
                     </h5>
                     <div>
                        <p>By default, all the hierarchy levels defined in the <code class="codeph">HierarchyInfo</code> implementation are loaded when performing the hierarchy search. The range of hierarchy levels loaded is from level 1 (parent level) to the level returned by <code class="codeph">HierarchyInfo.getNumberOfLevels()</code> method. The following example shows how to setup a job to only load the levels 2 and 3.
                        </p><pre class="oac_no_warn" dir="ltr">conf.setInt( ConfigParams.HIERARCHY_LOAD_MIN_LEVEL, 2);
conf.setInt( ConfigParams.HIERARCHY_LOAD_MAX_LEVEL, 3);
</pre><div class="infoboxnote" id="GUID-D70E9B59-4AB0-4934-AE53-1143282CFC0F__GUID-63DCFE7B-3562-456E-A347-AD551DEB98A3">
                           <p class="notep1">Note:</p>
                           <p>These parameters are useful when only a subset of the hierarchy levels is required and when you do not want to modify the <code class="codeph">HierarchyInfo</code> implementation.
                           </p>
                        </div>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292">Classifying Data Hierarchically</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="BDSPA437"></a><div class="props_rev_3"><a id="GUID-A660962A-5D46-47AC-B2E5-92D3B092159C" name="GUID-A660962A-5D46-47AC-B2E5-92D3B092159C"></a><h5 id="BDSPA-GUID-A660962A-5D46-47AC-B2E5-92D3B092159C" class="sect5"><span class="enumeration_section">2.9.5.2 </span>Controlling the Search Hierarchy
                     </h5>
                     <div>
                        <p>The search is always performed only at the bottom hierarchy level (the higher level number). If a user record matches some hierarchy entry at this level, then the match is propagated to the parent entry in upper levels. For example, if a user record matches Los Angeles, then it also matches California, USA, and North America. If there are no matches for a user record at the bottom level, then the search does not continue into the upper levels.</p>
                        <p>This behavior can be modified by setting the configuration parameter <code class="codeph">ConfigParams.HIERARCHY_SEARCH_MULTIPLE_LEVELS</code> to <code class="codeph">true</code>. Therefore, if a search at the bottom hierarchy level resulted in some unmatched user records, then search continues into the upper levels until the top hierarchy level is reached or there are no more user records to join. This behavior can be used when the geometries of parent levels do not perfectly enclose the geometries of their child entries
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292">Classifying Data Hierarchically</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="BDSPA438"></a><div class="props_rev_3"><a id="GUID-E1CB00BA-1D24-41D7-936A-F34F2CED9711" name="GUID-E1CB00BA-1D24-41D7-936A-F34F2CED9711"></a><h5 id="BDSPA-GUID-E1CB00BA-1D24-41D7-936A-F34F2CED9711" class="sect5"><span class="enumeration_section">2.9.5.3 </span>Using MVSuggest to Classify the Data
                     </h5>
                     <div>
                        <p><code class="codeph">MVSuggest</code> can be used instead of the spatial index to classify data. For this case, an implementation of <code class="codeph">LocalizableRecordInfoProvider</code> must be known and sent to MVSuggest to perform the search. See the information about <code class="codeph">LocalizableRecordInfoProvider</code>.
                        </p>
                        <p>In the following example, the program option is changed from spatial to MVS. The input is the path to the user data instead of the spatial index. The <code class="codeph">InputFormat</code> used to read the user record and an implementation of <code class="codeph">LocalizableRecordInfoProvider</code> are specified. The <code class="codeph">MVSuggest</code> service configuration is set. Notice that there is no spatial operation configuration needed in this case.
                        </p><pre class="oac_no_warn" dir="ltr">Categorization&lt;LongWritable, Text&gt; hierCount = new Categorization&lt;LongWritable, Text&gt;();

// the input path is the user's data

hierCount.setInput("/user/data/");

// set the job's output

hierCount.setOutput("/user/mvs_hierarchy_count");

// set HierarchyInfo implementation which describes the world
// administrative boundaries hierarchy

hierCount.setHierarchyInfoClass(WorldDynaAdminHierarchyInfo.class);

// specify the paths of the hierarchy data

Path[] hierarchyDataPaths = { new Path("file:///home/user/catalogs/world_continents.json"),
		new Path("file:///home/user/catalogs/world_countries.json"),
		new Path("file:///home/user/catalogs/world_states_provinces.json") };
hierCount.setHierarchyDataPaths(hierarchyDataPaths);

// set the path where the index for the previous hierarchy data will be
// generated

hierCount.setHierarchyIndexPath(new Path("/user/hierarchy_data_index/"));

// No spatial operation configuration is needed, Instead, specify the
// InputFormat used to read the user's data and the
// LocalizableRecordInfoProvider class.

hierCount.setInputFormatClass(TextInputFormat.class);
hierCount.setRecordInfoProviderClass(MyLocalizableRecordInfoProvider.class);

// finally, set the MVSuggest configuration

LocalMVSConfig lmvsConf = new LocalMVSConfig();
lmvsConf.setServiceLocation("file:///home/user/mvs_dir/oraclemaps_pub");
lmvsConf.setRepositoryLocation(true);
hierCount.setMvsConfig(lmvsConf);

// add the previous setup to the job configuration
hierCount.configure(conf);

// run the job

JobClient.runJob(conf);
</pre><div class="infoboxnote" id="GUID-E1CB00BA-1D24-41D7-936A-F34F2CED9711__GUID-D179A0C8-7861-4C86-A724-38D65D787085">
                           <p class="notep1">Note:</p>
                           <p>When using <code class="codeph">MVSuggest</code>, the hierarchy data files must be the same as the layer template files used by <code class="codeph">MVSuggest</code>. The hierarchy level names returned by the <code class="codeph">HierarchyInfo.getLevelNames()</code> method are used as the matching layers by <code class="codeph">MVSuggest</code>.
                           </p>
                        </div>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-34E39FE6-A104-4E97-9336-2C6EBBCD7292">Classifying Data Hierarchically</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="BDSPA367"></a><div class="props_rev_3"><a id="GUID-8D22891E-F2C4-4D9F-81C3-ABAA9F520AA9" name="GUID-8D22891E-F2C4-4D9F-81C3-ABAA9F520AA9"></a><h4 id="BDSPA-GUID-8D22891E-F2C4-4D9F-81C3-ABAA9F520AA9" class="sect4"><span class="enumeration_section">2.9.6 </span>Generating Buffers
                  </h4>
                  <div>
                     <div class="section">
                        <p>The API provides a mapper to generate a buffer around each record's geometry. The following code sample shows how to run a job to generate a buffer for each record geometry by using the <code class="codeph">BufferMapper</code> class.
                        </p><pre class="oac_no_warn" dir="ltr">//configure input
conf.setInputFormat(FileSplitInputFormat.class);
FileSplitInputFormat.setInputPaths(conf, "/user/waterlines/");
FileSplitInputFormat.setRecordInfoProviderClass(conf, GeoJsonRecordInfoProvider.class);
 
//configure output
conf.setOutputFormat(SequenceFileOutputFormat.class);
SequenceFileOutputFormat.setOutputPath(conf, new Path("/user/data_buffer/"));	

//set the BufferMapper as the job mapper
conf.setMapperClass(BufferMapper.class);
conf.setMapOutputKeyClass(Text.class);
conf.setMapOutputValueClass(RecordInfo.class);
conf.setOutputKeyClass(Text.class);
conf.setOutputValueClass(RecordInfo.class);
 
//set the width of the buffers to be generated
conf.setDouble(ConfigParams.BUFFER_WIDTH, 0.2);
 
//run the job
JobClient.runJob(conf);
</pre><p><code class="codeph">BufferMapper</code> generates a buffer for each input record containing a geometry. The output key and values are the record id and a <code class="codeph">RecordInfo</code> instance containing the generated buffer. The resulting file is a Hadoop <code class="codeph">MapFile</code> containing the mapper output key and values. If necessary, the output format can be modified by implementing a reducer that takes the mapper’s output keys and values, and outputs keys and values of a different type.
                        </p>
                        <p><code class="codeph">BufferMapper</code> accepts the following parameters:
                        </p>
                        <div class="tblformal" id="GUID-8D22891E-F2C4-4D9F-81C3-ABAA9F520AA9__GUID-72D8C267-3709-4346-A04A-A3970BF9BF3C">
                           <table cellpadding="4" cellspacing="0" class="Formal" title summary="Generating Buffer, the BufferMapper parameters" width="100%" frame="hsides" border="1" rules="rows">
                              <thead>
                                 <tr align="left" valign="top">
                                    <th align="left" valign="bottom" width="25%" id="d8066e8106">Parameter</th>
                                    <th align="left" valign="bottom" width="25%" id="d8066e8109">ConfigParam constant</th>
                                    <th align="left" valign="bottom" width="25%" id="d8066e8112">Type</th>
                                    <th align="left" valign="bottom" width="25%" id="d8066e8115">Description</th>
                                 </tr>
                              </thead>
                              <tbody>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="25%" id="d8066e8120" headers="d8066e8106 ">
                                       <p>oracle.spatial.buffer.width</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8120 d8066e8109 ">
                                       <p>BUFFER_WIDTH</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8120 d8066e8112 ">
                                       <p>double</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8120 d8066e8115 ">
                                       <p>The buffer width</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="25%" id="d8066e8133" headers="d8066e8106 ">
                                       <p>oracle.spatial.buffer.sma</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8133 d8066e8109 ">
                                       <p>BUFFER_SMA</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8133 d8066e8112 ">
                                       <p>double</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8133 d8066e8115 ">
                                       <p>The semi major axis for the datum used in the coordinate system of the input</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="25%" id="d8066e8146" headers="d8066e8106 ">
                                       <p>oracle.spatial.buffer.iFlat</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8146 d8066e8109 ">
                                       <p>BUFFER_IFLAT</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8146 d8066e8112 ">
                                       <p>double</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8146 d8066e8115 ">
                                       <p>The flattening value</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="25%" id="d8066e8159" headers="d8066e8106 ">
                                       <p>oracle.spatial.buffer.arcT</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8159 d8066e8109 ">
                                       <p>BUFFER_ARCT</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8159 d8066e8112 ">
                                       <p>double</p>
                                    </td>
                                    <td align="left" valign="top" width="25%" headers="d8066e8159 d8066e8115 ">
                                       <p>The arc tolerance used for geodetic densification</p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <!-- class="inftblhruleinformal" -->
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-C86524DB-A0C1-4A40-B4AC-DAA90D77A0F4" name="GUID-C86524DB-A0C1-4A40-B4AC-DAA90D77A0F4"></a><h4 id="BDSPA-GUID-C86524DB-A0C1-4A40-B4AC-DAA90D77A0F4" class="sect4"><span class="enumeration_section">2.9.7 </span>Spatial Binning
                  </h4>
                  <div>
                     <p>The Vector API provides the class <code class="codeph">oracle.spatial.hadoop.vector.mapred.job.Binning</code> to perform spatial binning over a spatial data set. The <code class="codeph">Binning</code> class is a MapReduce job driver that takes an input data set (which can be spatially indexed or not), assigns each record to a bin, and generates a file containing all the bins (which contain one or more records and optionally aggregated values).
                     </p>
                     <p>A binning job can be configured as follows:</p>
                     <ol>
                        <li>
                           <p>Specify the data set to be binned and the way it will be read and interpreted (<code class="codeph">InputFormat</code> and <code class="codeph">RecordInfoProvider</code>), or, specify the name of an existing spatial index.
                           </p>
                        </li>
                        <li>
                           <p>Set the output path.</p>
                        </li>
                        <li>
                           <p>Set the grid MBR, that is, the rectangular area to be binned.</p>
                        </li>
                        <li>
                           <p>Set the shape of the bins: <code class="codeph">RECTANGLE</code> or <code class="codeph">HEXAGON</code>.
                           </p>
                        </li>
                        <li>
                           <p>Specify the bin (cell) size. For rectangles, specify the width and height. For hexagon-shaped cells, specify the hexagon width. Each hexagon is always drawn with only one of its vertices as the base.</p>
                        </li>
                        <li>
                           <p>Optionally, pass a list of numeric field names to be aggregated per bin.</p>
                        </li>
                     </ol>
                     <p>The resulting output is a text file where each record is a bin (cell) in JSON format and contains the following information:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>id: the bin id</p>
                        </li>
                        <li>
                           <p>geom: the bin geometry; always a polygon that is a rectangle or a hexagon</p>
                        </li>
                        <li>
                           <p>count: the number of points contained in the bin</p>
                        </li>
                        <li>
                           <p>aggregated fields: zero or more aggregated fields</p>
                        </li>
                     </ul>
                     <p>The following example configures and runs a binning job:</p><pre class="oac_no_warn" dir="ltr">//create job driver
Binning&lt;LongWritable, Text&gt; binJob = new Binning&lt;LongWritable, Text&gt;();
//setup input
binJob.setInput("/user/hdfs/input/part*");
binJob.setInputFormatClass(GeoJsonInputFormat.class);
binJob.setRecordInfoProviderClass(GeoJsonRecordInfoProvider.class);
//set binning output
binJob.setOutput("/user/hdfs/output/binning");
//create a binning configuration to produce rectangular cells
BinningConfig binConf = new BinningConfig();
binConf.setShape(BinShape.RECTANGLE);
//set the bin size
binConf.setCellHeight(0.2);
binConf.setCellWidth(0.2);
//specify the area to be binned
binConf.setGridMbr(new double[]{-50,10,50,40});
binJob.setBinConf(binConf);
//save configuration
binJob.configure(conf);
//run job
JobClient.runJob(conf);
</pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-4F1ED8BC-E62B-4356-A31E-8C5FC1442922" name="GUID-4F1ED8BC-E62B-4356-A31E-8C5FC1442922"></a><h4 id="BDSPA-GUID-4F1ED8BC-E62B-4356-A31E-8C5FC1442922" class="sect4"><span class="enumeration_section">2.9.8 </span>Spatial Clustering
                  </h4>
                  <div>
                     <p>The job driver class <code class="codeph">oracle.spatial.hadoop.mapred.KMeansClustering</code> can be used to find spatial clusters in a data set. This class uses a distributed version of the K-means algorithm.
                     </p>
                     <p>Required parameters:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Path to the input data set, the <code class="codeph">InputFormat</code> class used to read the input data set and the <code class="codeph">RecordInfoProvider</code> used to extract the spatial information from records.
                           </p>
                        </li>
                        <li>
                           <p>Path where the results will be stored.</p>
                        </li>
                        <li>
                           <p>Number of clusters to be found.</p>
                        </li>
                     </ul>
                     <p>Optional parameters:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Maximum number of iterations before the algorithm finishes.</p>
                        </li>
                        <li>
                           <p>Criterion function used to determine when the clusters converge. It is given as an implementation of <code class="codeph">oracle.spatial.hadoop.vector.cluster.kmeans.CriterionFunction</code>. The Vector API contains the following criterion function implementations: <code class="codeph">SquaredErrorCriterionFunction</code> and <code class="codeph">EuclideanDistanceCriterionFunction</code>.
                           </p>
                        </li>
                        <li>
                           <p>An implementation of <code class="codeph">oracle.spatial.hadoop.vector.cluster.kmeans.ClusterShapeGenerator</code>, which is used to generate a geometry for each cluster. The default implementation is <code class="codeph">ConvexHullClusterShapeGenerator</code> and generates a convex hull for each cluster. If no cluster geometry is needed, the <code class="codeph">DummyClusterShapeGenerator</code> class can be used.
                           </p>
                        </li>
                        <li>
                           <p>The initial k cluster points as a sequence of x,y ordinates. For example: x1,y1,x2,y2,…xk,yk</p>
                        </li>
                     </ul>
                     <p>The result is a file named <code class="codeph">clusters.json</code>, which contains an array of clusters called features. Each cluster contains the following information:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>id: Cluster id</p>
                        </li>
                        <li>
                           <p>memberCount: Number of elements in the cluster</p>
                        </li>
                        <li>
                           <p>geom: Cluster geometry</p>
                        </li>
                     </ul>
                     <p>The following example runs the <code class="codeph">KMeansClustering</code> algorithm to find 5 clusters. By default, the <code class="codeph">SquredErrorCriterionFunction</code> and <code class="codeph">ConvexHullClusterShapeGenerator</code> are used , so you do not need yo set these classes explicitly. Also note that <code class="codeph">runIterations()</code> is called to run the algorithm; internally, it launches one MapReduce per iteration. In this example, the number 20 is passed to <code class="codeph">runIterations()</code> as the maximum number of iterations allowed.
                     </p><pre class="oac_no_warn" dir="ltr">//create the cluster job driver
KMeansClustering&lt;LongWritable, Text&gt; clusterJob = new KMeansClustering&lt;LongWritable, Text&gt;();
//set input properties:
//input dataset path
clusterJob.setInput("/user/hdfs/input/part*");
//InputFormat class
clusterJob.setInputFormatClass(GeoJsonInputFormat.class);
//RecordInfoProvider implementation
clusterJob.setRecordInfoProviderClass(GeoJsonRecordInfoProvider.class);
//specify where the results will be saved
clusterJob.setOutput("/user/hdfs/output/clusters");
//5 cluster will be found
clusterJob.setK(5);
//run the algorithm
success = clusterJob.runIterations(20, conf);
</pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-87C0B23C-C3D8-4317-863D-AC2AA9511306" name="GUID-87C0B23C-C3D8-4317-863D-AC2AA9511306"></a><h4 id="BDSPA-GUID-87C0B23C-C3D8-4317-863D-AC2AA9511306" class="sect4"><span class="enumeration_section">2.9.9 </span>Spatial Join
                  </h4>
                  <div>
                     <div class="section">
                        <p>The spatial join feature allows detecting spatial interactions between records of two different large data sets.</p>
                        <p>The driver class <code class="codeph">oracle.spatial.hadoop.vector.mapred.job.SpatialJoin</code> can be used to execute or configure a job to perform a spatial join between two data sets. The job driver takes the following inputs:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Input data sets: Two input data sets are expected. Each input data set is represented using the class <code class="codeph">oracle.spatial.hadoop.vector.InputDataSet</code>, which holds information about where to find and how to read a data set, such as path(s), spatial index, input format, and record info provider used to interpret records from the data set. It also accepts a spatial configuration for the data set.
                              </p>
                           </li>
                           <li>
                              <p>Spatial operation configuration: The spatial operation configuration defines the spatial interaction used to determine if two records are related to each other. It also defines the area to cover (MBR), that is, only records within or intersecting the MBR will be considered in the search.</p>
                           </li>
                           <li>
                              <p>Partitioning result file path: An optional parameter that points to a previously generated partitioning result for both data sets. Data need to be partitioned in order to distribute the work; if this parameter is not provided, a partitioning process will be executed over the input data sets. (See <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C127F600-72AD-4430-841A-1BB63EB2D942">Spatial Partitioning</a> for more information.)
                              </p>
                           </li>
                           <li>
                              <p>Output path: The path where the result file will be written.</p>
                           </li>
                        </ul>
                        <p>The spatial join result is a text file where each line is a pair of records that meet the spatial interaction defined in the spatial operation configuration.</p>
                        <p>The following table shows the currently supported spatial interactions for the spatial join.</p>
                        <div class="tblformal" id="GUID-87C0B23C-C3D8-4317-863D-AC2AA9511306__SPATIALINTERACTIONSSUPPORTEDFORSPAT-00A72550">
                           <table cellpadding="4" cellspacing="0" class="Formal" title summary="Spatial interactions supported for spatial join operations" width="100%" frame="hsides" border="1" rules="rows">
                              <thead>
                                 <tr align="left" valign="top">
                                    <th align="left" valign="bottom" width="21%" id="d8066e8527">Spatial Operation</th>
                                    <th align="left" valign="bottom" width="64%" id="d8066e8530">Extra Parameters</th>
                                    <th align="left" valign="bottom" width="15%" id="d8066e8533">Type</th>
                                 </tr>
                              </thead>
                              <tbody>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="21%" id="d8066e8538" headers="d8066e8527 ">
                                       <p>AnyInteract</p>
                                    </td>
                                    <td align="left" valign="top" width="64%" headers="d8066e8538 d8066e8530 ">
                                       <p>None</p>
                                    </td>
                                    <td align="left" valign="top" width="15%" headers="d8066e8538 d8066e8533 ">
                                       <p>(NA)</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="21%" id="d8066e8548" headers="d8066e8527 ">
                                       <p>IsInside</p>
                                    </td>
                                    <td align="left" valign="top" width="64%" headers="d8066e8548 d8066e8530 ">
                                       <p>None</p>
                                    </td>
                                    <td align="left" valign="top" width="15%" headers="d8066e8548 d8066e8533 ">
                                       <p>(N/A)</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="21%" id="d8066e8558" headers="d8066e8527 ">
                                       <p>WithinDistance</p>
                                    </td>
                                    <td align="left" valign="top" width="64%" headers="d8066e8558 d8066e8530 ">
                                       <p>oracle.spatial.hadoop.vector.util.SpatialOperationConfig.PARAM_WD_DISTANCE</p>
                                    </td>
                                    <td align="left" valign="top" width="15%" headers="d8066e8558 d8066e8533 ">
                                       <p>double</p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <!-- class="inftblhruleinformal" -->
                        <p>For a <code class="codeph">WithinDistance</code> operation, the distance parameter can be specified in the <code class="codeph">SpatialOperationConfig</code>, as shown in the following example:
                        </p><pre class="pre codeblock"><code>spatialOpConf.setOperation(SpatialOperation.WithinDistance);
spatialOpConf.addParam(SpatialOperationConfig.PARAM_WD_DISTANCE, 5.0);
</code></pre><p>The following example runs a Spatial Join job for two input data sets. The first data set, postal boundaries, is specified providing the name of its spatial index. For the second data set, tweets, the path to the file, input format, and record info provider are specified. The spatial interaction to detect is <code class="codeph">IsInside</code>, so only tweets (points) that are inside a postal boundary (polygon) will appear in the result along with their containing postal boundary.
                        </p><pre class="pre codeblock"><code>SpatialJoin spatialJoin = new SpatialJoin();
List&lt;InputDataSet&gt; inputDataSets = new ArrayList&lt;InputDataSet&gt;(2);

// set the spatial index of the 3-digit postal boundaries of the USA as the first input data set 
InputDataSet pbInputDataSet = new InputDataSet();
pbInputDataSet.setIndexName("usa_pcb3_index");

//no input format or record info provider are required here as a spatial index is provided
inputDataSets.add(pbInputDataSet);

// set the tweets data set in GeoJSON format as the second data set 
InputDataSet tweetsDataSet = new InputDataSet();
tweetsDataSet.setPaths(new Path[]{new Path("/user/example/tweets.json")});
tweetsDataSet.setInputFormatClass(GeoJsonInputFormat.class);
tweetsDataSet.setRecordInfoProviderClass(GeoJsonRecordInfoProvider.class);
inputDataSets.add(tweetsDataSet); 
 
//set input data sets
spatialJoin.setInputDataSets(inputDataSets);

//spatial operation configuration
SpatialOperationConfig spatialOpConf = new SpatialOperationConfig();
spatialOpConf.setOperation(SpatialOperation.IsInside);
spatialOpConf.setBoundaries(new double[]{47.70, -124.28, 35.45, -95.12});
spatialOpConf.setSrid(8307);
spatialOpConf.setTolerance(0.5);
spatialOpConf.setGeodetic(true);
spatialJoin.setSpatialOperationConfig(spatialOpConf); 
    
//set output path
spatialJoin.setOutput("/user/example/spatialjoin");

// prepare job
JobConf jobConf = new JobConf(getConf());

//preprocess will partition both data sets as no partitioning result file was specified
spatialJoin.preprocess(jobConf);
spatialJoin.configure(jobConf);
JobClient.runJob(jobConf);
</code></pre></div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-C127F600-72AD-4430-841A-1BB63EB2D942" name="GUID-C127F600-72AD-4430-841A-1BB63EB2D942"></a><h4 id="BDSPA-GUID-C127F600-72AD-4430-841A-1BB63EB2D942" class="sect4"><span class="enumeration_section">2.9.10 </span>Spatial Partitioning
                  </h4>
                  <div>
                     <div class="section">
                        <p>The partitioning feature is used to spatially partition one or more data sets.</p>
                        <p>Spatial partitioning consists of dividing the space into multiple rectangles, where each rectangle is intended to contain approximately the same number of points. Eventually these partitions can be used to distribute the work among reducers in other jobs, such as Spatial Join.</p>
                        <p>The spatial partitioning process is run or configured using the <code class="codeph">oracle.spatial.hadoop.mapred.job.Partitioning</code> driver class, which accepts the following input parameters:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Input data sets: One or more input data sets can be specified. Each input data set is represented using the class <code class="codeph">oracle.spatial.hadoop.vector.InputDataSet</code>, which holds information about where to find and how to read a data set, such as path(s), spatial index, input format, and record info provider used to interpret records from the data set. It also accepts a spatial configuration for the data set.
                              </p>
                           </li>
                           <li>
                              <p>Sampling ratio: Only a fraction of the entire data set or sets is used to perform the partitioning. The sample ratio is the ratio of the sample size to the whole input data set size. If it is not specified, 10 percent (0.1) of the input data set size is used.</p>
                           </li>
                           <li>
                              <p>Spatial configuration: Defines the spatial properties of the input data sets, such as the SRID. You must specify at least the dimensional boundaries.</p>
                           </li>
                           <li>
                              <p>Output path: The path where the result file will be written.</p>
                           </li>
                        </ul>
                        <p>The generated partitioning result file is in GeoJSON format and contains information for each generated partition, including the partition’s geometry and the number of points contained (from the sample).</p>
                        <p>The following example partitions a tweets data set. Because the sampling ratio is not provided, 0.1 is used by default.</p><pre class="pre codeblock"><code>Partitioning partitioning = new Partitioning();
List&lt;InputDataSet&gt; inputDataSets = new ArrayList&lt;InputDataSet&gt;(1);

//define the input data set
InputDataSet dataSet = new InputDataSet();
dataSet.setPaths(new Path[]{new Path("/user/example/tweets.json")});
dataSet.setInputFormatClass(GeoJsonInputFormat.class);
dataSet.setRecordInfoProviderClass(GeoJsonRecordInfoProvider.class);
inputDataSets.add(dataSet);
partitioning.setInputDataSets(inputDataSets);

//spatial configuration
SpatialConfig spatialConf = new SpatialConfig();
spatialConf.setSrid(8307);
spatialConf.setBoundaries(new double[]{-180,-90,180,90});
partitioning.setSpatialConfig(spatialConf);

//set output
partitioning.setOutput("/user/example/tweets_partitions.json");

//run the partitioning process
partitioning.runFullPartitioningProcess(new JobConf());
</code></pre></div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA439"></a><div class="props_rev_3"><a id="GUID-C73176F7-86C7-4743-95A7-56FCB919CF04" name="GUID-C73176F7-86C7-4743-95A7-56FCB919CF04"></a><h4 id="BDSPA-GUID-C73176F7-86C7-4743-95A7-56FCB919CF04" class="sect4"><span class="enumeration_section">2.9.11 </span>RecordInfoProvider
                  </h4>
                  <div>
                     <p>A record read by a MapReduce job from HDFS is represented in memory as a key-value pair using a Java type (typically) Writable subclass, such as LongWritable, Text, ArrayWritable or some user-defined type. For example, records read using TextInputFormat are represented in memory as LongWritable, Text key-value pairs.</p>
                     <p><code class="codeph">RecordInfoProvider</code> is the component that interprets these memory record representations and returns the data needed by the Vector Analysis API. Thus, the API is not tied to any specific format and memory representations.
                     </p>
                     <p>The <code class="codeph">RecordInfoProvider</code> interface has the following methods:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>void setCurrentRecord(K key, V value)</p>
                        </li>
                        <li>
                           <p>String getId()</p>
                        </li>
                        <li>
                           <p>JGeometry getGeometry()</p>
                        </li>
                        <li>
                           <p>boolean getExtraFields(Map&lt;String, String&gt; extraFields)</p>
                        </li>
                     </ul>
                     <p>There is always a <code class="codeph">RecordInfoProvider</code> instance per <code class="codeph">InputFormat</code>. The method <code class="codeph">setCurrentRecord()</code> is called passing the current key-value pair retrieved from the <code class="codeph">RecordReader</code>. The <code class="codeph">RecordInfoProvider</code> is then used to get the current record id, geometry, and extra fields. None of these fields are required fields. Only those records with a geometry participates in the spatial operations. The Id is useful for differentiating records in operations such as categorization. The extra fields can be used to store any record information that can be represented as text and which is desired to be quickly accessed without reading the original record, or for operations where <code class="codeph">MVSuggest</code> is used.
                     </p>
                     <p>Typically, the information returned by RecordInfoProvider is used to populate <code class="codeph">RecordInfo</code> instances. A RecordInfo can be thought as a light version of a record and contains the information returned by the RecordInfoProvider plus information to locate the original record in a file.
                     </p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-E9AA0E21-FC4A-4B05-A4B2-7C0923A5BCC7">Sample RecordInfoProvider Implementation</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-CC3EF26E-C5F6-49C9-A813-1656A7801C51">LocalizableRecordInfoProvider</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA440"></a><div class="props_rev_3"><a id="GUID-E9AA0E21-FC4A-4B05-A4B2-7C0923A5BCC7" name="GUID-E9AA0E21-FC4A-4B05-A4B2-7C0923A5BCC7"></a><h5 id="BDSPA-GUID-E9AA0E21-FC4A-4B05-A4B2-7C0923A5BCC7" class="sect5"><span class="enumeration_section">2.9.11.1 </span>Sample RecordInfoProvider Implementation
                     </h5>
                     <div>
                        <p>This sample implementation, called <code class="codeph">JsonRecordInfoProvider</code>, takes text records in JSON format, which are read using <code class="codeph">TextInputFormat</code>. A sample record is shown here:
                        </p><pre class="oac_no_warn" dir="ltr">{ "_id":"ABCD1234", "location":" 119.31669, -31.21615", "locationText":"Boston, Ma", "date":"03-18-2015", "time":"18:05", "device-type":"cellphone", "device-name":"iPhone"}
</pre><p>When a JsonRecordInfoProvider is instantiated, a JSON ObjectMapper is created. The ObjectMapper is used to parse records values later when <code class="codeph">setCurrentRecord()</code> is called. The record key is ignored. The record id, geometry, and one extra field are retrieved from the _id, location and locationText JSON properties. The geometry is represented as latitude-longitude pair and is used to create a point geometry using <code class="codeph">JGeometry.createPoint()</code> method. The extra field (locationText) is added to the extraFields map, which serves as an out parameter and true is returned indicating that an extra field was added.
                        </p><pre class="oac_no_warn" dir="ltr">public class JsonRecordInfoProvider implements RecordInfoProvider&lt;LongWritable, Text&gt; {
private Text value = null;
private ObjectMapper jsonMapper = null;
private JsonNode recordNode = null;
 
public JsonRecordInfoProvider(){
 
//json mapper used to parse all the records
 
jsonMapper = new ObjectMapper();
 
}
 
@Override
public void setCurrentRecord(LongWritable key, Text value) throws Exception {
        try{
 
           //parse the current value
 
           recordNode = jsonMapper.readTree(value.toString());
           }catch(Exception ex){
              recordNode = null;
              throw ex;
        }
}
 
@Override
public String getId() {
        String id = null;
        if(recordNode != null ){
                id = recordNode.get("_id").getTextValue();
        }
        return id;
}
@Override
public JGeometry getGeometry() {
        JGeometry geom = null;
        if(recordNode!= null){
                //location is represented as a lat,lon pair
                String location = recordNode.get("location").getTextValue();
                String[] locTokens = location.split(",");
                double lat = Double.parseDouble(locTokens[0]);
                double lon = Double.parseDouble(locTokens[1]);
                geom =  JGeometry.createPoint( new double[]{lon, lat},  2, 8307);
        }
        return geom;
}
 
@Override
public boolean getExtraFields(Map&lt;String, String&gt; extraFields) {
        boolean extraFieldsExist = false;
        if(recordNode != null) {
                extraFields.put("locationText", recordNode.get("locationText").getTextValue() );
                extraFieldsExist = true;
        }
        return extraFieldsExist;
}
}</pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C73176F7-86C7-4743-95A7-56FCB919CF04">RecordInfoProvider</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="BDSPA441"></a><div class="props_rev_3"><a id="GUID-CC3EF26E-C5F6-49C9-A813-1656A7801C51" name="GUID-CC3EF26E-C5F6-49C9-A813-1656A7801C51"></a><h5 id="BDSPA-GUID-CC3EF26E-C5F6-49C9-A813-1656A7801C51" class="sect5"><span class="enumeration_section">2.9.11.2 </span>LocalizableRecordInfoProvider
                     </h5>
                     <div>
                        <p>This interface extends <code class="codeph">RecordInfoProvider</code> and is used to know the extra fields that can be used as the search text, when <code class="codeph">MVSuggest</code> is used.
                        </p>
                        <p>The only method added by this interface is <code class="codeph">getLocationServiceField()</code>, which returns the name of the extra field that will be sent to MVSuggest. 
                        </p>
                        <p>In addition, the following is an implementation based on <span class="q">"<a href="using-big-data-spatial-graph-spatial-data.html#GUID-E9AA0E21-FC4A-4B05-A4B2-7C0923A5BCC7">Sample RecordInfoProvider Implementation</a>."</span> The name returned in this example is <code class="codeph">locationText</code>, which is the name of the extra field included in the parent class.
                        </p><pre class="oac_no_warn" dir="ltr">public class LocalizableJsonRecordInfoProvider extends JsonRecordInfoProvider implements LocalizableRecordInfoProvider&lt;LongWritable, Text&gt; {
 
@Override
public String getLocationServiceField() {
	return  "locationText";
}
}</pre><p>An alternative to <code class="codeph">LocalizableRecordInfoProvider</code> is to set the configuration property <code class="codeph">oracle.spatial.recordInfo.locationField</code> with the name of the search field, which value should be sent to <code class="codeph">MVSuggest</code>. Example: <code class="codeph">configuration.set(LocatizableRecordInfoProvider.CONF_RECORD_INFO_LOCATION_FIELD, “locationField”)</code></p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C73176F7-86C7-4743-95A7-56FCB919CF04">RecordInfoProvider</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="BDSPA442"></a><div class="props_rev_3"><a id="GUID-737CAF49-D97B-47ED-BA5D-B10E1E0F82BF" name="GUID-737CAF49-D97B-47ED-BA5D-B10E1E0F82BF"></a><h4 id="BDSPA-GUID-737CAF49-D97B-47ED-BA5D-B10E1E0F82BF" class="sect4"><span class="enumeration_section">2.9.12 </span>HierarchyInfo
                  </h4>
                  <div>
                     <p>The <code class="codeph">HierarchyInfo</code> interface is used to describe a hierarchical dataset. This implementation of HierarchyInfo is expected to provide the number, names, and the entries of the hierarchy levels of the hierarchy it describes.
                     </p>
                     <p>The root hierarchy level is always the hierarchy level 1. The entries in this level do not have parent entries and this level is referred as the top hierarchy level. Children hierarchy levels will have higher level values. For example: the levels for the hierarchy conformed by continents, countries, and states are 1, 2 and 3 respectively. Entries in the continent layer do not have a parent, but have children entries in the countries layer. Entries at the bottom level, the states layer, do not have children.</p>
                     <p>A HierarchyInfo implementation is provided out of the box with the Vector Analysis API. The <code class="codeph">DynaAdminHierarchyInfo</code> implementation can be used to read and describe the known hierarchy layers in GeoJSON format. A DynaAdminHierarchyInfo can be instantiated and configured or can be subclassed. The hierarchy layers to be contained are specified by calling the <code class="codeph">addLevel()</code> method, which takes the following parameters:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>The hierarchy level number</p>
                        </li>
                        <li>
                           <p>The hierarchy level name, which must match the file name (without extension) of the GeoJSON file that contains the data. For example, the hierarchy level name for the file <code class="codeph">world_continents.json</code> must be <code class="codeph">world_continents</code>, for <code class="codeph">world_countries.json</code> it is <code class="codeph">world_countries</code>, and so on.
                           </p>
                        </li>
                        <li>
                           <p>Children join field: This is a JSON property that is used to join entries of the current level with child entries in the lower level. If a null is passed, then the entry id is used.</p>
                        </li>
                        <li>
                           <p>Parent join field: This is a JSON property used to join entries of the current level with parent entries in the upper level. This value is not used for the top most level without an upper level to join. If the value is set null for any other level greater than 1, an <code class="codeph">IsInside</code> spatial operation is performed to join parent and child entries. In this scenario, it is supposed that an upper level geometry entry can contain lower level entries.
                           </p>
                        </li>
                     </ul>
                     <p>For example, let us assume a hierarchy containing the following levels from the specified layers: 1- world_continents, 2 - world_countries and 3 - world_states_provinces. A sample entry from each layer would look like the following:</p><pre class="oac_no_warn" dir="ltr">world_continents:
 {"type":"Feature","_id":"NA","geometry": {"type":"MultiPolygon", "coordinates":[ x,y,x,y,x,y] }"properties":{"NAME":"NORTH AMERICA", "CONTINENT_LONG_LABEL":"North America"},"label_box":[-118.07998,32.21006,-86.58515,44.71352]}

world_countries: {"type":"Feature","_id":"iso_CAN","geometry":{"type":"MultiPolygon","coordinates":[x,y,x,y,x,y]},"properties":{"NAME":"CANADA","CONTINENT":"NA","ALT_REGION":"NA","COUNTRY CODE":"CAN"},"label_box":[-124.28092,49.90408,-94.44878,66.89287]}

world_states_provinces:
{"type":"Feature","_id":"6093943","geometry": {"type":"Polygon", "coordinates":[ x,y,x,y,x,y]},"properties":{"COUNTRY":"Canada", "ISO":"CAN", "STATE_NAME":"Ontario"},"label_box":[-91.84903,49.39557,-82.32462,54.98426]}
</pre><p>A DynaAdminHierarchyInfo can be configured to create a hierarchy with the above layers in the following way:</p><pre class="oac_no_warn" dir="ltr">DynaAdminHierarchyInfo dahi = new DynaAdminHierarchyInfo();
 
dahi.addLevel(1, "world_continents", null /*_id is used by default to join with child entries*/, null /*not needed as there are not upper hierarchy levels*/);
 
dahi.addLevel(2, "world_countries", "properties.COUNTRY CODE"/*field used to join with child entries*/, "properties.CONTINENT" /*the value "NA" will be used to find Canada's parent which is North America and which _id field value is also "NA" */);
 
dahi.addLevel(3, "world_states_provinces", null /*not needed as not child entries are expected*/, "properties.ISO"/*field used to join with parent entries. For Ontario, it is the same value than the field properties.COUNTRY CODE specified for Canada*/);
 
//save the previous configuration to the job configuration
 
dahi.initialize(conf);
</pre><p>A similar configuration can be used to create hierarchies from different layers, such as countries, states and counties, or any other layers with a similar JSON format.</p>
                     <p>Alternatively, to avoid configuring a hierarchy every time a job is executed, the hierarchy configuration can be enclosed in a DynaAdminHierarchyInfo subclass as in the following example:</p><pre class="oac_no_warn" dir="ltr">public class WorldDynaAdminHierarchyInfo extends DynaAdminHierarchyInfo \
 
{
       public WorldDynaAdminHierarchyInfo() 
 
       {
              super();
              addLevel(1, "world_continents", null, null);
              addLevel(2, "world_countries", "properties.COUNTRY CODE", "properties.CONTINENT");
              addLevel(3, "world_states_provinces", null, "properties.ISO");
       }
 
}</pre></div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-DE6F398B-554F-4AB8-B3E1-3D166C71D678">Sample HierarchyInfo Implementation</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="BDSPA443"></a><div class="props_rev_3"><a id="GUID-DE6F398B-554F-4AB8-B3E1-3D166C71D678" name="GUID-DE6F398B-554F-4AB8-B3E1-3D166C71D678"></a><h5 id="BDSPA-GUID-DE6F398B-554F-4AB8-B3E1-3D166C71D678" class="sect5"><span class="enumeration_section">2.9.12.1 </span>Sample HierarchyInfo Implementation
                     </h5>
                     <div>
                        <p>The <code class="codeph">HierarchyInfo</code> interface contains the following methods, which must be implemented to describe a hierarchy. The methods can be divided in to the following three categories: 
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Methods to describe the hierarchy</p>
                           </li>
                           <li>
                              <p>Methods to load data</p>
                           </li>
                           <li>
                              <p>Methods to supply data</p>
                           </li>
                        </ul>
                        <p>Additionally there is an <code class="codeph">initialize() </code>method, which can be used to perform any initialization and to save and read data both to and from the job configuration
                        </p><pre class="oac_no_warn" dir="ltr">void initialize(JobConf conf);	
 
//methods to describe the hierarchy
 
String getLevelName(int level);	
int getLevelNumber(String levelName);
int getNumberOfLevels();
 
//methods to load data
 
void load(Path[] hierDataPaths, int fromLevel, JobConf conf) throws Exception;
void loadFromIndex(HierarchyDataIndexReader[] readers, int fromLevel, JobConf conf) throws Exception;
 
//methods to supply data
 
Collection&lt;String&gt; getEntriesIds(int level);
JGeometry getEntryGeometry(int level, String entryId);	
String getParentId(int childLevel, String childId);
</pre><p>The following is a sample HierarchyInfo implementation, which takes the previously mentioned world layers as the hierarchy levels. The first section contains the initialize method and the methods used to describe the hierarchy. In this case, the initialize method does nothing. The methods mentioned in the following example use the <code class="codeph">hierarchyLevelNames</code> array to provide the hierarchy description. The instance variables <code class="codeph">entriesGeoms</code> and <code class="codeph">entriesParent</code> are arrays of <code class="codeph">java.util.Map</code>, which contains the entries geometries and entries parents respectively. The entries ids are used as keys in both cases. Since the arrays indices are zero-based and the hierarchy levels are one-based, the array indices correlate to the hierarchy levels as <span class="italic">array index + 1 = hierarchy level</span>.
                        </p><pre class="oac_no_warn" dir="ltr">public class WorldHierarchyInfo implements HierarchyInfo 
{
 
       private String[] hierarchyLevelNames = {"world_continents", "world_countries", "world_states_provinces"};
       private Map&lt;String, JGeometry&gt;[] entriesGeoms = new Map[3];
       private Map&lt;String, String&gt;[] entriesParents = new Map[3];
 
       @Override
       public void initialize(JobConf conf) 
      {

         //do nothing for this implementation
}

        @Override
        public int getNumberOfLevels() 
        {
          return hierarchyLevelNames.length;
}
 
        @Override
        public String getLevelName(int level) 
        {
           String levelName = null;
           if(level &gt;=1 &amp;&amp; level &lt;= hierarchyLevelNames.length)
           {
             levelName = hierarchyLevelNames[ level - 1];    
           }
         return levelName;
         }

        @Override
        public int getLevelNumber(String levelName) 
        {
           for(int i=0; i&lt; hierarchyLevelNames.length; i++ ) 
           {
             if(hierarchyLevelNames.equals( levelName) ) return i+1;
   }
   return -1;
}
</pre><p>The following example contains the methods that load the different hierarchy levels data. The <code class="codeph">load()</code> method reads the data from the source files <code class="codeph">world_continents.json</code>, <code class="codeph">world_countries.json</code>, and <code class="codeph">world_states_provinces.json</code>. For the sake of simplicity, the internally called <code class="codeph">loadLevel()</code> method is not specified, but it is supposed to parse and read the JSON files.
                        </p>
                        <p>The <code class="codeph">loadFromIndex()</code> method only takes the information provided by the <code class="codeph">HierarchyIndexReader</code> instances passed as parameters. The <code class="codeph">load()</code> method is supposed to be executed only once and only if a hierarchy index has not been created, in a job. Once the data is loaded, it is automatically indexed and <code class="codeph">loadFromIndex()</code> method is called every time the hierarchy data is loaded into the memory.
                        </p><pre class="oac_no_warn" dir="ltr">      @Override
      public void load(Path[] hierDataPaths, int fromLevel, JobConf conf) throws Exception {
      int toLevel = fromLevel + hierDataPaths.length - 1;
      int levels = getNumberOfLevels();
 
      for(int i=0, level=fromLevel; i&lt;hierDataPaths.length &amp;&amp; level&lt;=levels; i++, level++)
      {
 
         //load current level from the current path
 
         loadLevel(level, hierDataPaths[i]);
       }
    }
 
    @Override
    public void loadFromIndex(HierarchyDataIndexReader[] readers, int fromLevel, JobConf conf)
                 throws Exception 
    {
     Text parentId = new Text();
     RecordInfoArrayWritable records = new RecordInfoArrayWritable();
     int levels = getNumberOfLevels();
 
     //iterate through each reader to load each level's entries
 
     for(int i=0, level=fromLevel; i&lt;readers.length &amp;&amp; level&lt;=levels; i++, level++)
     {
       entriesGeoms[ level - 1 ] = new Hashtable&lt;String, JGeometry&gt;();
       entriesParents[ level - 1 ] = new Hashtable&lt;String, String&gt;();
 
       //each entry is a parent record id (key) and a list of entries as RecordInfo (value)
 
       while(readers[i].nextParentRecords(parentId, records))
       {
          String pId = null;
 
          //entries with no parent will have the parent id UNDEFINED_PARENT_ID. Such is the case of the first level entries
 
           if( ! UNDEFINED_PARENT_ID.equals( parentId.toString() ) )
           {
           pId = parentId.toString();
           }
 
         //add the current level's entries
 
           for(Object obj : records.get())
           {
              RecordInfo entry = (RecordInfo) obj;
              entriesGeoms[ level - 1 ].put(entry.getId(), entry.getGeometry());
              if(pId != null) 
              {
              entriesParents[ level -1 ].put(entry.getId(), pId);
              }
           }//finishin loading current parent entries
        }//finish reading single hierarchy level index
     }//finish iterating index readers
}
</pre><p>Finally, the following code listing contains the methods used to provide information of individual entries in each hierarchy level. The information provided is the ids of all the entries contained in a hierarchy level, the geometry of each entry, and the parent of each entry.</p><pre class="oac_no_warn" dir="ltr">@Override
public Collection&lt;String&gt; getEntriesIds(int level) 
{
   Collection&lt;String&gt; ids = null;
 
   if(level &gt;= 1 &amp;&amp; level &lt;= getNumberOfLevels() &amp;&amp; entriesGeoms[ level - 1 ] != null)
   {
 
     //returns the ids of all the entries from the given level
 
     ids = entriesGeoms[ level - 1 ].keySet();
   }
   return ids;
}
 
@Override
public JGeometry getEntryGeometry(int level, String entryId) 
{
   JGeometry geom = null;
   if(level &gt;= 1 &amp;&amp; level &lt;= getNumberOfLevels() &amp;&amp; entriesGeoms[ level - 1 ] != null)
   {
 
      //returns the geometry of the entry with the given id and level
 
      geom = entriesGeoms[ level - 1 ].get(entryId);
    }
    return geom;
}
 
@Override
public String getParentId(int childLevel, String childId) 
{
   String parentId = null;
   if(childLevel &gt;= 1 &amp;&amp; childLevel &lt;= getNumberOfLevels() &amp;&amp; entriesGeoms[ childLevel - 1 ] != null)
   {
 
      //returns the parent id of the entry with the given id and level
 
      parentId = entriesParents[ childLevel - 1 ].get(childId);
   }
   return parentId;
   }
}//end of class</pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-737CAF49-D97B-47ED-BA5D-B10E1E0F82BF">HierarchyInfo</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="BDSPA444"></a><div class="props_rev_3"><a id="GUID-400F3157-36A6-4C7E-B2CB-A870DCC1E123" name="GUID-400F3157-36A6-4C7E-B2CB-A870DCC1E123"></a><h4 id="BDSPA-GUID-400F3157-36A6-4C7E-B2CB-A870DCC1E123" class="sect4"><span class="enumeration_section">2.9.13 </span>Using JGeometry in MapReduce Jobs
                  </h4>
                  <div>
                     <p>The Spatial Hadoop Vector Analysis only contains a small subset of the functionality provided by the Spatial Java API, which can also be used in the MapReduce jobs. This section provides some simple examples of how JGeometry can be used in Hadoop for spatial processing. The following example contains a simple mapper that performs the <code class="codeph">IsInside</code> test between a dataset and a query geometry using the JGeometry class.
                     </p>
                     <p>In this example, the query geometry ordinates, srid, geodetic value and tolerance used in the spatial operation are retrieved from the job configuration in the configure method. The query geometry, which is a polygon, is preprocessed to quickly perform the <code class="codeph">IsInside</code> operation.
                     </p>
                     <p>The map method is where the spatial operation is executed. Each input record value is tested against the query geometry and the id is returned, when the test succeeds.</p><pre class="oac_no_warn" dir="ltr">public class IsInsideMapper extends MapReduceBase implements Mapper&lt;LongWritable, Text, NullWritable, Text&gt;
{
       private JGeometry queryGeom = null;
       private int srid = 0;
       private double tolerance = 0.0;
       private boolean geodetic = false;
       private Text outputValue = new Text();
       private double[] locationPoint = new double[2];
	
	
       @Override
       public void configure(JobConf conf) 
       {
           super.configure(conf);
           srid = conf.getInt("srid", 8307);
           tolerance = conf.getDouble("tolerance", 0.0);
           geodetic = conf.getBoolean("geodetic", true);
 
    //The ordinates are represented as a string of comma separated double values
           
            String[] ordsStr = conf.get("ordinates").split(",");
            double[] ordinates = new double[ordsStr.length];
            for(int i=0; i&lt;ordsStr.length; i++)
            {
              ordinates[i] = Double.parseDouble(ordsStr[i]);
             }
 
    //create the query geometry as two-dimensional polygon and the given srid
 
             queryGeom = JGeometry.createLinearPolygon(ordinates, 2, srid);
 
    //preprocess the query geometry to make the IsInside operation run faster
 
              try 
              {
                queryGeom.preprocess(tolerance, geodetic, EnumSet.of(FastOp.ISINSIDE));
               } 
               catch (Exception e) 
               {
                 e.printStackTrace();
                }
		
          }
	
          @Override
          public void map(LongWritable key, Text value,
                      OutputCollector&lt;NullWritable, Text&gt; output, Reporter reporter)
                      throws IOException 
          {
 
     //the input value is a comma separated values text with the following columns: id, x-ordinate, y-ordinate
 
           String[] tokens = value.toString().split(",");
     
     //create a geometry representation of the record's location
 
            locationPoint[0] = Double.parseDouble(tokens[1]);//x ordinate
            locationPoint[1] = Double.parseDouble(tokens[2]);//y ordinate
            JGeometry location = JGeometry.createPoint(locationPoint, 2, srid);
 
     //perform spatial test
 
            try 
            {
              if( location.isInside(queryGeom, tolerance, geodetic)){
 
               //emit the record's id
 
               outputValue.set( tokens[0] );
               output.collect(NullWritable.get(), outputValue);
             }
     } 
             catch (Exception e) 
             {
                e.printStackTrace();
              }
}
}
</pre><p>A similar approach can be used to perform a spatial operation on the geometry itself. For example, by creating a buffer. The following example uses the same text value format and creates a buffer around each record location. The mapper output key and value are the record id and the generated buffer, which is represented as a <code class="codeph">JGeometryWritable</code>. The <code class="codeph">JGeometryWritable</code> is a Writable implementation contained in the Vector Analysis API that holds a JGeometry instance.
                     </p><pre class="oac_no_warn" dir="ltr">public class BufferMapper extends MapReduceBase implements Mapper&lt;LongWritable, Text, Text, JGeometryWritable&gt; 
{
       private int srid = 0;
       private double bufferWidth = 0.0;
       private Text outputKey = new Text();
       private JGeometryWritable outputValue = new JGeometryWritable();
       private double[] locationPoint = new double[2];
 
       @Override
       public void configure(JobConf conf)
       {
              super.configure(conf);
              srid = conf.getInt("srid", 8307);
 
              //get the buffer width 
 
              bufferWidth = conf.getDouble("bufferWidth", 0.0);
        }
 
        @Override
        public void map(LongWritable key, Text value,
               OutputCollector&lt;Text, JGeometryWritable&gt; output, Reporter reporter)
               throws IOException 
        {
 
               //the input value is a comma separated record with the following columns: id, longitude, latitude
 
               String[] tokens = value.toString().split(",");
 
               //create a geometry representation of the record's location
 
               locationPoint[0] = Double.parseDouble(tokens[1]);
               locationPoint[1] = Double.parseDouble(tokens[2]);
               JGeometry location = JGeometry.createPoint(locationPoint, 2, srid);
 
               try 
               {
 
                  //create the location's buffer
 
                  JGeometry buffer = location.buffer(bufferWidth);
 
                  //emit the record's id and the generated buffer
 
                  outputKey.set( tokens[0] );
                  outputValue.setGeometry( buffer );
                  output.collect(outputKey, outputValue);
                }
 
                catch (Exception e)
                {
                   e.printStackTrace();
                 }
        }
}</pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-4FDCF66B-0136-418A-B072-E400E9844B55" name="GUID-4FDCF66B-0136-418A-B072-E400E9844B55"></a><h4 id="BDSPA-GUID-4FDCF66B-0136-418A-B072-E400E9844B55" class="sect4"><span class="enumeration_section">2.9.14 </span>Support for Different Data Sources
                  </h4>
                  <div>
                     <p>In addition to file-based data sources (that is, a file or a set of files from a local or a distributed file system), other types of data sources can be used as the input data for a Vector API job.</p>
                     <p>Data sources are referenced as input data sets in the Vector API. All the input data sets implement the interface <code class="codeph">oracle.spatial.hadoop.vector.data.AbstractInputDataSet</code>. Input data set properties can be set directly for a Vector job using the methods <code class="codeph">setInputFormatClass()</code>, <code class="codeph">setRecordInfoProviderClass()</code>, and <code class="codeph">setSpatialConfig()</code>. More information can be set, depending the type of input data set. For example, <code class="codeph">setInput()</code> can specify the input string for a file data source, or <code class="codeph">setIndexName()</code> can be used for a spatial index. The job determines the input data type source based on the properties that are set.
                     </p>
                     <p>Input data set information can also be set directly for a Vector API job using the job’s method <code class="codeph">setInputDataSet()</code>. With this method, the input data source information is encapsulated, you have more control, and it is easier to identify the type of data source that is being used.
                     </p>
                     <p>The Vector API provides the following implementations of <code class="codeph">AsbtractInputDataSet</code>:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">SimpleInputDataSet</code>: Contains the minimum information required by the Vector API for an input data set. Typically, this type of input data set should be used for non-file based input data sets, such as Apache Hbase, an Oracle database, or any other non-file-based data source.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">FileInputDataSet</code>: Encapsulates file-based input data sets from local or distributed file systems. It provides properties for setting the input path as an array of Path instances or as a string that can be a regular expression for selecting paths.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">SpatialIndexInputDataSet</code>: A subclass of <code class="codeph">FileInputDataSet</code> optimized for working with spatial indexes generated by the Vector API. It is sufficient to specify the index name for this type of input data set.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">NoSQLInputDataSet</code>: Specifies Oracle NoSQL data sources. It should be used in conjunction with Vector NoSQL API. If the NoSQL <code class="codeph">KVInputFormat</code> or <code class="codeph">TableInputFormat</code> classes need to be used, use <code class="codeph">SimpleInputFormat</code> instead.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">MultiInputDataSet</code>: Input data set that encapsulates two or more input data sets.
                           </p>
                        </li>
                     </ul>
                     <div class="section">
                        <p class="subhead3">Multiple Input Data Sets</p>
                        <p>Most of the Hadoop jobs provided by the Vector API (except Categorization) are able to manage more than one input data set by using the class <code class="codeph">oracle.spatial.hadoop.vector.data.MultiInputDataSet</code>.
                        </p>
                        <p>To add more than one input data set to a job, follow these steps.</p>
                        <ol>
                           <li>
                              <p>Create and configure two or more instances of <code class="codeph">AbstractInputDataSet</code> subclasses.
                              </p>
                           </li>
                           <li>
                              <p>Create an instance of <code class="codeph">oracle.spatial.hadoop.vector.data.MultiInputDataSet</code>.
                              </p>
                           </li>
                           <li>
                              <p>Add the input data sets created in step 1 to the <code class="codeph">MultiInputDataSet</code> instance.
                              </p>
                           </li>
                           <li>
                              <p>Set <code class="codeph">MultiInputDataSet</code> instance as the job’s input data set.
                              </p>
                           </li>
                        </ol>
                        <p>The following code snippet shows how to set multiple input data sets to a Vector API.</p><pre class="pre codeblock"><code>//file input data set
FileInputDataSet fileDataSet = new FileInputDataSet();
fileDataSet.setInputFormatClass(GeoJsonInputFormat.class);
fileDataSet.setRecordInfoProviderClass(GeoJsonRecordInfoProvider.class);
fileDataSet.setInputString("/user/myUser/geojson/*.json");
		
//spatial index input data set
SpatialIndexInputDataSet indexDataSet = new SpatialIndexInputDataSet();
indexDataSet.setIndexName("myIndex");
		
//create multi input data set
MultiInputDataSet multiDataSet = new MultiInputDataSet();
		
//add the previously defined input data sets
multiDataSet.addInputDataSet(fileDataSet);
multiDataSet.addInputDataSet(indexDataSet);
		
Binning binningJob = new Binning();
//set multiple input data sets to the job
binningJob.setInputDataSet(multiDataSet);
</code></pre></div>
                     <!-- class="section" -->
                     <div class="section">
                        <p class="subhead3">NoSQL Input Data Set</p>
                        <p>The Vector API provides classes to read data from Oracle NoSQL Database. The Vector NoSQL components let you group multiple key-value pairs into single records, which are passed to Hadoop mappers as <code class="codeph">RecordInfo</code> instances. They also let you map NoSQL entries (key and value) to Hadoop records fields (<code class="codeph">RecordInfo</code>’s <code class="codeph">id</code>, <code class="codeph">geometry</code>, and extra fields).
                        </p>
                        <p>The NoSQL parameters are passed to a Vector job using the <code class="codeph">NoSQLInputDataSet</code> class. You only need to fill and set a <code class="codeph">NoSQLConfiguration</code> instance that contains the KV store, hosts, parent key, and additional information for the NoSQL data source. <code class="codeph">InputFormat</code> and <code class="codeph">RecordInfoProvider</code> classes do not need to be set because the default ones are used.
                        </p>
                        <p>The following example shows how to configure a job to use NoSQL as data source, using the Vector NoSQL classes. </p><pre class="pre codeblock"><code>//create NoSQL configuration
NoSQLConfiguration nsqlConf = new NoSQLConfiguration();
// set connection data
nsqlConf.setKvStoreName("mystore");
nsqlConf.setKvStoreHosts(new String[] { "myserver:5000" });
nsqlConf.setParentKey(Key.createKey("tweets"));
// set NoSQL entries to be included in the Hadoop records
// the entries with the following minor keys will be set as the
// RecordInfo's extra fields
nsqlConf.addTargetEntries(new String[] { "friendsCount", "followersCount" });
// add an entry processor to map the spatial entry to a RecordInfo's
// geometry
nsqlConf.addTargetEntry("geometry", NoSQLJGeometryEntryProcessor.class);
//create and set the NoSQL input data set
NoSQLInputDataSet nsqlDataSet = new NoSQLInputDataSet();
//set noSQL configuration
nsqlDataSet.setNoSQLConfig(nsqlConf);
//set spatial configuration
SpatialConfig spatialConf = new SpatialConfig();
spatialConf.setSrid(8307);
nsqlDataSet.setSpatialConfig(spatialConf);
</code></pre><p>Target entries refer to the NoSQL entries that will be part of the Hadoop records and are specified by the NoSQL minor keys. In the preceding example, the entries with the minor keys <code class="codeph">friendsCount</code> and <code class="codeph">followersCount</code> will be part of a Hadoop record. These NoSQL entries will be parsed as text values and assigned to the Hadoop <code class="codeph">RecordInfo</code> as the extra fields called <code class="codeph">friendsCount</code> and <code class="codeph">followersCount</code>. By default, the major key is used as record id. The entries that contain “geometry” as minor key are used to set the <code class="codeph">RecordInfo</code>’s <code class="codeph">geometry</code> field. 
                        </p>
                        <p>In the preceding example, the value type of the geometry NoSQL entries is <code class="codeph">JGeometry</code>, so it is necessary to specify a class to parse the value and assign it to the <code class="codeph">RecordInfo</code>’s <code class="codeph">geometry</code> field. This requires setting an implementation of the <code class="codeph">NoSQLEntryProcessor</code> interface. In this case, the <code class="codeph">NoSQLJGeometryEntryProcessor</code> class is used, and it reads the value from the NoSQL entry and sets that value to the current <code class="codeph">RecordInfo</code>’s <code class="codeph">geometry</code> field. You can provide your own implementation of <code class="codeph">NoSQLEntryProcessor</code> for parsing specific entry formats.
                        </p>
                        <p>By default, NoSQL entries sharing the same major key are grouped into the same Hadoop record. This behavior can be changed by implementing the interface <code class="codeph">oracle.spatial.hadoop.nosql.NoSQLGrouper</code> and setting the <code class="codeph">NoSQLConfiguration</code> property <code class="codeph">entryGrouperClass</code> with the new grouper class.
                        </p>
                        <p>The Oracle NoSQL library <code class="codeph">kvstore.jar</code> is required when running Vector API jobs that use NoSQL as the input data source.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <div class="section">
                        <p class="subhead3">Other Non-File-Based Data Sources</p>
                        <p>Other non-file-based data sources can be used with the Vector API, such as NoSQL (using the Oracle NoSQL classes) and Apache HBase. Although the Vector API does not provide specific classes to manage every type of data source, you can associate the specific data source with the job configuration and specify the following information to the Vector job:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph">InputFormat</code>: The <code class="codeph">InputFormat</code> implementation used to read data from the data source.
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph">RecordInfoProvider</code>: An implementation of <code class="codeph">RecordInfoProvider</code> to extract required information such as <code class="codeph">id</code>, spatial information, and extra fields from the key-value pairs returned by the current InputFormat.
                              </p>
                           </li>
                           <li>
                              <p>Spatial configuration: Describes the spatial properties of the input data, such as the SRID and the dimension boundaries.</p>
                           </li>
                        </ul>
                        <p>The following example shows how to use Apache HBase data in a Vector job. </p><pre class="pre codeblock"><code>//create job
Job job = Job.getInstance(getConf());
job.setJobName(getClass().getName());
job.setJarByClass(getClass());

//Setup hbase parameters
Scan scan = new Scan();
scan.setCaching(500);
scan.setCacheBlocks(false);
scan.addColumn(Bytes.toBytes("location_data"), Bytes.toBytes("geometry"));
scan.addColumn(Bytes.toBytes("other_data"), Bytes.toBytes("followers_count"));
scan.addColumn(Bytes.toBytes("other_data"), Bytes.toBytes("user_id"));

//initialize job configuration with hbase parameters
TableMapReduceUtil.initTableMapperJob(
		"tweets_table",
		scan,
		null,
		null,
		null,
		job);
//create binning job
Binning&lt;ImmutableBytesWritable, Result&gt; binningJob = new Binning&lt;ImmutableBytesWritable, Result&gt;();
//setup the input data set 
SimpleInputDataSet inputDataSet = new SimpleInputDataSet();
//use HBase's TableInputFormat
inputDataSet.setInputFormatClass(TableInputFormat.class);
//Set a RecordInfoProvider which can extract information from HBase TableInputFormat's returned key and values
inputDataSet.setRecordInfoProviderClass(HBaseRecordInfoProvider.class);
//set spatial configuration
SpatialConfig spatialConf = new SpatialConfig();
spatialConf.setSrid(8307);
inputDataSet.setSpatialConfig(spatialConf);
binningJob.setInputDataSet(inputDataSet);

//job output
binningJob.setOutput("hbase_example_output");

//binning configuration
BinningConfig binConf = new BinningConfig();
binConf.setGridMbr(new double[]{-180, -90, 180, 90});
binConf.setCellHeight(5);
binConf.setCellWidth(5);
binningJob.setBinConf(binConf);

//configure the job
binningJob.configure(job);

//run
boolean success = job.waitForCompletion(true);
</code></pre><p>The <code class="codeph">RecordInfoProvider</code> class set in the preceding example is a custom implementation called <code class="codeph">HBaseRecordInfoProvider</code>, the definition of which is as follows.
                        </p><pre class="oac_no_warn" dir="ltr">public class HBaseRecordInfoProvider implements RecordInfoProvider&lt;ImmutableBytesWritable, Result&gt;, Configurable{
	
	private Result value = null;
	private Configuration conf = null;
	private int srid = 0;

	@Override
	public void setCurrentRecord(ImmutableBytesWritable key, Result value) throws Exception {
		this.value = value;
	}

	@Override
	public String getId() {
		byte[] idb = value.getValue(Bytes.toBytes("other_data"), Bytes.toBytes("user_id"));
		String id = idb != null ? Bytes.toString(idb) : null;
		return id;
	}

	@Override
	public JGeometry getGeometry() {
		byte[] geomb = value.getValue(Bytes.toBytes("location_data"), Bytes.toBytes("geometry"));
		String geomStr = geomb!=null ? Bytes.toString(geomb) : null;
		JGeometry geom = null;
		if(geomStr != null){
			String[] pointsStr = geomStr.split(",");
			geom = JGeometry.createPoint(new double[]{Double.valueOf(pointsStr[0]), Double.valueOf(pointsStr[1])}, 2, srid);
		}
		return geom;
	}

	@Override
	public boolean getExtraFields(Map&lt;String, String&gt; extraFields) {
		byte[] fcb =  value.getValue(Bytes.toBytes("other_data"), Bytes.toBytes("followers_count"));
		if(fcb!=null){
			extraFields.put("followers_count", Bytes.toString(fcb));
		}
		return fcb!=null;
	}

	@Override
	public Configuration getConf() {
		return conf;
	}

	@Override
	public void setConf(Configuration conf) {
		srid = conf.getInt(ConfigParams.SRID, 0);
	}
	
} 
</pre></div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-A25B2252-63BF-4656-A2EB-F0A3DA0982E2" name="GUID-A25B2252-63BF-4656-A2EB-F0A3DA0982E2"></a><h4 id="BDSPA-GUID-A25B2252-63BF-4656-A2EB-F0A3DA0982E2" class="sect4"><span class="enumeration_section">2.9.15 </span>Job Registry
                  </h4>
                  <div>
                     <p>Every time a Vector API job is launched using the command line interface or the web console, a registry file is created for that job. A job registry file contains the following information about the job:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Job name</p>
                        </li>
                        <li>
                           <p>Job ID</p>
                        </li>
                        <li>
                           <p>User that executed the job</p>
                        </li>
                        <li>
                           <p>Start and finish time</p>
                        </li>
                        <li>
                           <p>Parameters used to run the job</p>
                        </li>
                        <li>
                           <p>Jobs launched by the first job (called <span class="italic">child jobs</span>). Child jobs contain the same fields as the parent job.
                           </p>
                        </li>
                     </ul>
                     <p>A job registry file preserves the parameters used to run the job, which can be used as an aid for running an identical job even when it was not initially run using the command line interface.</p>
                     <p>By default, job registry files are created under the HDFS path relative to the user folder <code class="codeph">oracle_spatial/job_registry</code> (for example, <code class="codeph">/user/hdfs/oracle_spatial/job_registry</code> for the hdfs user).
                     </p>
                     <p>Job registry files can be removed directly using HDFS commands or using the following utility methods from class <code class="codeph">oracle.spatial.hadoop.commons.logging.registry.RegistryManager</code>:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">public static int removeJobRegistry(long beforeDate, Configuration conf)</code>: Removes all the job registry files that were created before the specified  time stamp from<span class="italic"> the default</span> job registry folder.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">public static int removeJobRegistry(Path jobRegDirPath, long beforeDate, Configuration conf)</code>: Removes all the job registry files that were created before the specified  time stamp from <span class="italic">a specified</span> job registry folder.
                           </p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA453"></a><a id="BDSPA452"></a><div class="props_rev_3"><a id="GUID-6718ACA8-E625-4A03-8895-1452402FBE1F" name="GUID-6718ACA8-E625-4A03-8895-1452402FBE1F"></a><h4 id="BDSPA-GUID-6718ACA8-E625-4A03-8895-1452402FBE1F" class="sect4"><span class="enumeration_section">2.9.16 </span>Tuning Performance Data of Job Running Times Using the Vector Analysis API
                  </h4>
                  <div>
                     <p>The table lists some running times for jobs built using the Vector Analysis API. The jobs were executed using a 4-node cluster. The times may vary depending on the characteristics of the cluster. The test dataset contains over One billion records and the size is above 1 terabyte. </p>
                     <div class="tblformal" id="GUID-6718ACA8-E625-4A03-8895-1452402FBE1F__GUID-DA79DDC3-EA29-4F64-8C53-5C4C3891C41E">
                        <p class="titleintable">Table 2-4 Performance time for running jobs using Vector Analysis API</p>
                        <table cellpadding="4" cellspacing="0" class="Formal" title="Performance time for running jobs using Vector Analysis API" summary="Performance time for running jobs using Vector Analysis API" width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="45%" id="d8066e9780">Job Type</th>
                                 <th align="left" valign="bottom" width="55%" id="d8066e9783">Time taken (approximate value)</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="45%" id="d8066e9788" headers="d8066e9780 ">
                                    <p>Spatial Indexing</p>
                                 </td>
                                 <td align="left" valign="top" width="55%" headers="d8066e9788 d8066e9783 ">
                                    <p>2 hours</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="45%" id="d8066e9795" headers="d8066e9780 ">
                                    <p>Spatial Filter with Spatial Index</p>
                                 </td>
                                 <td align="left" valign="top" width="55%" headers="d8066e9795 d8066e9783 ">
                                    <p>1 hour</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="45%" id="d8066e9802" headers="d8066e9780 ">
                                    <p>Spatial Filter without Spatial Index</p>
                                 </td>
                                 <td align="left" valign="top" width="55%" headers="d8066e9802 d8066e9783 ">
                                    <p>3 hours</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="45%" id="d8066e9809" headers="d8066e9780 ">
                                    <p>Hierarchy count with Spatial Index</p>
                                 </td>
                                 <td align="left" valign="top" width="55%" headers="d8066e9809 d8066e9783 ">
                                    <p>5 minutes</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="45%" id="d8066e9816" headers="d8066e9780 ">
                                    <p>Hierarchy count without Spatial Index</p>
                                 </td>
                                 <td align="left" valign="top" width="55%" headers="d8066e9816 d8066e9783 ">
                                    <p>3 hours</p>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                     <p>The time taken for the jobs can be decreased by increasing the maximum split size using any of the following configuration parameters.</p><pre class="oac_no_warn" dir="ltr">mapred.max.split.size
mapreduce.input.fileinputformat.split.maxsize
</pre><p>This results in more splits are being processed by each single mapper and improves the execution time. This is done by using the <code class="codeph">SpatialFilterInputFormat</code> (spatial indexing) or <code class="codeph">FileSplitInputFormat</code> (spatial hierarchical join, buffer). Also, the same results can be achieved by using the implementation of <code class="codeph">CombineFileInputFormat</code> as internal <code class="codeph">InputFormat</code>.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1BF96303-0D19-4B3B-A491-B2D642360EF3" title="Oracle Big Data Spatial Vector Analysis is a Spatial Vector Analysis API, which runs as a Hadoop job and provides MapReduce components for spatial processing of data stored in HDFS.">Oracle Big Data Spatial Vector Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div>
            <div class="props_rev_3"><a id="GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" name="GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00"></a><h3 id="BDSPA-GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" class="sect3"><span class="enumeration_section">2.10 </span>Oracle Big Data Spatial Vector Analysis for Spark
               </h3>
               <div>
                  <p>Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.</p>
                  <p>These components make use of the Spatial Java API to perform spatial analysis tasks. The supported features include the following.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE">Spatial RDD (Resilient Distributed Dataset)</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-D41E4954-426E-4AFE-AD85-34F3DC2485D0">Spatial Actions (MBR and NearestNeighbors)</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5">Spatially Indexing a Spatial RDD</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-476255B2-E738-4159-9409-183196645E89">Support for Common Spatial Formats</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8D826B09-410D-4C12-A51A-3225D2A4439F">Spatial Spark SQL API</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-839E48A5-3E1A-4A1A-A204-F938AFFCD339">JDBC Data Sources for Spatial RDDs</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="props_rev_3"><a id="GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE" name="GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE"></a><h4 id="BDSPA-GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE" class="sect4"><span class="enumeration_section">2.10.1 </span>Spatial RDD (Resilient Distributed Dataset)
                  </h4>
                  <div>
                     <p>A spatial RDD (Resilient Distributed Dataset) is a Spark RDD that allows you to perform spatial transformations and actions.</p>
                     <p>The current spatial RDD implementation is the class <code class="codeph">oracle.spatial.spark.vector.rdd.SpatialJavaRDD</code> for Java and <code class="codeph">oracle.spatial.spark.vector.scala.rdd.SpatialRDD</code> for Scala. A spatial RDD implementation can be created from an existing instance of RDD or JavaRDD, as shown in the following examples:
                     </p>
                     <p>Java:</p><pre class="pre codeblock"><code>//create a regular RDD
JavaRDD&lt;String&gt; rdd = sc.textFile("someFile.txt");
//create a SparkRecordInfoProvider to extract spatial information from the source RDD’s records
SparkRecordInfoProvider&lt;String&gt; recordInfoProvider = new MySparkRecordInfoProvider();
//create a spatial RDD
SpatialJavaRDD&lt;String&gt; spatialRDD = SpatialJavaRDD.fromJavaRDD(rdd, recordInfoProvider, String.class));
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>//create a regular RDD
val rdd: RDD[String] = sc.textFile("someFile.txt")
//create a SparkRecordInfoProvider to extract spatial information from the source RDD’s records
val recordInfoProvider: SparkRecordInfoProvider[String] = new MySparkRecordInfoProvider()
//create a spatial RDD
val spatialRDD: SpatialRDD[String] = SpatialRDD(rdd, recordInfoProvider)
</code></pre><p>A spatial RDD takes an implementation of the interface <code class="codeph">oracle.spatial.spark.vector.SparkRecordInfoProvider</code>, which is used for extracting spatial information from each RDD element.
                     </p>
                     <p>A regular RDD can be transformed into a spatial RDD of the same generic type, that is, if the source RDD contains records of type String. The spatial RDD will also contain String records.</p>
                     <p>You can also create a Spatial RDD with records of type <code class="codeph">oracle.spatial.spark.vector.SparkRecordInfo</code>. A <code class="codeph">SparkRecordInfo</code> is an abstraction of a record from the source RDD; it holds the source record’s spatial information and may contain a subset of the source record’s data.
                     </p>
                     <p>The following examples show how to create an RDD of <code class="codeph">SparkRecordInfo</code> records.
                     </p>
                     <p>Java:</p><pre class="pre codeblock"><code>//create a regular RDD
JavaRDD&lt;String&gt; rdd = sc.textFile("someFile.txt");
//create a SparkRecordInfoProvider to extract spatial information from the source RDD’s records
SparkRecordInfoProvider&lt;String&gt; recordInfoProvider = new MySparkRecordInfoProvider();
//create a spatial RDD
SpatialJavaRDD&lt;SparkRecordInfo&gt; spatialRDD = SpatialJavaRDD.fromJavaRDD(rdd, recordInfoProvider));
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>//create a regular RDD
val rdd: RDD[String] = sc.textFile("someFile.txt")
//create a SparkRecordInfoProvider to extract spatial information from the source RDD’s records
val recordInfoProvider: SparkRecordInfoProvider[String] = new MySparkRecordInfoProvider()
//create a spatial RDD
val spatialRDD: SpatialRDD[SparkRecordInfo] = SpatialRDD.fromRDD(rdd, recordInfoProvider))
</code></pre><p>A spatial RDD of <code class="codeph">SparkRecordInfo</code> records has the advantage that spatial information does not need to be extracted from each record every time it is needed for a spatial operation.
                     </p>
                     <p>You can accelerate spatial searches by spatially indexing a spatial RDD. Spatial indexing is described in section <a href="using-big-data-spatial-graph-spatial-data.html#GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE___REF465070188">1.4 Spatial Indexing</a>.
                     </p>
                     <p>The spatial RDD provides the following spatial transformations and actions, which are described in the sections <a href="using-big-data-spatial-graph-spatial-data.html#GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE___REF465070213">1.2 Spatial Transformations</a> and <a href="using-big-data-spatial-graph-spatial-data.html#GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE___REF465070226">1.3 Spatial Actions</a>.
                     </p>
                     <p>Spatial transformations:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>filter</p>
                        </li>
                        <li>
                           <p>flatMap</p>
                        </li>
                        <li>
                           <p>join (available when creating a spatial index)</p>
                        </li>
                     </ul>
                     <p>Spatial Actions:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>MBR</p>
                        </li>
                        <li>
                           <p>nearestNeighbors</p>
                        </li>
                     </ul>
                     <div class="section">
                        <p class="subhead3">Spatial Pair RDD</p>
                        <p>A pair version of the Java class<code class="codeph">SpatialJavaRDD</code> is provided and is implemented as the class <code class="codeph">oracle.spatial.spark.vector.rdd.SpatialJavaPairRDD</code>. A spatial pair RDD is created from an existing pair RDD and contains the same spatial transformations and actions as the single spatial RDD. A <code class="codeph">SparkRecordInfoProvider</code> used for a spatial pair RDD should receive records of type <code class="codeph">scala.Tuple2&lt;K,V&gt;</code>, where <code class="codeph">K</code> and <code class="codeph">V</code> correspond to the pair RDD key and value types, respectively.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <div class="example" id="GUID-EE6B5A28-70EC-42F6-B151-7C0245148DDE__GUID-D97E9C2D-FD36-419F-B6DB-FA25F3C878A2">
                        <p class="titleinexample">Example 2-1 SparkRecordInfoProvider to Read Information from a CSV File</p>
                        <p>The following example shows how to implement a simple <code class="codeph">SparkRecordInfoProvider</code> to read information from a CSV file.
                        </p><pre class="pre codeblock"><code>public class CSVRecordInfoProvider implements SparkRecordInfoProvider&lt;String&gt;{
    private int srid = 8307;

    //receives an RDD record and fills the given recordInfo
    public boolean getRecordInfo(String record, SparkRecordInfo recordInfo) {
        try {
            String[] tokens = record.split(",");
            //expected records have the format: id,name,last_name,x,y where x and y are optional 
            //output recordInfo will contain the fields id, last name and geometry
            recordInfo.addField("id", tokens[0]);
            recordInfo.addField("last_name", tokens[2]);
            if (tokens.length == 5) {
                recordInfo.setGeometry(JGeometry.createPoint(tokens[3], tokens[4], 2, srid));
            }
        } catch (Exception ex) {
            //return false when there is an error extracting data from the input value
            return false;
        }
        return true;
    }

    public void setSrid(int srid) {this.srid = srid;}	
    public int getSrid() {return srid;}
}
</code></pre><p>In this example, the record’s ID and last-name fields are extracted along with the spatial information to be set to the <code class="codeph">SparkRecordInfo</code> instance used as an out parameter. Extracting additional information is only needed when the goal is to create a spatial RDD containing <code class="codeph">SparkRecordInfo</code> elements and is necessary to preserve a subset of the original records information. Otherwise, it is only necessary to extract the spatial information.
                        </p>
                        <p>The call to <code class="codeph">SparkRecordInfoProvider.getRecordInfo()</code> should return <code class="codeph">true</code> whenever the record should be included in a transformation or considered in a search. If <code class="codeph">SparkRecordInfoProvider.getRecordInfo()</code> returns <code class="codeph">false</code>, the record is ignored.
                        </p>
                     </div>
                     <!-- class="example" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C" name="GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C"></a><h4 id="BDSPA-GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C" class="sect4"><span class="enumeration_section">2.10.2 </span>Spatial Transformations
                  </h4>
                  <div>
                     <p>The transformations described in the following subtopics are available for spatial RDD, spatial pair RDD, and the distributed spatial index unless stated otherwise (for example, a join transformation is only available for a distributed spatial index).</p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-DAF43B68-183E-4172-A79A-638E751AC711">Filter Transformation</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-EE14E3B7-866F-4BCE-B1B6-2676FE4100C2">FlatMap Transformation</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-E180C050-908B-45E1-87BA-3531F3F760D7">Join Transformation</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C2B4FBD2-BC8C-48AE-BCDE-EDE527F5B9D8">Controlling Spatial Evaluation</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-04246BC9-D736-4361-B1C8-CB5F52BBA05E">Spatially Enabled Transformations</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-DAF43B68-183E-4172-A79A-638E751AC711" name="GUID-DAF43B68-183E-4172-A79A-638E751AC711"></a><h5 id="BDSPA-GUID-DAF43B68-183E-4172-A79A-638E751AC711" class="sect5"><span class="enumeration_section">2.10.2.1 </span>Filter Transformation
                     </h5>
                     <div>
                        <p>A filter transformation is a spatial version of the regular RDD’s filter() transformation. In addition to a user-provided filtering function, it takes an instance of <code class="codeph">oracle.spatial.hadoop.vector.util.SpatialOperationConfig</code>, which is used to describe the spatial operation used to filter spatial records. A <code class="codeph">SpatialOperationConfig</code> contains a query window which is the geometry used as reference and a spatial operation. The spatial operation is executed in the form: <code class="codeph">(RDD record’s geometry) (spatial operation) (query window)</code>. For example: <code class="codeph">(RDD record) IsInside (queryWindow)</code></p>
                        <p> Spatial operations available are <code class="codeph">AnyInteract</code>, <code class="codeph">IsInside</code>, <code class="codeph">Contains</code>, and <code class="codeph">WithinDistance</code>.
                        </p>
                        <p>The following examples return an RDD containing only records that are inside the given query window and with not null ID.</p>
                        <p>Java:</p><pre class="pre codeblock"><code>SpatialOperationConfig soc = new SpatialOperationConfig();
soc.setOperation(SpatialOperation.IsInside);
soc.setQueryWindow(JGeometry.createLinearPolygon(new double[] { 2.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 1.0, 2.0, 1.0 }, 2, srid));
SpatialJavaRDD&lt;SparkRecordInfo&gt; filteredSpatialRDD = spatialRDD.filter(
(record) -&gt; {
return record.getField(“id”) != null;
}, soc);
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val soc = new SpatialOperationConfig()
soc.setOperation(SpatialOperation.IsInside)
soc.setQueryWindow(JGeometry.createLinearPolygon(Array(2.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 1.0, 2.0, 1.0 ), 2, srid))
val filteredSpatialRDD: SpatialRDD[SparkRecordInfo] = spatialRDD.filter(
record =&gt; { record.getField(“id”) != null }, soc)
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-EE14E3B7-866F-4BCE-B1B6-2676FE4100C2" name="GUID-EE14E3B7-866F-4BCE-B1B6-2676FE4100C2"></a><h5 id="BDSPA-GUID-EE14E3B7-866F-4BCE-B1B6-2676FE4100C2" class="sect5"><span class="enumeration_section">2.10.2.2 </span>FlatMap Transformation
                     </h5>
                     <div>
                        <p>A FlatMap transformation is a spatial version of the regular RDD’s <code class="codeph">flatMap()</code> transformation. In addition to the user-provided function, it takes a SpatialOperationConfig to perform a spatial filtering. It works like the <a href="using-big-data-spatial-graph-spatial-data.html#GUID-DAF43B68-183E-4172-A79A-638E751AC711">Filter Transformation</a>, except that spatially filtered results are passed to the map function and flattened.
                        </p>
                        <p>The following examples create an RDD that contains only elements that interact with the given query window and geometries that have been buffered.</p>
                        <p>Java:</p><pre class="pre codeblock"><code>SpatialOperationConfig soc = new SpatialOperationConfig();
soc.setOperation(SpatialOperation.AnyInteract);
soc.setQueryWindow(JGeometry.createLinearPolygon(new double[] { 2.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 1.0, 2.0, 1.0 }, 2, srid));
JavaRDD&lt;SparkRecordInfo&gt; mappedRDD = spatialRDD.flatMap(
(record) -&gt; {
	JGeometry buffer = record.getGeometry().buffer(2.5);
	record.setGeometry(buffer);
return Collections.singletonList(record);
}, soc);
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val soc = new SpatialOperationConfig()
soc.setOperation(SpatialOperation.AnyInteract)
soc.setQueryWindow(JGeometry.createLinearPolygon(Array( 2.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 1.0, 2.0, 1.0 ), 2, srid))
val mappedRDD: RDD[SparkRecordInfo] = spatialRDD.flatMap(
record =&gt; {
	val buffer: JGeometry = record.getGeometry().buffer(2.5)
	record.setGeometry(buffer)
record
}, soc)
</code></pre><div class="infoboxnote" id="GUID-EE14E3B7-866F-4BCE-B1B6-2676FE4100C2__GUID-4A976B03-F697-4D99-8CAE-9F8757404E11">
                           <p class="notep1">Note:</p>
                           <p>As of Spark 2, the Java class <code class="codeph">org.apache.spark.api.java.function.FlatMapFunction</code> received by the <code class="codeph">flatMap</code> transformation returns an instance of <code class="codeph">java.util.Iterator</code> instead of <code class="codeph">Iterable</code>, so the return line of the preceding <code class="codeph">flatMap</code> transformation Java example changes for Spark 2 to: <code class="codeph">return Collections.singletonList(record).iterator();</code><span class="bold"><span class="italic">  </span></span></p>
                        </div>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-E180C050-908B-45E1-87BA-3531F3F760D7" name="GUID-E180C050-908B-45E1-87BA-3531F3F760D7"></a><h5 id="BDSPA-GUID-E180C050-908B-45E1-87BA-3531F3F760D7" class="sect5"><span class="enumeration_section">2.10.2.3 </span>Join Transformation
                     </h5>
                     <div>
                        <p>A join transformation joins two spatial RDDs based on a spatial relationship between their records. In order to perform this transformation, one of the two RDDs must be spatially indexed. (See <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a> for more information about indexing a spatial RDD.)
                        </p>
                        <p>The result type of a spatial join transformation is defined by a user-provided lambda function that is called for each pair of joined records.</p>
                        <p>The following examples join all the records from both data sets that interact in any way.</p>
                        <p>Java:</p><pre class="pre codeblock"><code>DistributedSpatialIndex index = DistributedSpatialIndex.createIndex(sparkContext, spatialRDD1, new QuadTreeConfiguration());
SpatialJavaRDD&lt;SparkRecordInfo&gt; spatialRDD2 = SpatialJavaRDD.fromJavaRDD(rdd2, new RegionsRecordInfoProvider(srid));
SatialOperationConfig soc = new SpatialOperationConfig();
soc.setOperation(SpatialOperation.AnyInteract);
JavaRDD&lt;Tuple2&lt;SparkRecordInfo, SparkRecordInfo&gt; joinedRDD = index.spatialJoin( spatialRDD2,
(recordRDD1, recordRDD2) -&gt; {
return Collections.singletonList( new Tuple2&lt;&gt;(recordRDD1, recordRDD2)).iterator());
}, soc);
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val index: DistributedSpatialIndex[SparkRecordInfo] = DistributedSpatialIndex.createIndex(spatialRDD1, new QuadTreeConfiguration())
val spatialRDD2: SpatialRDD[SparkRecordInfo] = SpatialRDD.fromRDD(rdd2, new RegionsRecordInfoProvider(srid))
val soc = new SpatialOperationConfig()
soc.setOperation(SpatialOperation.AnyInteract)
val joinedRDD: RDD[(SparkRecordInfo, SparkRecordInfo)] = index.join( spatialRDD2,
(recordRDD1, recordRDD2) =&gt; {Seq((recordRDD1, recordRDD2))}, soc)
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-C2B4FBD2-BC8C-48AE-BCDE-EDE527F5B9D8" name="GUID-C2B4FBD2-BC8C-48AE-BCDE-EDE527F5B9D8"></a><h5 id="BDSPA-GUID-C2B4FBD2-BC8C-48AE-BCDE-EDE527F5B9D8" class="sect5"><span class="enumeration_section">2.10.2.4 </span>Controlling Spatial Evaluation
                     </h5>
                     <div>
                        <p>When executing a filtering transformation or nearest neighbors action, by default the spatial operation is executed before calling the user-defined filtering function; however, you can change this behavior. Executing a user-defined filtering function before the spatial operation can improve performance in scenarios where the spatial operation is costly in comparison to the user-defined filtering function.</p>
                        <p>To set the user-defined function to be executed <span class="italic">before</span> the spatial operation, set the following parameter to the <code class="codeph">SpatialOperationConfig</code> passed to either a filter transformation or nearest neighbors action.
                        </p><pre class="pre codeblock"><code>SpatialOperationConfig spatialOpConf = new SpatialOperationConfig(SpatialOperation.AnyInteract, qryWindow, 0.05);
//set the spatial operation to be executed after the user-defined filtering function
spatialOpConf.addParam(SpatialOperationConfig.PARAM_SPATIAL_EVAL_STAGE, SpatialOperationConfig.VAL_SPATIAL_EVAL_STAGE_POST);
spatialRDD.filter((r)-&gt;{ return r.getFollowersCount()&gt;1000;}, spatialOpConf);
</code></pre><p>The preceding example applies to both spatial RDDs and a distributed spatial index.</p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-04246BC9-D736-4361-B1C8-CB5F52BBA05E" name="GUID-04246BC9-D736-4361-B1C8-CB5F52BBA05E"></a><h5 id="BDSPA-GUID-04246BC9-D736-4361-B1C8-CB5F52BBA05E" class="sect5"><span class="enumeration_section">2.10.2.5 </span>Spatially Enabled Transformations
                     </h5>
                     <div>
                        <p>Spatial operations can be performed in regular transformations by creating a <code class="codeph">SpatialTransformationContext</code> before executing any transformation.
                        </p>
                        <p>After the <code class="codeph">SpatialTransformationContext</code> instance is in the transformation function, that instance can be used to get the record’s geometry and apply spatial operations, as shown in the following example, which transforms an RDD of String records into a pair RDD where the key and value corresponds to the source record ID and a buffered geometry.
                        </p>
                        <p>Java:</p><pre class="pre codeblock"><code>SpatialJavaRDD&lt;String&gt; spatialRDD = SpatialJavaRDD.fromJavaRDD(rdd, new CSVRecordInfoProvider(srid), String.class);
SpatialTransformationContext stCtx = spatialRDD.createSpatialTransformationContext();
JavaPairRDD&lt;String, JGeometry&gt; bufferedRDD = spatialRDD.mapToPair(
(record) -&gt; {
	SparkRecordInfo recordInfo = stCtx.getRecordInfo(record);
	String id = (String) recordInfo.getField(“id”)
	JGeometry geom. = recordInfo.getGeometry(record);
	JGeometry buffer = geom.buffer(0.5);
return new Tuple2(id, buffer);
});
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val spatialRDD: SpatialRDD[String]= SpatialRDD.fromRDD(rdd, new CSVRecordInfoProvider(srid))
val stCtx: SpatialTransformationContext[String] = spatialRDD.createSpatialTransformationContext()
val bufferedRDD: RDD[(String, JGeometry)] = spatialRDD.map(
record =&gt; {
	val recordInfo: SparkRecordInfo = stCtx.getRecordInfo(record)
	val id: String = recordInfo.getField(“id”).asInstanceOf[String]
	val geom: JGeometry = recordInfo.getGeometry(record)
	val buffer: JGeometry = geom.buffer(0.5)
(id, buffer)
})
</code></pre><p>When working on a per-partition basis, you should use a stateful version of <code class="codeph">SpatialTransformationContext</code>, which avoids creating multiple instances of <code class="codeph">SparkRecordInfo</code>.  The following pattern can be followed when working on a per-partition basis:
                        </p><pre class="pre codeblock"><code>val stCtx: SpatialTransformationContext[String] = spatialRDD.createSpatialTransformationContext()
val bufferedRDD: RDD[(String, JGeometry)] = spatialRDD.mapPartitions(
(records) =&gt; {
	val sSTCtx = new StatefulSpatialTransformationContext(stCtx)
	records.map(record=&gt;{
	    val recordInfo: SparkRecordInfo = sSTCtx.getRecordInfo(record)
	    val id: String = recordInfo.getField(“id”).asInstanceOf[String]
	    val geom: JGeometry = recordInfo.getGeometry(record)
	    val buffer: JGeometry = geom.buffer(0.5)
             (id, buffer)
	})
}, true)
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-D41E4954-426E-4AFE-AD85-34F3DC2485D0" name="GUID-D41E4954-426E-4AFE-AD85-34F3DC2485D0"></a><h4 id="BDSPA-GUID-D41E4954-426E-4AFE-AD85-34F3DC2485D0" class="sect4"><span class="enumeration_section">2.10.3 </span>Spatial Actions (MBR and NearestNeighbors)
                  </h4>
                  <div>
                     <p>Spatial RDDs,spatial pair RDDs, and the distributed spatial index provide the following spatial actions.</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><span class="bold">MBR</span>: Calculates the RDD’s minimum bounding rectangle (MBR). The MBR is only calculated once and cached so the second time it is called, it will not be recalculated. The following examples show how to get the MBR from a spatial RDD. (This transformation is not available for <code class="codeph">DistributedSpatialIndex</code>.)
                           </p>
                           <p>Java:</p><pre class="pre codeblock"><code>doubl[] mbr = spatialRDD.getMBR();</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val mbr: Array[Double] = spatialRDD.getMBR()</code></pre></li>
                        <li>
                           <p><span class="bold">NearestNeighbors</span>: Returns a list containing the K nearest elements from an RDD or distributed spatial index to a given geometry. Additionally, a user-defined filter lambda function can be passed, so that only the records that pass the filter will be candidates to be part of the K nearest neighbors list. The following examples show how to get the 5 records closest to the given point.
                           </p>
                           <p>Java:</p><pre class="pre codeblock"><code>JGeometry qryWindow = JGeometry.createPoint(new double[] { 2.0, 1.0 }, 2, srid));
SpatialOperationConfig soc = new SpatialOperationConfig(SpatialOperation.None, qryWindow, 0.05);
List&lt;SparkRecordInfo&gt; nearestNeighbors = spatialRDD.nearestNeighbors(
(record)-&gt;{
	return ((Integer)record.getField(“followers_count”))&gt;1000;
}, 5, soc);
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val qryWindow: JGeometry = JGeometry.createPoint(Array(2.0, 1.0 ), 2, srid))
val soc: SpatialOperationConfig = new SpatialOperationConfig(SpatialOperation.None, qryWindow, 0.05)
val nearestNeighbors: Seq[SparkRecordInfo] = spatialRDD.nearestNeighbors(
record=&gt;{ record.getField(“followers_count”).asInstanceOf[Int]&gt;1000 }, 5, soc);
</code></pre></li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5" name="GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5"></a><h4 id="BDSPA-GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5" class="sect4"><span class="enumeration_section">2.10.4 </span>Spatially Indexing a Spatial RDD
                  </h4>
                  <div>
                     <p>A spatial RDD can be spatially indexed to speed up spatial searches when performing spatial transformations.</p>
                     <p>A spatial index repartitions the spatial RDD so that each partition only contains records on some specific area. This allows partitions that do not contain results in a spatial search to be quickly discarded, making the search faster.</p>
                     <p>A spatial index is created through the Java abstract class <code class="codeph">oracle.spatial.spark.vector.index.DistributedSpatialIndex</code> or its Scala equivalent <code class="codeph">oracle.spatial.spark.vector.scala.index.DistributedSpatialIndex</code>, both of which use a specific implementation to create the actual spatial index. The following examples show how to create a spatial index using a QuadTree-based spatial index implementation.
                     </p>
                     <p>Java:</p><pre class="pre codeblock"><code>DistributedSpatialIndex&lt;String&gt; index = DistributedSpatialIndex.createIndex(sparkContext, spatialRDD1, new QuadTreeConfiguration());</code></pre><p>Scala:</p><pre class="pre codeblock"><code>val index: DistributedSpatialIndex[String] = DistributedSpatialIndex.createIndex(spatialRDD1, new QuadTreeConfiguration())(sparkContext)</code></pre><p>The type of spatial index implementation is determined by the last parameter, which is a subtype of <code class="codeph">oracle.spatial.spark.vector.index.SpatialPartitioningConfiguration</code>. Depending on the index implementation, the configuration parameter may accept different settings for performing partitioning and indexing. Currently, the only implementation of a spatial index is the class <code class="codeph">oracle.spatial.spark.vector.index.quadtree.QuadTreeDistIndex</code>, and it receives a configuration of type <code class="codeph">oracle.spatial.spark.vector.index.quadtree.QuadTreeConfiguration</code>.
                     </p>
                     <p>The <code class="codeph">DistributedSpatialIndex</code> class currently supports the filter, flatMap, join, and nearestNeighbors transformations, which are described in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-E8AE5009-CE5E-46F5-A930-EF77B2043D0C">Spatial Transformations</a>.
                     </p>
                     <p>A spatial index can be persisted using the method <code class="codeph">DistributedSpatialIndex.save()</code>, which takes an existing <code class="codeph">SparkContext</code> and a path where the index will be stored. The path may be in a local or a distributed (HDFS) file system. Similarly, a persisted spatial index can be loaded by calling the method <code class="codeph">DistributedSpatialIndex.load()</code>, which also takes an existing <code class="codeph">SparkContext</code> and the path where the index is stored.
                     </p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-9F15A684-2542-46AE-93C2-39279DA2E71F">Spatial Partitioning of a Spatial RDD</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-174F0B77-BB3D-4394-BCC2-67809171A2AA">Local Spatial Indexing of a Spatial RDD</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-9F15A684-2542-46AE-93C2-39279DA2E71F" name="GUID-9F15A684-2542-46AE-93C2-39279DA2E71F"></a><h5 id="BDSPA-GUID-9F15A684-2542-46AE-93C2-39279DA2E71F" class="sect5"><span class="enumeration_section">2.10.4.1 </span>Spatial Partitioning of a Spatial RDD
                     </h5>
                     <div>
                        <p>A spatial RDD can be partitioned through an implementation of the class <code class="codeph">oracle.spatial.spark.vector.index.SpatialPartitioning</code>. The <code class="codeph">SpatialPartitioning</code> class represents a spatial partitioning algorithm that transforms a spatial RDD into a spatially partitioned spatial pair RDD whose keys point to a spatial partition.
                        </p>
                        <p>A SpatialPartitioning algorithm is used internally by a spatial index, or it can be used directly by creating a concrete class. Currently, there is a QuadTree-based implementation called oracle.spatial.spark.vector.index.quadtree.QuadTreePartitioning. The following example shows how to spatially partition a spatial RDD.</p><pre class="pre codeblock"><code>QuadTreePartitioning&lt;T&gt; partitioning = new QuadTreePartitioning&lt;&gt;(sparkContext, spatialRDD, new QuadTreeConfiguration());
SpatialJavaPairRDD&lt;PartitionKey, T&gt; partRDD = partitioning.getPartitionedRDD();
</code></pre></div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5">Spatially Indexing a Spatial RDD</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-174F0B77-BB3D-4394-BCC2-67809171A2AA" name="GUID-174F0B77-BB3D-4394-BCC2-67809171A2AA"></a><h5 id="BDSPA-GUID-174F0B77-BB3D-4394-BCC2-67809171A2AA" class="sect5"><span class="enumeration_section">2.10.4.2 </span>Local Spatial Indexing of a Spatial RDD
                     </h5>
                     <div>
                        <p>A local spatial index can be created for each partition of a spatial RDD. Locally partitioning the content of each partition helps to improve spatial searches when working on a partition basis.</p>
                        <p>A local index can be created for each partition by setting the parameter <code class="codeph">useLocalIndex</code> to <code class="codeph">true</code> when creating a distributed spatial index. A spatially partitioned RDD can also be transformed so each partition is locally indexed by calling the utility method <code class="codeph">oracle.spatial.spark.vector.index.local.LocalIndex.createLocallyIndexedRDD(SpatialJavaPairRDD&lt;PartitionKey, T&gt; rdd)</code>. 
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5">Spatially Indexing a Spatial RDD</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-476255B2-E738-4159-9409-183196645E89" name="GUID-476255B2-E738-4159-9409-183196645E89"></a><h4 id="BDSPA-GUID-476255B2-E738-4159-9409-183196645E89" class="sect4"><span class="enumeration_section">2.10.5 </span>Support for Common Spatial Formats
                  </h4>
                  <div>
                     <p>The Spark Vector API provides utilities to easily read data from common spatial formats such as GeoJSON and ESRI ShapeFile.</p>
                     <p>The Java class <code class="codeph">oracle.spatial.spark.vector.io.SpatialSources</code> and the Scala class <code class="codeph">oracle.spatial.spark.vector.scala.io.SpatialSources</code> contain static methods to read data from GeoJSON and ShapeFile formats by specifying the data path, the data Spatial Reference System ID (SRID), and the list of non-spatial fields to be loaded.
                     </p>
                     <p>The following examples show how to load data from a GeoJSON file. The records are automatically transformed to instances of <code class="codeph">SparkRecordInfo</code>, which contain the spatial information plus the <code class="codeph">_id</code> and <code class="codeph">followers_count</code> fields. If all the fields need to be retrieved, null can be passed instead of the whole list of fields. Both GeoJSON and Shapefile read methods contain an overload that returns the original records as String and MapWritable representations, respectively.
                     </p>
                     <p>Java:</p><pre class="pre codeblock"><code>//list of GeoJSON field names to be loaded for each feature
List&lt;String&gt; fieldNames = new ArrayList&lt;String&gt;();
fieldNames.add("_id");
fieldNames.add("followers_count");

//create a spatial RDD from a GeoJSON file
SpatialJavaRDD&lt;SparkRecordInfo&gt; spatialRDD = SpatialSources.readGeoJSONRecordInfo(geoJSONInputPath, 8307, fieldNames, sparkContext);
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>//create a spatial RDD from a GeoJSON file
val spatialRDD = SpatialSources.readGeoJSONRecordInfo(geoJSONInputPath, 8307, Seq("_id","followers_count"))(sparkContext)
</code></pre><p>Or, using implicit classes:</p><pre class="pre codeblock"><code>//create a spatial RDD from a GeoJSON file
import oracle.spatial.spark.vector.scala.io.SpatialSources.ImplicitSpatialSources
val spatialRDD = sparkContext.readGeoJSONRecordInfo(geoJSONInputPath, 8307, Seq("_id","followers_count"))
</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-8D826B09-410D-4C12-A51A-3225D2A4439F" name="GUID-8D826B09-410D-4C12-A51A-3225D2A4439F"></a><h4 id="BDSPA-GUID-8D826B09-410D-4C12-A51A-3225D2A4439F" class="sect4"><span class="enumeration_section">2.10.6 </span>Spatial Spark SQL API
                  </h4>
                  <div>
                     <p>The Spatial Spark SQL API supports Spark SQL DataFrame objects containing spatial information in any format. </p>
                     <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2" title="Oracle Big Data Spatial Vector Hive Analysis provides spatial functions to analyze the data using Hive.">Oracle Big Data Spatial Vector Hive Analysis</a> can be used with Spark SQL.
                     </p>
                     <div class="example" id="GUID-8D826B09-410D-4C12-A51A-3225D2A4439F__GUID-9EAE757B-E860-450B-A3D7-466CABC4B7F1">
                        <p class="titleinexample">Example 2-2 Creating a Spatial DataFrame for Querying Tweets</p>
                        <p>The following example uses the Spark 1.x API to create a spatial DataFrame for querying tweets. Ithe data is loaded using a spatial RDD, then a DataFrame can be created using the function <code class="codeph">SpatialJavaRDD.createSpatialDataFrame</code>.
                        </p><pre class="pre codeblock"><code>//create HiveContext
HiveContext sqlContext = new HiveContext(sparkContext.sc());
//get the spatial DataFrame from the SpatialRDD
//the geometries are in GeoJSON format
DataFrame spatialDataFrame = <span class="bold">spatialRDD.createSpatialDataFrame(sqlContext, properties)</span>;
// Register the DataFrame as a table.
spatialDataFrame.registerTempTable("tweets");
//register UDFs
sqlContext.sql("create temporary function ST_Polygon as 'oracle.spatial.hadoop.vector.hive.ST_Polygon'");
sqlContext.sql("create temporary function ST_Point as 'oracle.spatial.hadoop.vector.hive.ST_Point'");
sqlContext.sql("create temporary function ST_Contains as 'oracle.spatial.hadoop.vector.hive.function.ST_Contains'");
// SQL can be run over RDDs that have been registered as tables.
StringBuffer query = new StringBuffer();
query.append("SELECT geometry, friends_count, location, followers_count FROM tweets ");
query.append("WHERE ST_Contains( ");
query.append("	ST_Polygon('{\"type\": \"Polygon\",\"coordinates\": [[[-106, 25], [-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}', 8307) ");
query.append("	, ST_Point(geometry, 8307) ");
query.append("	, 0.05)");
query.append("	and followers_count &gt; 50");
DataFrame results = sqlContext.sql(query.toString());		
//Filter the tweets in a query window (somewhere in the north of Mexico) 
//and with more than 50 followers.
//Note that since the geometries are in GeoJSON format it is possible to create the ST_Point like
//ST_Point(geometry, 8307)
//instead of
//ST_Point(geometry, 'oracle.spatial.hadoop.vector.hive.json.GeoJsonHiveRecordInfoProvider')
List&lt;String&gt; filteredTweets = results.javaRDD().map(new Function&lt;Row, String&gt;() {
  public String call(Row row) {
	  StringBuffer sb = new StringBuffer();
	  sb.append("Geometry: ");
	  sb.append(row.getString(0));
	  
	  sb.append("\nFriends count: ");
	  sb.append(row.getString(1));
	  sb.append("\nLocation: ");
	  sb.append(row.getString(2));
	  sb.append("\nFollowers count: ");
	  sb.append(row.getString(3));
	  return sb.toString();
  }
}).collect();
//print the filtered tweets
filteredTweets.forEach(tweet -&gt; System.out.println("Tweet: "+tweet)); 
</code></pre></div>
                     <!-- class="example" -->
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4">Spark 2 API Enhancements</a><br></li>
                        <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588">Spatial Analysis Spark SQL UDFs</a><br></li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
                  <div class="props_rev_3"><a id="GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4" name="GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4"></a><h5 id="BDSPA-GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4" class="sect5"><span class="enumeration_section">2.10.6.1 </span>Spark 2 API Enhancements
                     </h5>
                     <div>
                        <p>New Spark SQL capabilities have been added to the Spark 2 Vector API.</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__SPATIALDATASETDATAFRAME-750E30E6">Spatial DataSet/DataFrame</a></p>
                           </li>
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__SPATIALUDFS-750E33B1">Spatial UDFs</a></p>
                           </li>
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__SPATIALINDEX-750E3662">Spatial Index</a></p>
                           </li>
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__PERFORMANCECONSIDERATIONSWITHASPATI-750E38D7">Performance Considerations with a Spatial Index Over Spark 2 SQL</a></p>
                           </li>
                        </ul>
                        <div class="section" id="GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__SPATIALDATASETDATAFRAME-750E30E6">
                           <p class="subhead3">Spatial DataSet/DataFrame</p>
                           <p>Spatial RDDs can be transformed to DataSets/DataFrames using the functions provided by the class <code class="codeph">oracle.spatial.spark.vector.sql.SpatialJavaRDDConversions</code> (Java) and <code class="codeph">oracle.spatial.spark.vector.scala.sql. SpatialRDDConversions</code> (Scala). The latter provides an implicit class in order to make it possible to call the transformation from the Spatial RDD instance. The following examples show how to transform a Spatial RDD to a DataFrame.
                           </p>
                           <p>Java:</p><pre class="pre codeblock"><code>List&lt;String&gt; fields = Arrays.asList(new String[]{("friends_count","location", "followers_count"});
DataSet&lt;Row&gt; spatialDataFrame = SpatialJavaRDDConversions.toDataFrame(spatialRDD, fields, sparkSession);
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>//using implicit classes
import oracle.spatial.spark.vector.scala.sql.SpatialRDDConversions.ImplicitSpatialRDDConversions
val spatialDataFrame = spatialRDD.toDataFrame(Seq("friends_count","location", "followers_count"))(sparkSession)
</code></pre></div>
                        <!-- class="section" -->
                        <div class="section" id="GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__SPATIALUDFS-750E33B1">
                           <p class="subhead3">Spatial UDFs</p>
                           <p>The same set of Hive UDFs is available as Spark UDFs for the Spark 2 Vector API. For details, see <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588">Spatial Analysis Spark SQL UDFs</a>.
                           </p><pre class="pre codeblock"><code>SpatialEnvironment.setup(sparkSession)</code></pre></div>
                        <!-- class="section" -->
                        <div class="section" id="GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__SPATIALINDEX-750E3662">
                           <p class="subhead3">Spatial Index</p>
                           <p>An existing Spark Vector API’s spatial index can be used from Spark 2 SQL to perform faster spatial queries. </p>
                           <p>The following examples show how to transform an instance of a spatial index to a DataFrame:</p>
                           <p>Java:</p><pre class="pre codeblock"><code>// Create a spatial RDD from a GeoJSON file
List&lt;String&gt; fieldNames = Arrays.asList(new String[] {"id", "followers_count"});
SpatialJavaRDD&lt;SparkRecordInfo&gt; spatialRDD =  SpatialSources.readGeoJSONRecordInfo(path, srid, fieldNames, sparkContext);

//Create a spatial index
DistributedSpatialIndex&lt;SparkRecordInfo&gt; index = DistributedSpatialIndex.createIndex(sparkContext, spatialRDD, new QuadTreeConfiguration());

//Specify the columns as StructFields. The geometry column is always included by default
StructField[] fields = SchemaUtils.toStringStructFields(fieldNames);

//options can be null if there are no options to be passed
Map&lt;String, Object&gt; options = new HashMap&lt;&gt;();
//include the CRS to all the geometries to avoid using SDO_&lt;TYPE&gt; wrappers in spatial UDF's
options.put(QuadTreeIndexRelation.OptIncludeCRS(), true); 

//transform the existing spatial index to DataFrame and register as a temporal table
<span class="bold">QuadTreeIndexRelation.toDataFrame(index, SparkRecordInfo.class, fields, options, sparkSession).createOrReplaceTempView("tweets_index");</span>
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>import oracle.spatial.spark.vector.scala.io.SpatialSources.ImplicitSpatialSources
import oracle.spatial.spark.vector.scala.sql.index.quadtree.QuadTreeIndexRelation._
import oracle.spatial.spark.vector.scala.sql.SpatialRDDConversions.ImplicitSpatialRDDConversions

//List of field names to be loaded from the GeoJSON file
val fieldNames = Seq("id", "followers_count")

//create a spatial RDD
val spatialRDD = sparkContext.readGeoJSON(path, srid, fieldNames)

//spatially index the spatial RDD
val index = DistributedSpatialIndex.createIndex(spatialRDD, new QuadTreeConfiguration())(implicitly, sparkContext)

//transform the existing spatial index to DataFrame and register as a temporal table
//fieldNames are automatically transformed to an array of string StructFields thanks to the //import of QuadTreeIndexRelation._
//toDataFrame can be called from the index thanks to the import of //ImplicitSpatialRDDConversions
<span class="bold">index.toDataFrame(fieldNames, Map(QuadTreeIndexRelation.OptIncludeCRS-&gt;true))(sparkSession).createOrReplaceTempView("tweets_index")</span>
</code></pre><p>It is also possible to load directly a persisted spatial index into a DataFrame, as the following examples show.</p>
                           <p>Java:</p><pre class="pre codeblock"><code>// list of GeoJSON field names to be loaded for each feature
List&lt;String&gt; fieldNames = Arrays.asList(new String[] { "id", "followers_count"});

// Create the required schema for the index. In this case, the schema
// contains only fields of type StringType. A schema with other data
// types can be passed if needed.
StructType schema = SchemaUtils.createStringFieldsSchema(fieldNames);

// read an existing spatial index and register it as table
sparkSession.read().format(QuadTreeIndexRelation.Format()).schema(schema).load(indexPath).createOrReplaceTempView("tweets_index");
</code></pre><p>Scala:</p><pre class="pre codeblock"><code>//List of field names from the spatial index to be included as columns.
val fieldNames = Seq("id", "followers_count")

//Create the required schema for the index. 
//In this case, the schema contains only fields of type StringType. 
//A schema with other data types can be passed if needed.  
val schema = SchemaUtils.createStringFieldsSchema(fieldNames)

//read an existing spatial index and register it as a table
sparkSession.read.format(QuadTreeIndexRelation.Format).schema(schema).load(indexPath).createOrReplaceTempView("tweets_index")
</code></pre><p>After a spatial index is transformed to a DataFrame, it can be used as any other spatial DataFrame.</p>
                        </div>
                        <!-- class="section" -->
                        <div class="section" id="GUID-5176C3D8-8C9A-4CC4-8941-55D6A82893E4__PERFORMANCECONSIDERATIONSWITHASPATI-750E38D7">
                           <p class="subhead3">Performance Considerations with a Spatial Index Over Spark 2 SQL</p>
                           <p>A Spatial index performs faster when using only a spatial filter or a spatial filter and AND conditions in the WHERE clause. The following queries take full advantage of a spatial index as the spatial data is pre filtered before executing the SQL query:</p><pre class="pre codeblock"><code>SELECT * FROM tweets_index WHERE ST_ANYINTERACT( ST_POLYGON('$polygonJSON',8307), ST_POINT(geometry,8307), 0.05 )

SELECT * FROM tweets_index WHERE ST_CONTAINS( ST_POLYGON('$polygonJSON',8307), ST_POINT(geometry,8307), 0.05 ) AND followers_count &gt; 50

SELECT * FROM tweets_index WHERE ST_INSIDE( ST_POINT(geometry,8307), ST_POLYGON('$polygonJSON',8307), 0.05 ) AND followers_count &gt; 50 AND id != null
</code></pre><p>Using OR conditions avoids the spatial data to be pre filtered, however, some spatial index optimizations are applied. The following query is an example of this case:</p><pre class="pre codeblock"><code>SELECT * FROM tweets_index WHERE ST_CONTAINS( ST_POLYGON('$polygonJSON',8307), ST_POINT(geometry,8307), 0.05 ) OR followers_count &gt; 50</code></pre><p>When using more than one spatial filter in a WHERE clause, no spatial index optimizations are used and the query is performed as if there were no spatial index. For example:</p><pre class="pre codeblock"><code>SELECT * FROM tweets_index 
    WHERE 
     ST_ANYINTERACT( ST_POLYGON('$polygonJSON1',8307), ST_POINT(geometry,8307), 0.05 )
     AND 
     ST_CONTAINS( ST_POLYGON('$polygonJSON2',8307), ST_POINT(geometry,8307), 0.05 )
</code></pre></div>
                        <!-- class="section" -->
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8D826B09-410D-4C12-A51A-3225D2A4439F">Spatial Spark SQL API</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
                  <div class="props_rev_3"><a id="GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588" name="GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588"></a><h5 id="BDSPA-GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588" class="sect5"><span class="enumeration_section">2.10.6.2 </span>Spatial Analysis Spark SQL UDFs
                     </h5>
                     <div>
                        <p>Spatial analysis functions are available as Spark 2 SQL UDFs (user-defined functions).</p>
                        <p>The same set of Hive UDFs is available as Spark UDFs for the Spark 2 Vector API. In order to start using the Spatial UDFs, the following method from class <code class="codeph">oracle.spatial.spark.vector.scala.sql.SpatialEnvironment</code> needs to be executed before calling any query containing a spatial UDF:
                        </p><pre class="pre codeblock"><code>SpatialEnvironment.setup(sparkSession)</code></pre><p>The input spatial data can be in GeoJSON, WKT, or WKB format. You can also use a spatial index for faster processing.</p>
                        <p>In the queries, spatial geometry type constructors, such as <a href="hive-spatial-functions.html#GUID-09F3C077-6179-4C58-A04B-59DD3DEAF1C7">ST_Polygon</a> or <a href="hive-spatial-functions.html#GUID-8AF179BD-808A-4EBA-9EFC-FC9E4F8E9F72">ST_Point</a>, can be used to create a GeoJSON representation of the input geometry and to add a SRID (coordinate system) for the geometry. Such constructors must be used if a geometry is specified in the query, even if the geometry is already in GeoJSON format &#x2013; <span class="bold"><span class="italic">unless</span></span> you use the spatial index <span class="bold">option</span> to set the SRID in the geometry, in which case a spatial geometry type constructor is not needed; for example: 
                        </p><pre class="pre codeblock"><code>spark.read().format(QuadTreeIndexRelation.Format()).schema(schema)
         <span class="bold">.option(QuadTreeIndexRelation.OptIncludeCRS(), true)</span> //avoid using Type Functions
         .load(indexPath).createOrReplaceTempView("tweets_index");</code></pre><ul style="list-style-type: disc;">
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588__PREREQUISITELIBRARIESFORSPATIALANAL-777C7EA4">Prerequisite Libraries for Spatial Analysis Spark SQL UDFs</a></p>
                           </li>
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588__USINGSPARKSQLUDFS-777BC4FB">Using Spark SQL UDFs</a></p>
                           </li>
                           <li>
                              <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588__USINGSPATIALINDEXESWITHSPARKUDFS-777BF779">Using Spatial Indexes with Spark UDFs</a></p>
                           </li>
                        </ul>
                        <div class="section" id="GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588__PREREQUISITELIBRARIESFORSPATIALANAL-777C7EA4">
                           <p class="subhead3">Prerequisite Libraries for Spatial Analysis Spark SQL UDFs</p>
                           <p>The required libraries for Spatial Analysis Spark SQL UDFs are:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><code class="codeph">sdohadoop-vector.jar</code></p>
                              </li>
                              <li>
                                 <p><code class="codeph">sdospark2-vector.jar</code></p>
                              </li>
                              <li>
                                 <p><code class="codeph">sdoutl.jar</code></p>
                              </li>
                              <li>
                                 <p><code class="codeph">sdoapi.jar</code></p>
                              </li>
                              <li>
                                 <p><code class="codeph">ojdbc8.jar</code></p>
                              </li>
                           </ul>
                        </div>
                        <!-- class="section" -->
                        <div class="section" id="GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588__USINGSPARKSQLUDFS-777BC4FB">
                           <p class="subhead3">Using Spark SQL UDFs</p>
                           <p>Spatial analysis Spark SQL UDFs are a series of Spark SQL user-defined functions used to create geometries and perform spatial operations using one or two geometries in creating a Spark SQL query.</p>
                           <p><a href="hive-spatial-functions.html#GUID-FFEED52D-AAA0-4251-9BB8-5F49D0A887B9" title="This appendix provides reference information about the Hive and Spark spatial SQL functions.">Hive and Spark Spatial SQL Functions</a> provides reference information for the available spatial functions.
                           </p>
                           <p>The following example returns the tweet records within a specific geographical polygon and where there are more than 50 followers. The general steps for the example are:</p>
                           <ol>
                              <li>
                                 <p>Set up the spatial SQL environment.</p>
                              </li>
                              <li>
                                 <p>Create a spatial RDD from geographical input.</p>
                              </li>
                              <li>
                                 <p>Create a DataSet from the SpatialRDD. A spatial DataSet contains a column called <span class="italic">geometry</span> whose values are in GeoJSON format.
                                 </p>
                              </li>
                              <li>
                                 <p>Register the DataSet so it can be used within SQL statements as a table.</p>
                              </li>
                              <li>
                                 <p>Create the query to filter the records.</p>
                              </li>
                              <li>
                                 <p>Execute the filter.</p>
                              </li>
                           </ol>
                           <p>Java Example:</p><pre class="pre codeblock"><code>import java.util.Arrays;
import java.util.List;

import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

import oracle.spatial.spark.vector.SparkRecordInfo;
import oracle.spatial.spark.vector.io.SpatialSources;
import oracle.spatial.spark.vector.rdd.SpatialJavaRDD;
import oracle.spatial.spark.vector.scala.sql.SpatialEnvironment;
import oracle.spatial.spark.vector.sql.SpatialJavaRDDConversions;

public class SpatialQueryExample {
  public static void main(String[] args) {
	SparkSession spark = SparkSession.builder().appName("SpatialEx").getOrCreate();
         //Setup spatial SQL environment
         SpatialEnvironment.setup(spark);
         String geoJSONInput = args[0];
         //The coordinate system the spatial data is expected to be
         int srid = 8307;
         // list of GeoJSON field names to be loaded for each feature
         List&lt;String&gt; fieldNames = Arrays.asList(new String[] {
			        "id", "followers_count", "friends_count", "location"} );
         // Create a spatial RDD from a GeoJSON file
	SpatialJavaRDD&lt;SparkRecordInfo&gt; spatialRDD =  
		SpatialSources.readGeoJSONRecordInfo(geoJSONInput, srid, fieldNames, 
			JavaSparkContext.fromSparkContext(spark.sparkContext()));
         // Create a DataSet from the SpatialRDD.
         Dataset&lt;Row&gt; spatialDF = SpatialJavaRDDConversions.toDataFrame(
				spatialRDD, fieldNames, spark);
         // Register the dataset so it can be used within SQL statements
         spatialDF.createOrReplaceTempView("sample_tweets");
	//polygon used to spatially filter data
         String qryWindow = "{\"type\": \"Polygon\",\"coordinates\": [[[-106, 25], [-106, 
			   30], [-104, 30], [-104, 25], [-106, 25]]]}";

	// Filter the tweets within the query window (somewhere in the north of Mexico)
         StringBuilder query =new StringBuilder()
                .append(" SELECT geometry, friends_count, location, followers_count")
                .append("       FROM sample_tweets ")
                .append("       WHERE ")
                .append("   ST_CONTAINS(ST_POLYGON('").append(qryWindow).append("', 8307), 
                                        ST_POINT(geometry, 8307), 0.05)")
                .append("   AND followers_count &gt; 50 ");
	//Execute the query
         spark.sql(query.toString()).show();
  }
}
</code></pre><p>Scala Example:</p><pre class="pre codeblock"><code>import org.apache.spark.sql.SparkSession
import oracle.spatial.spark.vector.sql.udf.function.FunctionExecutor
import oracle.spatial.spark.vector.scala.io.SpatialSources.ImplicitSpatialSources
import oracle.spatial.spark.vector.scala.sql.SpatialRDDConversions.ImplicitSpatialRDDConversions
import scala.collection.mutable.StringBuilder
import oracle.spatial.spark.vector.scala.sql.SpatialEnvironment

object SpatialQueryExample {
  def main(args: Array[String]): Unit = {
	val spark = SparkSession.builder().appName("SpatialQueryExample").getOrCreate()
	//Setup spatial SQL environment
         SpatialEnvironment.setup(spark)
         val geoJSONInput = args(0)
         //The coordinate system the spatial data is expected to be
         val srid = 8307
         // list of GeoJSON field names to be loaded for each feature
         val fieldNames = Seq("id", "followers_count", "friends_count", "location")
         // Create a spatial RDD from a GeoJSON file
         val spatialRDD = spark.sparkContext.readGeoJSONRecordInfo(geoJSONInput, srid, 
                                                                   fieldNames)
         // Create a DataSet from the SpatialRDD.
         val spatialDF = spatialRDD.toDataFrame(fieldNames)(spark)
         // Register the dataset so it can be used within SQL statements
         spatialDF.createOrReplaceTempView("sample_tweets")
         //polygon used to spatially filter data
         val qryWindow = """{"type": "Polygon","coordinates":
		       [[[-106, 25], [-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}"""

	// Filter the tweets within the query window (somewhere in the north of Mexico)
         val query =s""" SELECT geometry, friends_count, location, followers_count
         	         | FROM sample_tweets
                  	| WHERE
	                  |   ST_CONTAINS(ST_POLYGON('$qryWindow', $srid), 
			    ST_POINT(geometry, $srid), 0.05)
	                  |   AND followers_count &gt; 50 """.stripMargin
	//Execute the query
         val results = spark.sql(query)
         results.show()
  }
}
</code></pre></div>
                        <!-- class="section" -->
                        <div class="section" id="GUID-8EB22BC0-1322-494F-8B5F-16C9C705D588__USINGSPATIALINDEXESWITHSPARKUDFS-777BF779">
                           <p class="subhead3">Using Spatial Indexes with Spark UDFs</p>
                           <p>Spatial Spark SQL UDFs can process indexed data sets. You can create an index on the fly or you can use a persisted spatial index. For more information, see <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8572265E-03C3-4D0A-AE6B-63A3E801E4C5">Spatially Indexing a Spatial RDD</a>.
                           </p>
                           <p>The following example filters the tweet records that spatially interact with a specified polygon or with fewer than 2 followers, and it uses the spatial index option to include the SRID in the geometry column.  In this scenario there is no need to wrap the geometry in a Type function. </p>
                           <p>The general steps are:</p>
                           <ol>
                              <li>
                                 <p>Set up the spatial SQL environment.</p>
                              </li>
                              <li>
                                 <p>Read a persisted index into a DataSet and register it as a table.</p>
                              </li>
                              <li>
                                 <p>Create the query to filter the records.</p>
                              </li>
                              <li>
                                 <p>Execute the filter.</p>
                              </li>
                           </ol>
                           <p>Java Example:</p><pre class="pre codeblock"><code>import org.apache.spark.SparkConf;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.Metadata;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;

import oracle.spatial.spark.vector.scala.sql.SpatialEnvironment;
import oracle.spatial.spark.vector.scala.sql.index.quadtree.QuadTreeIndexRelation;
import oracle.spatial.spark.vector.serialization.SpatialVectorKryoRegistrator;

public class IndexOptionsAndSchemaTypesExample {
  public static void main(String[] args) {
	SparkConf conf = new SparkConf();
	// the index is expected to have its partitions indexed with an R-Tree
         // so the following line is required if Kryo is used
         SpatialVectorKryoRegistrator.register(conf);
	SparkSession spark=SparkSession.builder().config(conf).appName("I").getOrCreate();
	//Setup spatial SQL environment
         SpatialEnvironment.setup(spark);
         String indexPath = args[0];
         //Create the required schema for the index.
         StructType schema = new StructType(new StructField[]{
	new StructField("followers_count", DataTypes.IntegerType, true, Metadata.empty()),
         new StructField("friends_count", DataTypes.IntegerType, true, Metadata.empty()),
         new StructField("location", DataTypes.StringType, true, Metadata.empty())
         });
	//read an existing spatial index and register it as table called "tweets_index"
         spark.read().format(QuadTreeIndexRelation.Format()).schema(schema)
         .option(QuadTreeIndexRelation.OptIncludeCRS(), true)//avoid using Type Functions
         .load(indexPath).createOrReplaceTempView("tweets_index");

	//polygon used to spatially filter data
         String qryWindow = "{\"type\": \"Polygon\",\"coordinates\": [[[-106, 25],
    			[-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}";

	// Retrieve all the tweets which spatially interact with the given polygon                    
  // Note that geometry column is not surrounded by the ST_POINT function
         StringBuilder query =new StringBuilder()
                .append(" SELECT geometry, friends_count, location, followers_count")
                .append("       FROM tweets_index ")
                .append("       WHERE ")
                .append("   ST_ANYINTERACT(
                                        ST_POLYGON('").append(qryWindow).append("', 8307),
                                                   geometry, 0.05)")
                .append("   OR followers_count = 2 ");
                System.out.println(query);
                spark.sql(query.toString()).show();
  }
}
</code></pre><p>Scala Example:</p><pre class="pre codeblock"><code>import org.apache.spark.sql.SparkSession
import oracle.spatial.spark.vector.sql.udf.function.FunctionExecutor
import oracle.spatial.spark.vector.scala.io.SpatialSources.ImplicitSpatialSources
import oracle.spatial.spark.vector.scala.sql.SpatialRDDConversions.ImplicitSpatialRDDConversions
import scala.collection.mutable.StringBuilder
import org.apache.spark.SparkConf
import oracle.spatial.spark.vector.serialization.SpatialVectorKryoRegistrator
import oracle.spatial.spark.vector.scala.sql.SpatialEnvironment
import oracle.spatial.spark.vector.scala.sql.index.quadtree.QuadTreeIndexRelation
import oracle.spatial.spark.vector.scala.sql.util.SchemaUtils
import org.apache.spark.sql.types.StructField
import oracle.spatial.spark.vector.scala.sql.util.SchemaUtils
import org.apache.spark.sql.types.StructType
import org.apache.spark.sql.types.IntegerType
import org.apache.spark.sql.types.Metadata
import org.apache.spark.sql.types.StringType

object IndexOptionsAndSchemaTypesExample {
  def main(args: Array[String]): Unit = {
	val conf = new SparkConf
	//the index is expected to have its partitions indexed with an R-Tree
	//so the following line is required if Kryo is used
	SpatialVectorKryoRegistrator.register(conf)
	val spark = SparkSession.builder().config(conf).appName("IndexEx").getOrCreate()
	//Setup spatial SQL environment
	SpatialEnvironment.setup(spark)
	val indexPath = args(0)
	
	//Create the required schema for the index
	val schema = StructType(Array(
        	        StructField("followers_count",IntegerType, true, Metadata.empty),
	        StructField("friends_count",IntegerType, true, Metadata.empty),
	        StructField("location",StringType, true, Metadata.empty)))

	//read an existing spatial index and register it as table called "tweets_index"
	spark.read.format(QuadTreeIndexRelation.Format).schema(schema)
	.option(QuadTreeIndexRelation.OptIncludeCRS, true)//set to avoid using Type Functs
         .load(indexPath).createOrReplaceTempView("tweets_index")

	//polygon used to spatially filter the data
	val polygonJSON = """{"type": "Polygon", "coordinates": [[[-106, 25], [-106, 30], 
			[-104, 30], [-104, 25], [-106, 25]]]}"""

	//Spatial reference system ID of the data
	val srid = 8307
	//Retrieve tweets which spatially interact with the given polygon
	//Note that geometry column is not surrounded by the ST_POINT function
	val query = s"""SELECT geometry, location, friends_count, followers_count
                | FROM tweets_index
                | WHERE
                |  ST_ANYINTERACT( ST_POLYGON('$polygonJSON',$srid), geometry, 0.05 )
                |  OR followers_count = 2 """.stripMargin
	println(s"Executing: \n$query")
	val results = spark.sql(query)
	results.show()
  }
}
</code></pre></div>
                        <!-- class="section" -->
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-8D826B09-410D-4C12-A51A-3225D2A4439F">Spatial Spark SQL API</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div>
               <div class="props_rev_3"><a id="GUID-839E48A5-3E1A-4A1A-A204-F938AFFCD339" name="GUID-839E48A5-3E1A-4A1A-A204-F938AFFCD339"></a><h4 id="BDSPA-GUID-839E48A5-3E1A-4A1A-A204-F938AFFCD339" class="sect4"><span class="enumeration_section">2.10.7 </span>JDBC Data Sources for Spatial RDDs
                  </h4>
                  <div>
                     <p>Oracle Database data can be used as the data source of a Spatial RDD by using the Spark Vector Analysis API.</p>
                     <p>The class <code class="codeph">oracle.spatial.spark.vector.util.JDBCUtils</code> (or <code class="codeph">oracle.spatial.spark.vector.scala.util.JDBCUtils</code> for Scala) provides convenience methods for creating a Spatial RDD from an Oracle database table or from a SQL query to an Oracle database. The table or SQL query should contain one column of type SDO_GEOMETRY in order to create a Spatial RDD.
                     </p>
                     <p>Both the from-table and from-query method versions require a connection to the Oracle database, which is supplied by a lambda function defined by the template <code class="codeph">oracle.spatial.spark.vector.util.ConnectionSupplier</code> (or <code class="codeph">oracle.spatial.spark.vector.scala.util.ConnectionSupler</code> for Scala).
                     </p>
                     <p>The resulting Spatial RDD type parameter will always be <code class="codeph">SparkRecordInfo</code>, that is, the resulting RDD will contain records of the type <code class="codeph">SparkRecordInfo</code>, which will contain the fields specified when querying the table or the columns in the SELECT section of the SQL query. By default, the name and type of the columns retrieved are inferred using the <code class="codeph">ResultSet</code> metadata; however, you can control the naming and type of the retrieved fields by supplying an implementation of <code class="codeph">SparkRecordInfoProvider</code></p>
                     <p>The following examples show how to create a Spatial RDD from a table and from a SQL query respectively.</p>
                     <div class="example" id="GUID-839E48A5-3E1A-4A1A-A204-F938AFFCD339__GUID-EA902BEC-B3B2-435A-883D-E2A975850565">
                        <p class="titleinexample">Example 2-3 Creating a Spatial RDD from a Database Table</p><pre class="pre codeblock"><code>SpatialJavaRDD&lt;SparkRecordInfoProvider&gt; jdbcSpatialRDD = JDBCUtils.createSpatialRDDFromTable(
	sparkContext, //spark context
	()-&gt;{
		Class.forName("oracle.jdbc.driver.OracleDriver");  
		return new DriverManager.getConnection(connURL, usr, pwd);
	}, //DB connection supplier lambda
	“VEHICLES”, //DB table
	Arrays.asList(new String[]{"ID","DESC","LOCATION"}), //list of fields to retrieve
	null //SparkRecordInfoProvider&lt;ResultSet, SparkRecordIngo&gt; (optional)
);
</code></pre></div>
                     <!-- class="example" -->
                     <div class="example" id="GUID-839E48A5-3E1A-4A1A-A204-F938AFFCD339__GUID-653CFCD5-C9E9-434A-996E-99FD742C1A32">
                        <p class="titleinexample">Example 2-4 Creating a Spatial RDD from a SQL Query to the Database</p><pre class="pre codeblock"><code>SpatialJavaRDD&lt;SparkRecordInfoProvider&gt; jdbcSpatialRDD = JDBCUtils.createSpatialRDDFromQuery(
	sparkContext, //spark context
	()-&gt;{
		Class.forName("oracle.jdbc.driver.OracleDriver");  
		return new DriverManager.getConnection(connURL, usr, pwd);
	}, //DB connection supplier lambda
	“SELECT * FROM VEHICLES WHERE category &gt; 5”, //SQL query
	null //SparkRecordInfoProvider&lt;ResultSet, SparkRecordIngo&gt; (optional)
);
</code></pre><p>In the preceding examples, data from the Oracle database is queried and partitioned to create a Spark RDD. The number and size of the partitions is determined automatically by the Spark Vector Analysis API.</p>
                        <p>You can also specify the desired number of database rows to be contained in a Spark partition by calling a method overload that takes this number as a parameter. Manually specifying the number of rows per partition can improve the performance of the Spatial RDD creation.</p>
                     </div>
                     <!-- class="example" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-96B6492E-E93F-46F6-844F-E59F39DB1B00" title="Oracle Big Data Spatial Vector Analysis for Apache Spark is a spatial vector analysis API for Java and Scala that provides spatially-enabled RDDs (Resilient Distributed Datasets) that support spatial transformations and actions, spatial partitioning, and indexing.">Oracle Big Data Spatial Vector Analysis for Spark</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div>
            <div class="props_rev_3"><a id="GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2" name="GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2"></a><h3 id="BDSPA-GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2" class="sect3"><span class="enumeration_section">2.11 </span>Oracle Big Data Spatial Vector Hive Analysis
               </h3>
               <div>
                  <p>Oracle Big Data Spatial Vector Hive Analysis provides spatial functions to analyze the data using Hive.</p>
                  <p>The spatial data can be in any Hive supported format. You can also use a spatial index created with the Java analysis API (see <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a>) for fast processing.
                  </p>
                  <p>The supported features include:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF">Using the Hive Spatial API</a></p>
                     </li>
                     <li>
                        <p><a href="using-big-data-spatial-graph-spatial-data.html#GUID-D3C632D4-4244-46A1-B696-9B2A6087DC47">Using Spatial Indexes in Hive</a></p>
                     </li>
                  </ul>
                  <p>See also <a href="using-big-data-spatial-graph-spatial-data.html#GUID-5DA03480-50B5-4D9E-ADE7-189D8D457965">HiveRecordInfoProvider</a> for details about the implementation of these features.
                  </p>
                  <p><a href="hive-spatial-functions.html#GUID-FFEED52D-AAA0-4251-9BB8-5F49D0A887B9" title="This appendix provides reference information about the Hive and Spark spatial SQL functions.">Hive and Spark Spatial SQL Functions</a> provides reference information about the available functions.
                  </p>
                  <div class="section">
                     <p class="subhead2">Prerequisite Libraries</p>
                     <p>The following libraries are required by the Spatial Vector Hive Analysis API.</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">sdohadoop-vector-hive.jar</code></p>
                        </li>
                        <li>
                           <p><code class="codeph">sdohadoop-vector.jar</code></p>
                        </li>
                        <li>
                           <p><code class="codeph">sdoutil.jar</code></p>
                        </li>
                        <li>
                           <p><code class="codeph">sdoapi.jar</code></p>
                        </li>
                        <li>
                           <p><code class="codeph">ojdbc.jar</code></p>
                        </li>
                     </ul>
                  </div>
                  <!-- class="section" -->
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5DA03480-50B5-4D9E-ADE7-189D8D457965">HiveRecordInfoProvider</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF">Using the Hive Spatial API</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-D3C632D4-4244-46A1-B696-9B2A6087DC47">Using Spatial Indexes in Hive</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="props_rev_3"><a id="GUID-5DA03480-50B5-4D9E-ADE7-189D8D457965" name="GUID-5DA03480-50B5-4D9E-ADE7-189D8D457965"></a><h4 id="BDSPA-GUID-5DA03480-50B5-4D9E-ADE7-189D8D457965" class="sect4"><span class="enumeration_section">2.11.1 </span>HiveRecordInfoProvider
                  </h4>
                  <div>
                     <p>A record in a Hive table may contain a geometry field in any format like JSON, WKT, or a user-specifiedformat. Geometry constructors like ST_Geometry can create a geometry receiving the GeoJSON, WKT, or WKB representation of the geometry. If the geometry is stored in another format, a HiveRecordInfoProvider can be used.</p>
                     <p><code class="codeph">HiveRecordInfoProvider</code>&nbsp;is a component that interprets the geometry field representation and returns the geometry in a GeoJSON format.
                     </p>
                     <p>The returned geometry must contain the geometry SRID, as in the following example format: </p><pre class="oac_no_warn" dir="ltr">{"type":&lt;geometry-type", "crs": {"type": "name", "properties": {"name": "EPSG:4326"}}"coordinates":[c1,c2,....cn]} </pre><p>The&nbsp;<code class="codeph">HiveRecordInfoProvider</code>&nbsp;interface has the following methods:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">void setCurrentRecord(Object record)</code></p>
                        </li>
                        <li>
                           <p><code class="codeph">String getGeometry()</code></p>
                        </li>
                     </ul>
                     <p>The method <code class="codeph">setCurrentRecord()</code> is called by passing the current geometry field provided when creating a geometry in Hive. The <code class="codeph">HiveRecordInfoProvider</code> is used then to get the geometry or to return null if the record has no spatial information. 
                     </p>
                     <p>The information returned by the <code class="codeph">HiveRecordInfoProvider</code> is used by the Hive Spatial functions to create geometries  (see <a href="hive-spatial-functions.html#GUID-FFEED52D-AAA0-4251-9BB8-5F49D0A887B9" title="This appendix provides reference information about the Hive and Spark spatial SQL functions.">Hive and Spark Spatial SQL Functions</a>).
                     </p>
                     <div class="section">
                        <p class="subhead3">Sample HiveRecordInfoProvider Implementation</p>
                        <div class="p">This sample implementation, named <code class="codeph">SimpleHiveRecordInfoProvider</code>, takes text records in JSON format. The following is a sample input record:<pre class="pre codeblock"><code>{"longitude":-71.46, "latitude":42.35}</code></pre></div>
                        <p>When <code class="codeph">SimpleHiveRecordInfoProvider</code> is instantiated, a JSON <code class="codeph">ObjectMapper</code> is created. The <code class="codeph">ObjectMapper</code> is used to parse records values later when&nbsp;<code class="codeph">setCurrentRecord()</code>&nbsp;is called. The geometry is represented as latitude-longitude pair, and is used to create a point geometry using the&nbsp;<code class="codeph">JsonUtils.readGeometry()</code>&nbsp;method. Then the GeoJSON format to be returned is created using <code class="codeph">GeoJsonGen.asGeometry()</code>, and the SRID is added to the GeoJSON using <code class="codeph">JsonUtils.addSRIDToGeoJSON().</code></p><pre class="pre codeblock"><code>public class SimpleHiveRecordInfoProvider implements HiveRecordInfoProvider{
  private static final Log LOG =
    LogFactory.getLog(SimpleHiveRecordInfoProvider.class.getName());

  private JsonNode recordNode = null;
  private ObjectMapper jsonMapper = null;

  public SimpleHiveRecordInfoProvider(){
    jsonMapper = new ObjectMapper();
  }
  
  @Override
  public void setCurrentRecord(Object record) throws Exception {
    try{
      if(record != null){
        //parse the current value
        recordNode = jsonMapper.readTree(record.toString());
      }
    }catch(Exception ex){
      recordNode = null;
      LOG.warn("Problem reading JSON record
        value:"+record.toString(), ex);
    }    
  }

  @Override
  public String getGeometry() {
    if(recordNode == null){
      return null;
    }
    
    JGeometry geom = null;

    try{
      geom = JsonUtils.readGeometry(recordNode, 
          2, //dimensions
          8307 //SRID
          );
    }catch(Exception ex){
      recordNode = null;
      LOG.warn("Problem reading JSON record
        geometry:"+recordNode.toString(), ex);
    }
    
    if(geom != null){
      StringBuilder res = new StringBuilder();
      //Get a GeoJSON representation of the JGeometry
      GeoJsonGen.asGeometry(geom, res);
      String result = res.toString();
      //add SRID to GeoJSON and return the result
      return JsonUtils.addSRIDToGeoJSON(result, 8307);
    }
    
     return null;
  }
}
</code></pre></div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2" title="Oracle Big Data Spatial Vector Hive Analysis provides spatial functions to analyze the data using Hive.">Oracle Big Data Spatial Vector Hive Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF" name="GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF"></a><h4 id="BDSPA-GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF" class="sect4"><span class="enumeration_section">2.11.2 </span>Using the Hive Spatial API
                  </h4>
                  <div>
                     <p>The Hive Spatial API consists of Oracle-supplied Hive User Defined Functions that can be used to create geometries and perform operations using one or two geometries.</p>
                     <p>The functions can be grouped into logical categories: types, single-geometry, and two-geometries. (<a href="hive-spatial-functions.html#GUID-FFEED52D-AAA0-4251-9BB8-5F49D0A887B9" title="This appendix provides reference information about the Hive and Spark spatial SQL functions.">Hive and Spark Spatial SQL Functions</a> lists the functions in each category and provides reference information about each function.)
                     </p>
                     <div class="example" id="GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF__GUID-0FAEB94A-8B0C-46EB-8B51-504E4A837446">
                        <p class="titleinexample">Example 2-5 Hive Script</p>
                        <p>The following example script returns information about Twitter users in a data set who are within a specified geographical polygon and who have more than 50 followers. It does the following:</p>
                        <ol>
                           <li>
                              <p>Adds the necessary jar files:</p><pre class="pre codeblock"><code>add jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/ojdbc8.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoutl.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoapi.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector-hive.jar;
</code></pre></li>
                           <li>
                              <p>Creates the Hive user-defined functions that will be used:</p><pre class="pre codeblock"><code>create temporary function ST_Point as 'oracle.spatial.hadoop.vector.hive.ST_Point';
create temporary function ST_Polygon as 'oracle.spatial.hadoop.vector.hive.ST_Polygon';
create temporary function ST_Contains as 'oracle.spatial.hadoop.vector.hive.function.ST_Contains';
</code></pre></li>
                           <li>
                              <p>Creates a Hive table based on the files under the HDFS directory <code class="codeph">/user/oracle/twitter</code>. The <code class="codeph">InputFormat</code> used in this case is <code class="codeph">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat</code> and the Hive SerDe is a user-provided SerDe <code class="codeph">oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe</code>.
                              </p><pre class="pre codeblock"><code>CREATE EXTERNAL TABLE IF NOT EXISTS sample_tweets (id STRING, geometry STRING, followers_count STRING, friends_count STRING, location STRING)
ROW FORMAT SERDE 'oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe'
STORED AS INPUTFORMAT 'oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION '/user/oracle/twitter';
</code></pre></li>
                           <li>
                              <p>Runs a spatial query receiving an ST_Polygon query area and the ST_Point tweets geometry, and using 0.5 as the tolerance value for the spatial operation. The output will be information about Twitter users in the query area who have more than 50 followers.</p><pre class="pre codeblock"><code>SELECT id, followers_count, friends_count, location FROM sample_tweets
WHERE ST_Contains(
  ST_Polygon(
    '{"type": "Polygon",
    "coordinates": 
      [[[-106, 25],[-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}', 
    8307
  ), 
  ST_Point(geometry, 8307), 
  0.5
)
and followers_count &gt; 50;
</code></pre></li>
                        </ol>
                        <p>The complete script is as follows:</p><pre class="pre codeblock"><code>add jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/ojdbc8.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoutl.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoapi.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector-hive.jar;

create temporary function ST_Point as 'oracle.spatial.hadoop.vector.hive.ST_Point';
create temporary function ST_Polygon as 'oracle.spatial.hadoop.vector.hive.ST_Polygon';
create temporary function ST_Contains as 'oracle.spatial.hadoop.vector.hive.function.ST_Contains';
 
CREATE EXTERNAL TABLE IF NOT EXISTS sample_tweets (id STRING, geometry STRING, followers_count STRING, friends_count STRING, location STRING)                                         
ROW FORMAT SERDE 'oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe'              
STORED AS INPUTFORMAT 'oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION '/user/oracle/twitter';


SELECT id, followers_count, friends_count, location FROM sample_tweets
WHERE 
ST_Contains(
  ST_Polygon(
    '{"type": "Polygon",
    "coordinates": 
      [[[-106, 25],[-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}', 
    8307
  ), 
  ST_Point(geometry, 8307), 
  0.5
)
and followers_count &gt; 50;
</code></pre></div>
                     <!-- class="example" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2" title="Oracle Big Data Spatial Vector Hive Analysis provides spatial functions to analyze the data using Hive.">Oracle Big Data Spatial Vector Hive Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-D3C632D4-4244-46A1-B696-9B2A6087DC47" name="GUID-D3C632D4-4244-46A1-B696-9B2A6087DC47"></a><h4 id="BDSPA-GUID-D3C632D4-4244-46A1-B696-9B2A6087DC47" class="sect4"><span class="enumeration_section">2.11.3 </span>Using Spatial Indexes in Hive
                  </h4>
                  <div>
                     <p>Hive spatial queries can use a previously created spatial index, which you can create using the Java API (see <a href="using-big-data-spatial-graph-spatial-data.html#GUID-50C85114-78F7-40FE-A633-54E3352724DE">Spatial Indexing</a>).
                     </p>
                     <p>If you do not need to use the index in API functions that will access the original data, you can specify <code class="codeph">isMapFileIndex=false</code>  when you call <code class="codeph">oracle.spatial.hadoop.vector.mapred.job.SpatialIndexing</code>, or you can use the function <code class="codeph">setMapFileIndex(false)</code>. In these cases, the index will have the following structure:
                     </p><pre class="pre codeblock"><code>HDFSIndexDirectory/part-xxxxx</code></pre><p>And in these cases, when creating a Hive table, just provide the folder where you created the index.</p>
                     <p>If you need to access the original data and you do not set the parameter <code class="codeph">isMapFileIndex=false</code>, the index structure is as follows:
                     </p><pre class="pre codeblock"><code>part-xxxxx
  data
  index
</code></pre><p>In such cases, to create a Hive table, the data files of the index are needed. Copy the <code class="codeph">data</code> files into a new HDFS folder, with each data file having a different name, like data1, data2,, and so on. The new folder will be used to create the Hive table.
                     </p>
                     <p>The index contains the geometry records and extra fields. That data can be used when creating the Hive table.</p>
                     <p>(Note that <a href="using-big-data-spatial-graph-spatial-data.html#GUID-76C29D55-F043-407D-9402-FF9DBF94BDB8">Spatial Indexing Class Structure</a> describes the index structure, and <a href="using-big-data-spatial-graph-spatial-data.html#GUID-C73176F7-86C7-4743-95A7-56FCB919CF04">RecordInfoProvider</a> provides an example of a <code class="codeph">RecordInfoProvider</code> adding extra fields.)
                     </p>
                     <p><code class="codeph">InputFormat oracle.spatial.hadoop.vector.mapred.input.SpatialIndexTextInputFormat</code> will be used to read the index. The output of this <code class="codeph">InputFormat</code> is GeoJSON.
                     </p>
                     <p>Before running any query, you can specify a minimum bounding rectangle (MBR) that will perform a first data filtering using <code class="codeph">SpatialIndexTextInputFormat</code>..
                     </p>
                     <div class="example" id="GUID-D3C632D4-4244-46A1-B696-9B2A6087DC47__HIVESCRIPT-01CC9805">
                        <p class="titleinexample">Example 2-6 Hive Script Using a Spatial Index</p>
                        <p>The following example script returns information about Twitter users in a data set who are within a specified geographical polygon and who have more than 50 followers. It does the following:</p>
                        <ol>
                           <li>
                              <p>Adds the necessary jar files:</p><pre class="pre codeblock"><code>add jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/ojdbc8.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoutl.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoapi.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector-hive.jar;
</code></pre></li>
                           <li>
                              <p>Creates the Hive user-defined functions that will be used:</p><pre class="pre codeblock"><code>create temporary function ST_Point as 'oracle.spatial.hadoop.vector.hive.ST_Point';
create temporary function ST_Polygon as 'oracle.spatial.hadoop.vector.hive.ST_Polygon';
create temporary function ST_Contains as 'oracle.spatial.hadoop.vector.hive.function.ST_Contains';
</code></pre></li>
                           <li>
                              <p>Sets the data maximum and minimum boundaries (dim1Min,dim2Min,dim1Max,dim2Max):</p><pre class="pre codeblock"><code>set oracle.spatial.boundaries=-180,-90,180,90;</code></pre></li>
                           <li>
                              <div class="p">Sets the extra fields contained in the spatial index that will be included in the table creation:<pre class="pre codeblock"><code>set oracle.spatial.index.includedExtraFields=followers_count,friends_count,location;</code></pre></div>
                           </li>
                           <li>
                              <p>Creates a Hive table based on the files under the HDFS directory /user/oracle/twitter. The <code class="codeph">InputFormat</code> used in this case is <code class="codeph">oracle.spatial.hadoop.vector.mapred.input.SpatialIndexTextInputFormat</code> and the Hive SerDe is a user-provided SerDe <code class="codeph">oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe</code>. (The code for <code class="codeph">oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe</code> is included with the Hive examples.) The geometry of the tweets will be saved in the geometry column with the format {"longitude":<span class="italic">n</span>, "latitude":<span class="italic">n</span>} :
                              </p><pre class="pre codeblock"><code>CREATE EXTERNAL TABLE IF NOT EXISTS sample_tweets_index (id STRING, geometry STRING, followers_count STRING, friends_count STRING, location STRING)                                         
ROW FORMAT SERDE 'oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe'              
STORED AS INPUTFORMAT 'oracle.spatial.hadoop.vector.mapred.input.SpatialIndexTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION '/user/oracle/twitter/index';
</code></pre></li>
                           <li>
                              <p>Defines the minimum bounding rectangle (MBR) to filter in the <code class="codeph">SpatialIndexTextInputFormat</code>. Any spatial query will only have access to the data in this MBR. If no MBR is specified, then the data boundaries will be used. This setting is recommended to improve the performance.
                              </p><pre class="pre codeblock"><code>set oracle.spatial.spatialQueryWindow={"type": "Polygon","coordinates": [[[-107, 24], [-107, 31], [-103, 31], [-103, 24], [-107, 24]]]};</code></pre></li>
                           <li>
                              <p>Runs a a spatial query receiving an ST_Polygon query area and the ST_Point tweets geometry, and using 0.5 as the tolerance value for the spatial operation. The tweet geometries are in GeoJSON format, and the ST_Point function is usedspecifying the SRID as 8307.. The output will be information about Twitter users in the query area who have more than 50 followers.</p><pre class="pre codeblock"><code>SELECT id, followers_count, friends_count, location FROM sample_tweets
WHERE ST_Contains(
  ST_Polygon('{"type": "Polygon","coordinates": [[[-106, 25], [-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}', 8307)
  , ST_Point(geometry, 8307)
  , 0.5)
  and followers_count &gt; 50;
</code></pre></li>
                        </ol>
                        <p>The complete script is as follows. (Differences between this script and the one in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-DEBAB692-35D9-41AD-8044-DE916CDE6BCF">Using the Hive Spatial API</a> are marked in bold; however, all of the steps are described in the preceding list.)
                        </p><pre class="pre codeblock"><code>add jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/ojdbc8.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoutl.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdoapi.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector.jar
  /opt/oracle/oracle-spatial-graph/spatial/vector/jlib/sdohadoop-vector-hive.jar;

create temporary function ST_Polygon as 'oracle.spatial.hadoop.vector.hive.ST_Polygon';
create temporary function ST_Point as 'oracle.spatial.hadoop.vector.hive.ST_Point';
create temporary function ST_Contains as 'oracle.spatial.hadoop.vector.hive.function.ST_Contains';

<span class="bold">set oracle.spatial.boundaries=-180,-90,180,90;
</span><span class="bold">set oracle.spatial.index.includedExtraFields=followers_count,friends_count,location;
</span>
CREATE EXTERNAL TABLE IF NOT EXISTS sample_tweets_index (id STRING, geometry STRING, followers_count STRING, friends_count STRING, location STRING)                                         
ROW FORMAT SERDE 'oracle.spatial.hadoop.vector.hive.json.GeoJsonSerDe'              
STORED AS INPUTFORMAT <span class="bold">'oracle.spatial.hadoop.vector.mapred.input.SpatialIndexTextInputFormat'</span>
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION '/user/oracle/twitter/<span class="bold">index'</span>;

<span class="bold">set oracle.spatial.spatialQueryWindow={"type": "Polygon","coordinates": [[[-107, 24], [-107, 31], [-103, 31], [-103, 24], [-107, 24]]]};</span>

SELECT id, followers_count, friends_count, location FROM sample_tweets
WHERE ST_Contains(
  ST_Polygon('{"type": "Polygon","coordinates": [[[-106, 25], [-106, 30], [-104, 30], [-104, 25], [-106, 25]]]}', 8307)
  , ST_Point(geometry, <span class="bold">8307</span>)
  , 0.5)
  and followers_count &gt; 50;
</code></pre></div>
                     <!-- class="example" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-04F31B8A-6F6B-4568-BA0B-845CD68316B2" title="Oracle Big Data Spatial Vector Hive Analysis provides spatial functions to analyze the data using Hive.">Oracle Big Data Spatial Vector Hive Analysis</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="BDSPA173"></a><div class="props_rev_3"><a id="GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" name="GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6"></a><h3 id="BDSPA-GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" class="sect3"><span class="enumeration_section">2.12 </span>Using the Oracle Big Data SpatialViewer Web Application
               </h3>
               <div>
                  <p>You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.</p>
                  <p>These include tasks related to spatial indexing, creating and showing thematic maps, loading rasters into HDFS, visualizing uploaded rasters in the globe, selecting individual or multiple footprints, performing raster algebra operations, dealing with gaps and overlaps, combining selected footprints, generating a new image with the specified file format from the selected footprints, and applying user-specific processing.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-0C624B33-C76A-4812-8406-CCC4D6396AE5">Creating a Hadoop Spatial Index Using SpatialViewer</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-12F06102-D5AD-40E8-9153-10A67F81A792">Exploring the Hadoop Indexed Spatial Data</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-5E181C06-29E6-4226-AF99-A17AF6C75E9F">Creating a Spark Spatial Index Using SpatialViewer</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-9BBEA82F-5D48-4416-B1AC-EE02CE7BE30B">Exploring the Spark Indexed Spatial Data</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-7DA2DDA9-F31B-4166-9136-CECD17B95703">Running a Categorization Job Using SpatialViewer</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-4EFFC3BA-67C4-4260-9E86-96D04D37F57D">Viewing the Categorization Results</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-0AF440D7-015F-4ECA-92BA-3EDDC7853F23">Saving Categorization Results to a File</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C31C18E9-825A-478A-94E2-49BA29D2EBE6">Creating and Deleting Templates</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A9947B46-0104-430F-89EE-F8A0D80CD9D8">Configuring Templates</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-07EC4895-9316-4128-AEB0-36847D82255E">Running a Clustering Job Using SpatialViewer</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-90864EE1-DF20-4D74-90E1-C7317DC66B4F">Viewing the Clustering Results</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-99247061-D15C-41AC-9DBD-B8AB0B8BEED3">Saving Clustering Results to a File</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-95FDF8DF-7841-4A49-A20E-A293BC9F6753">Running a Binning Job Using SpatialViewer</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-2E69B928-CBB4-4EB4-B4CD-1E98C1E85914">Viewing the Binning Results</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-144C9A5A-5FCB-4391-80CF-9D80070BFB2E">Saving Binning Results to a File</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-ECC8BE1E-7519-44B0-BEA1-A70833A8F213">Running a Job to Create an Index Using the Command Line</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-C6FF86B5-B29B-4594-82F6-9469E82064C5">Running a Job to Create a Categorization Result</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-8AD2EAD2-4593-4C62-88F6-5B040346956F">Running a Job to Create a Clustering Result</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A50010C2-47B9-49FA-A421-84A9486F51F6">Running a Job to Create a Binning Result</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-7ACFE882-F09D-4751-B2DE-70DC865A183C">Running a Job to Perform Spatial Filtering</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-D3914D3E-A3EF-44DA-8CFC-08915C1F24DF">Running a Job to Get Location Suggestions</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-AB021393-03B6-48F8-98D2-45878F568CAF">Running a Job to Perform a Spatial Join</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-A72097FA-D4DE-43D2-9C67-3791195D79E9">Running a Job to Perform Partitioning</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-39A85E2C-7F5C-47F0-8CC5-11D355A9DC66">Using Multiple Inputs</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4">Loading Images from the Local Server to the HDFS Hadoop Cluster</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-95B0C667-3D27-4225-8796-7C8F78CE624F">Visualizing Rasters in the Globe</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-BDBA610E-0C5D-4A20-924A-629CE8ACF48F">Processing a Raster or Multiple Rasters with the Same MBR</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-4BB63E8A-80DE-4D3F-A04F-8C0F4D56B419">Creating a Mosaic Directly from the Globe</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-9E4A4947-C9F7-435F-B318-1CBC00B12BE0">Adding Operations for Raster Processing</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-B0FE7112-6744-40E0-892A-C90D823E75C9">Creating a Slope Image from the Globe</a><br></li>
                     <li class="ulchildlink"><a href="using-big-data-spatial-graph-spatial-data.html#GUID-46977902-9C1D-42CE-B7C9-A69A2258491F">Changing the Image File Format from the Globe</a><br></li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-1FD11649-E864-4B55-BB24-8D405667E406" title="This chapter provides conceptual and usage information about loading, storing, accessing, and working with spatial data in a Big Data environment.">Using Big Data Spatial and Graph with Spatial Data</a></p>
                     </div>
                  </div>
               </div>
               <a id="BDSPA174"></a><div class="props_rev_3"><a id="GUID-0C624B33-C76A-4812-8406-CCC4D6396AE5" name="GUID-0C624B33-C76A-4812-8406-CCC4D6396AE5"></a><h4 id="BDSPA-GUID-0C624B33-C76A-4812-8406-CCC4D6396AE5" class="sect4"><span class="enumeration_section">2.12.1 </span>Creating a Hadoop Spatial Index Using SpatialViewer
                  </h4>
                  <div>
                     <div class="section">
                        <p>To create a Hadoop spatial index using SpatialViewer, follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code></p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Spatial Index</span>.
                              </p>
                           </li>
                           <li>
                              <p>Specify all the required details:</p>
                              <ol type="a">
                                 <li>
                                    <p>Index name.</p>
                                 </li>
                                 <li>
                                    <p>Path of the file or files to index in HDFS. For example, <code class="codeph">/user/oracle/bdsg/tweets.json</code>.
                                    </p>
                                 </li>
                                 <li>
                                    <p>New index path: This is the job output path. For example: <code class="codeph">/user/oracle/bdsg/index</code>.
                                    </p>
                                 </li>
                                 <li>
                                    <p>SRID of the geometries to be indexed. Example: 8307</p>
                                 </li>
                                 <li>
                                    <p>Tolerance of the geometries to be indexed. Example: 0.05</p>
                                 </li>
                                 <li>
                                    <p>Input Format class: The input format class. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat</code></p>
                                 </li>
                                 <li>
                                    <p>Record Info Provider class: The class that provides the spatial information. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider</code>.
                                    </p>
                                    <div class="infoboxnote" id="GUID-0C624B33-C76A-4812-8406-CCC4D6396AE5__GUID-446C3B02-1037-4545-9D9B-402EFC47895D">
                                       <p class="notep1">Note:</p>
                                       <p>If the <code class="codeph">InputFormat</code> class or the <code class="codeph">RecordInfoProvider</code> class is not in the API, or in the hadoop API classes, then a jar with the user-defined classes must be provided. To be able to use this jar, you must add it in the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/WEB-INF/lib</code> directory and restart the server.
                                       </p>
                                    </div>
                                 </li>
                                 <li>
                                    <p>Whether the the enrichment service (<code class="codeph">MVSuggest</code>) must be used or not. If the geometry has to be found from a location string, then use the <code class="codeph">MVSuggest</code> service. In this case the provided <code class="codeph">RecordInfoProvider</code> must implement the interface <code class="codeph">oracle.spatial.hadoop.vector.LocalizableRecordInfoProvider</code>. 
                                    </p>
                                 </li>
                                 <li>
                                    <p>MVSuggest Templates (Optional): When using the <code class="codeph">MVSuggest</code> service, you can define the templates used to create the index. 
                                    </p>
                                 </li>
                              </ol>
                           </li>
                           <li>
                              <p>Click <span class="bold">Create</span>.
                              </p>
                              <p>A URL will be displayed to track the job. </p>
                           </li>
                        </ol>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-12F06102-D5AD-40E8-9153-10A67F81A792" name="GUID-12F06102-D5AD-40E8-9153-10A67F81A792"></a><h4 id="BDSPA-GUID-12F06102-D5AD-40E8-9153-10A67F81A792" class="sect4"><span class="enumeration_section">2.12.2 </span>Exploring the Hadoop Indexed Spatial Data
                  </h4>
                  <div>
                     <div class="section">
                        <p>To explore Hadoop indexed spatial data, follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code></p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Explore Data</span>.
                              </p>
                           </li>
                        </ol>
                        <p>For example, you can:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Select the desired indexed data and use the rectangle tool to display the data in the desired area.</p>
                           </li>
                           <li>
                              <p>Change the background map style.</p>
                           </li>
                           <li>
                              <p>Show data using a heat map.</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-5E181C06-29E6-4226-AF99-A17AF6C75E9F" name="GUID-5E181C06-29E6-4226-AF99-A17AF6C75E9F"></a><h4 id="BDSPA-GUID-5E181C06-29E6-4226-AF99-A17AF6C75E9F" class="sect4"><span class="enumeration_section">2.12.3 </span>Creating a Spark Spatial Index Using SpatialViewer
                  </h4>
                  <div>
                     <div class="section">
                        <p>To create a Spark spatial index using SpatialViewer, follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vectorspark</code></p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Spatial Index</span>.
                              </p>
                           </li>
                           <li>
                              <p>Specify all the required details:</p>
                              <ol type="a">
                                 <li>
                                    <p>Index name.</p>
                                 </li>
                                 <li>
                                    <p>Path of the file or files to index in HDFS. For example, <code class="codeph">/user/oracle/bdsg/tweets.json</code>.
                                    </p>
                                 </li>
                                 <li>
                                    <p>New index path: This is the job output path. For example: <code class="codeph">/user/oracle/bdsg/index</code>.
                                    </p>
                                 </li>
                                 <li>
                                    <p>SRID of the geometries to be indexed. Example: 8307</p>
                                 </li>
                                 <li>
                                    <p>Tolerance of the geometries to be indexed. Example: 0.05</p>
                                 </li>
                                 <li>
                                    <p>Input Format class (optional): The input format class. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat</code></p>
                                 </li>
                                 <li>
                                    <p>Key class (required if an input format class is defined): Class of the input format keys. For example: <code class="codeph">org.apache.hadoop.io.LongWritable</code></p>
                                 </li>
                                 <li>
                                    <p>Value class (required if an input format class is defined): Class of the input format values. For example: <code class="codeph">org.apache.hadoop.io.Text</code></p>
                                 </li>
                                 <li>
                                    <p>Record Info Provider class: The class that provides the spatial information. For example: <code class="codeph">oracle.spatial.spark.vector.recordinfoprovider.GeoJsonRecordInfoProvider</code></p>
                                    <div class="infoboxnote" id="GUID-5E181C06-29E6-4226-AF99-A17AF6C75E9F__GUID-446C3B02-1037-4545-9D9B-402EFC47895D">
                                       <p class="notep1">Note:</p>
                                       <p>If the <code class="codeph">InputFormat</code> class or the <code class="codeph">RecordInfoProvider</code> class  is not in the API, or in the hadoop API classes, then a jar with the user-defined classes must be provided. To be able to use this jar the user must add it in the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/WEB-INF/lib directory</code> and restart the server.
                                       </p>
                                    </div>
                                 </li>
                              </ol>
                           </li>
                           <li>
                              <p>Click <span class="bold">Create</span>.
                              </p>
                              <p>A URL will be displayed to track the job. </p>
                           </li>
                        </ol>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-9BBEA82F-5D48-4416-B1AC-EE02CE7BE30B" name="GUID-9BBEA82F-5D48-4416-B1AC-EE02CE7BE30B"></a><h4 id="BDSPA-GUID-9BBEA82F-5D48-4416-B1AC-EE02CE7BE30B" class="sect4"><span class="enumeration_section">2.12.4 </span>Exploring the Spark Indexed Spatial Data
                  </h4>
                  <div>
                     <div class="section">
                        <p>To explore Spark indexed spatial data, follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open the console:<code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vectorspark</code></p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Explore Data</span>.
                              </p>
                           </li>
                        </ol>
                        <p>For example, you can:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Select the desired indexed data and use the rectangle tool to display the data in the desired area.</p>
                           </li>
                           <li>
                              <p>Change the background map style.</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA175"></a><div class="props_rev_3"><a id="GUID-7DA2DDA9-F31B-4166-9136-CECD17B95703" name="GUID-7DA2DDA9-F31B-4166-9136-CECD17B95703"></a><h4 id="BDSPA-GUID-7DA2DDA9-F31B-4166-9136-CECD17B95703" class="sect4"><span class="enumeration_section">2.12.5 </span>Running a Categorization Job Using SpatialViewer
                  </h4>
                  <div>
                     <div class="section">
                        <p>You can run a categorization job with or without the spatial index. Follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.
                              </p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Categorization</span>, then <span class="bold">Categorization Job</span>.
                              </p>
                           </li>
                           <li>
                              <p>Select either With Index or Without Index and provide the following details, as required:</p>
                              <ul style="list-style-type: disc;">
                                 <li>
                                    <p>With Index</p>
                                    <ol type="a">
                                       <li>
                                          <p>Index name</p>
                                       </li>
                                    </ol>
                                 </li>
                                 <li>
                                    <p>Without Index</p>
                                    <ol type="a">
                                       <li>
                                          <p>Path of the data: Provide the HDFS data path. For example, <code class="codeph">/user/oracle/bdsg/tweets.json</code>.
                                          </p>
                                       </li>
                                       <li>
                                          <p>JAR with user classes (Optional): If the <code class="codeph">InputFormat</code> class or the <code class="codeph">RecordInfoProvider</code> class is not in the API, or in the hadoop API classes, then a jar with the user-defined classes must be provided. To be able to use this jar the user must add it in the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/WEB-INF/lib</code> directory and restart the server.
                                          </p>
                                       </li>
                                       <li>
                                          <p>Input Format class: The input format class. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat</code></p>
                                       </li>
                                       <li>
                                          <p>Record Info Provider class: The class that will provide the spatial information. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider</code>.
                                          </p>
                                       </li>
                                       <li>
                                          <p>Whether the enrichment service <code class="codeph">MVSuggest</code> service must be used or not. If the geometry must be found from a location string, then use the <code class="codeph">MVSuggest</code> service. In this case the provided <code class="codeph">RecordInfoProvider</code> has to implement the interface<code class="codeph"> oracle.spatial.hadoop.vector.LocalizableRecordInfoProvider</code>. 
                                          </p>
                                       </li>
                                       <li>
                                          <p>Templates: The templates to create the thematic maps.</p>
                                          <div class="infoboxnote" id="GUID-7DA2DDA9-F31B-4166-9136-CECD17B95703__GUID-D2FD3403-D10A-4CDD-9BBE-20B6082A76AE">
                                             <p class="notep1">Note:</p>
                                             <p>If a template refers to point geometries (for example, cities), the result returned is empty for that template, if <code class="codeph">MVSuggest</code> is not used. This is because the spatial operations return results only for polygons.
                                             </p>
                                          </div>
                                          <div class="infobox-tip" id="GUID-7DA2DDA9-F31B-4166-9136-CECD17B95703__GUID-C3FCD15D-BF77-4B24-86D4-E23027D92FAA">
                                             <p class="notep1">Tip:</p>
                                             <p>When using the <code class="codeph">MVSuggest</code> service the results will be more accurate if all the templates that could match the results are provided. For example, if the data can refer to any city, state, country, or continent in the world, then the better choice of templates to build results are World Continents, World Countries, World State Provinces, and World Cities. On the other hand, if the data is from the USA states and counties, then the suitable templates are USA States and USA Counties. If an index that was created using the <code class="codeph">MVSuggest</code> service is selected, then select the top hierarchy for an optimal result. For example, if it was created using World Countries, World State Provinces, and World Cities, then use World Countries as the template.
                                             </p>
                                          </div>
                                       </li>
                                       <li>
                                          <p>Output path: The Hadoop job output path. For example: <code class="codeph">/user/oracle/bdsg/catoutput</code></p>
                                       </li>
                                       <li>
                                          <p>Result name: The result name. If a result exists for a template with the same name, it is overwritten. For example, <code class="codeph">Tweets test</code>.
                                          </p>
                                       </li>
                                    </ol>
                                 </li>
                              </ul>
                           </li>
                        </ol>
                        <p>Click <span class="bold">Create</span>. A URL will be displayed to track the job.
                        </p>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA177"></a><div class="props_rev_3"><a id="GUID-4EFFC3BA-67C4-4260-9E86-96D04D37F57D" name="GUID-4EFFC3BA-67C4-4260-9E86-96D04D37F57D"></a><h4 id="BDSPA-GUID-4EFFC3BA-67C4-4260-9E86-96D04D37F57D" class="sect4"><span class="enumeration_section">2.12.6 </span>Viewing the Categorization Results
                  </h4>
                  <div>
                     <div class="section">
                        <p>To view the categorization results, follow these steps.</p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Categorization</span>, then <span class="bold">Results</span>.</span></li>
                        <li class="stepexpand"><span>Click any one of the Templates. For example, World Continents.</span><div>
                              <p>The World Continents template is displayed.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Click any one of the Results displayed.</span><div>
                              <p>Different continents appear with different patches of colors.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Click any continent from the map. For example, North America.</span><div>
                              <p>The template changes to World Countries and the focus changes to North America with the results by country.</p>
                           </div>
                        </li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA445"></a><div class="props_rev_3"><a id="GUID-0AF440D7-015F-4ECA-92BA-3EDDC7853F23" name="GUID-0AF440D7-015F-4ECA-92BA-3EDDC7853F23"></a><h4 id="BDSPA-GUID-0AF440D7-015F-4ECA-92BA-3EDDC7853F23" class="sect4"><span class="enumeration_section">2.12.7 </span>Saving Categorization Results to a File
                  </h4>
                  <div>
                     <div class="section">
                        <p>You can save categorization results to a file (for example, the result file created with a job executed from the command line) on the local system for possible future uploading and use. The templates are located in the folder <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/templates</code>. The templates are GeoJSON files with features and all the features have ids. For example, the first feature in the template <span class="italic">USA States</span> starts with: <code class="codeph">{"type":"Feature","_id":"WYOMING",</code>...
                        </p>
                        <p>The results must be JSON files with the following format: <code class="codeph">{"id":"JSONFeatureId","result":result}</code>. 
                        </p>
                        <p>For example, if the template <span class="italic">USA States</span> is selected, then a valid result is a file containing: <code class="codeph">{"id":"WYOMING","result":3232} {"id":"SOUTH DAKOTA","result":74968}</code></p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Click <span class="bold">Categorization</span>, then <span class="bold">Results</span>.</span></li>
                        <li class="stepexpand"><span>Select a <span>Template</span> .</span></li>
                        <li class="stepexpand"><span>Click the icon for saving the results.</span></li>
                        <li class="stepexpand"><span>Specify a <span>Name</span>.</span></li>
                        <li class="stepexpand"><span>Click <span>Choose File</span> to select the <span>File</span> location.</span></li>
                        <li class="stepexpand"><span>Click <span>Save</span>.</span><div>
                              <p>The results can be located in the folder <code class="codeph">clustering_results</code> contained in the SpatialViewer local working directory (see <a href="big-data-spatial-overview.html#GUID-045D5A34-6BC4-40BC-BBF0-4FE0B45ED903">Configuring SpatialViewer on Oracle Big Data Appliance</a>).
                              </p>
                           </div>
                        </li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA446"></a><div class="props_rev_3"><a id="GUID-C31C18E9-825A-478A-94E2-49BA29D2EBE6" name="GUID-C31C18E9-825A-478A-94E2-49BA29D2EBE6"></a><h4 id="BDSPA-GUID-C31C18E9-825A-478A-94E2-49BA29D2EBE6" class="sect4"><span class="enumeration_section">2.12.8 </span>Creating and Deleting Templates
                  </h4>
                  <div>
                     <div class="section">
                        <p>To create new templates do the following:</p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li><span>Add the template JSON file in the folder <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/templates/</code>.</span></li>
                        <li><span>Add the template configuration file in the folder <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/templates/_config_</code>.</span></li>
                     </ol>
                     <div class="section">
                        <p>To delete the template, delete the JSON and configuration files added in steps 1 and 2.</p>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA447"></a><div class="props_rev_3"><a id="GUID-A9947B46-0104-430F-89EE-F8A0D80CD9D8" name="GUID-A9947B46-0104-430F-89EE-F8A0D80CD9D8"></a><h4 id="BDSPA-GUID-A9947B46-0104-430F-89EE-F8A0D80CD9D8" class="sect4"><span class="enumeration_section">2.12.9 </span>Configuring Templates
                  </h4>
                  <div>
                     <p>Each template has a configuration file. The template configuration files are located in the folder <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/templates/_config_</code>. The name of the configuration file is the same as the template files suffixed with <code class="codeph">config.json</code> instead of <code class="codeph">.json</code>.For example, the configuration file name of the template file <code class="codeph">usa_states.json</code> is<code class="codeph"> usa_states.config.json</code>. The configuration parameters are:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>name: Name of the template to be shown on the console. For example, <code class="codeph">name: USA States</code>.
                           </p>
                        </li>
                        <li>
                           <p>display_attribute: When displaying a categorization result, a cursor move on the top of a feature displays this property and result of the feature. For example, <code class="codeph">display_attribute: STATE NAME</code>.
                           </p>
                        </li>
                        <li>
                           <p>point_geometry: True, if the template contains point geometries and false, in case of polygons. For example, <code class="codeph">point_geometry: false</code>.
                           </p>
                        </li>
                        <li>
                           <p>child_templates (optional): The templates that can have several possible child templates separated by a coma. For example, <code class="codeph">child_templates: ["world_states_provinces, usa_states(properties.COUNTRY CODE:properties.PARENT_REGION)"].</code></p>
                           <p>If the child templates do not specify a linked field, it means that all the features inside the parent features are considered as child features. In this case, the <code class="codeph">world_states_provinces</code> doesn't specify any fields. If the link between parent and child is specified, then the spatial relationship doesn't apply and the feature properties link are checked. In the above example, the relationship with the <code class="codeph">usa_states</code> is found with the property <code class="codeph">COUNTRY CODE</code> in the current template, and the property P<code class="codeph">ARENT_REGION</code> in the template file <code class="codeph">usa_states.json</code>. 
                           </p>
                        </li>
                        <li>
                           <p>srid: The SRID of the template's geometries. For example, <code class="codeph">srid: 8307</code>.
                           </p>
                        </li>
                        <li>
                           <p>back_polygon_template_file_name (optional): A template with polygon geometries to set as background when showing the defined template. For example, <code class="codeph">back_polygon_template_file_name: usa_states</code>.
                           </p>
                        </li>
                        <li>
                           <p>vectorLayers: Configuration specific to the <code class="codeph">MVSuggest</code> service. For example:
                           </p><pre class="oac_no_warn" dir="ltr">{
"vectorLayers": [
{
		"gnidColumns":["_GNID"],
		"boostValues":[2.0,1.0,1.0,2.0]
 	}
 	]
 }
</pre><p>Where:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>gnidColumns is the name of the column(s) within the Json file that represents the Geoname ID. This value is used to support multiple languages with <code class="codeph">MVSuggest</code>. (See references of that value in the file <code class="codeph">templates/_geonames_/alternateNames.json</code>.) There is nodefault value for this property.
                                 </p>
                              </li>
                              <li>
                                 <p>boostValues is an array of float numbers that represent how important a column is within the "properties" values for a given row. The higher the number, the more important that field is. A value of zero means the field will be ignored. When boostValues is not present, all fields receive a default value of 1.0, meaning they all are equally important properties. The <code class="codeph">MVSuggest</code> service may return different results depending on those values. For a Json file with the following properties, the boost values might be as follows:
                                 </p><pre class="oac_no_warn" dir="ltr">"properties":{"Name":"New York City","State":"NY","Country":"United States","Country Code":"US","Population":8491079,"Time Zone":"UTC-5"}
"boostValues":[3.0,2.0,1.0,1.0,0.0,0.0]
</pre></li>
                           </ul>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-07EC4895-9316-4128-AEB0-36847D82255E" name="GUID-07EC4895-9316-4128-AEB0-36847D82255E"></a><h4 id="BDSPA-GUID-07EC4895-9316-4128-AEB0-36847D82255E" class="sect4"><span class="enumeration_section">2.12.10 </span>Running a Clustering Job Using SpatialViewer
                  </h4>
                  <div>
                     <div class="section">
                        <p>To run a clustering job using SpatialViewer, follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code></p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Clustering</span>, then <span class="bold">Clustering Job</span>.
                              </p>
                           </li>
                           <li>
                              <p>Provide the following details, as required:</p>
                              <ol type="a">
                                 <li>
                                    <p>Path of the data: Provide the HDFS data path. For example, <code class="codeph">/user/oracle/bdsg/tweets.json</code>.
                                    </p>
                                 </li>
                                 <li>
                                    <p>The SRID of the geometries. For example: 8307</p>
                                 </li>
                                 <li>
                                    <p>The tolerance of the geometries. For example: 0.05</p>
                                 </li>
                                 <li>
                                    <p>JAR with user classes (Optional): If the <code class="codeph">InputFormat</code> class or the <code class="codeph">RecordInfoProvider</code> class is not in the API, or in the hadoop API classes, then a jar with the user-defined classes must be provided. To be able to use this jar the user must add it in the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/WEB-INF/lib</code> directory and restart the server.
                                    </p>
                                 </li>
                                 <li>
                                    <p>Input Format class: The input format class. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat</code></p>
                                 </li>
                                 <li>
                                    <p>Record Info Provider class: The class that will provide the spatial information. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider</code>.
                                    </p>
                                 </li>
                                 <li>
                                    <p>Number of clusters: The number of clusters to be found.</p>
                                 </li>
                                 <li>
                                    <p>Output path: The Hadoop job output path. For example: <code class="codeph">/user/oracle/bdsg/catoutput</code></p>
                                 </li>
                                 <li>
                                    <p>Result name: The result name. If a result exists for a template with the same name, it is overwritten. For example, Tweets test.</p>
                                 </li>
                              </ol>
                           </li>
                           <li>
                              <p>Click <span class="bold">Create</span>.
                              </p>
                              <p>A URL will be displayed to track the job.</p>
                           </li>
                        </ol>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-90864EE1-DF20-4D74-90E1-C7317DC66B4F" name="GUID-90864EE1-DF20-4D74-90E1-C7317DC66B4F"></a><h4 id="BDSPA-GUID-90864EE1-DF20-4D74-90E1-C7317DC66B4F" class="sect4"><span class="enumeration_section">2.12.11 </span>Viewing the Clustering Results
                  </h4>
                  <div>
                     <div class="section">
                        <p>To view the clustering results, follow these steps.</p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li><span>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.</span></li>
                        <li><span>Click <span class="bold">Clustering</span>, then <span class="bold">Results</span>.</span></li>
                        <li><span>Click any one of the Results displayed.</span></li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-99247061-D15C-41AC-9DBD-B8AB0B8BEED3" name="GUID-99247061-D15C-41AC-9DBD-B8AB0B8BEED3"></a><h4 id="BDSPA-GUID-99247061-D15C-41AC-9DBD-B8AB0B8BEED3" class="sect4"><span class="enumeration_section">2.12.12 </span>Saving Clustering Results to a File
                  </h4>
                  <div>
                     <div class="section">
                        <p>You can save clustering results to a file on your local system, for later uploading and use. To save the clustering results to a file, follow these steps.</p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li><span>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.</span></li>
                        <li><span>Click <span class="bold">Clustering</span>, then <span class="bold">Results</span>.</span></li>
                        <li><span>Click the icon for saving the results.</span></li>
                        <li><span>Specify a name.</span></li>
                        <li><span>Specify the SRID of the geometries. For example: 8307</span></li>
                        <li><span>Click <span class="bold">Choose File</span> and select the file location.</span></li>
                        <li><span>Click <span class="bold">Save</span>.</span></li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-95FDF8DF-7841-4A49-A20E-A293BC9F6753" name="GUID-95FDF8DF-7841-4A49-A20E-A293BC9F6753"></a><h4 id="BDSPA-GUID-95FDF8DF-7841-4A49-A20E-A293BC9F6753" class="sect4"><span class="enumeration_section">2.12.13 </span>Running a Binning Job Using SpatialViewer
                  </h4>
                  <div>
                     <div class="section">
                        <p>You can run a binning job with or without the spatial index. Follow these steps.</p>
                        <ol>
                           <li>
                              <p>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.
                              </p>
                           </li>
                           <li>
                              <p>Click <span class="bold">Binning</span>, then <span class="bold">Binning Job</span>.
                              </p>
                           </li>
                           <li>
                              <p>Select either With Index or Without Index and provide the following details, as required:</p>
                              <ul style="list-style-type: disc;">
                                 <li>
                                    <p>With Index</p>
                                    <ol type="a">
                                       <li>
                                          <p>Index name</p>
                                       </li>
                                    </ol>
                                 </li>
                                 <li>
                                    <p>Without Index</p>
                                    <ol type="a">
                                       <li>
                                          <p>Path of the data: Provide the HDFS data path. For example, <code class="codeph">/user/oracle/bdsg/tweets.json</code></p>
                                       </li>
                                       <li>
                                          <p>The SRID of the geometries. For example: 8307</p>
                                       </li>
                                       <li>
                                          <p>The tolerance of the geometries. For example: 0.05</p>
                                       </li>
                                       <li>
                                          <p>JAR with user classes (Optional): If the <code class="codeph">InputFormat</code> class or the <code class="codeph">RecordInfoProvider</code> class is not in the API, or in the hadoop API classes, then a jar with the user-defined classes must be provided. To be able to use this jar the user must add it in the <code class="codeph">/opt/oracle/oracle-spatial-graph/spatial/web-server/spatialviewer/WEB-INF/lib</code> directory and restart the server.
                                          </p>
                                       </li>
                                       <li>
                                          <p>Input Format class: The input format class. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat</code></p>
                                       </li>
                                       <li>
                                          <p>Record Info Provider class: The class that will provide the spatial information. For example: <code class="codeph">oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider</code>.
                                          </p>
                                       </li>
                                    </ol>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <p>Binning grid minimum bounding rectangle (MBR). You can click the icon for seeing the MBR on the map.</p>
                           </li>
                           <li>
                              <p>Binning shape: hexagon (specify the hexagon width) or rectangle (specify the width and height).</p>
                           </li>
                           <li>
                              <p>Thematic attribute: If the job uses an index, double-click to see the possible values, which are those returned by the function <code class="codeph">getExtraFields</code> of the <code class="codeph">RecordInfoProvider</code> used when creating the index. If the job does not use an index, then the field can be one of the fields returned by the function <code class="codeph">getExtraFields</code> of the specified <code class="codeph">RecordInfoProvider</code> class. In any case, the <code class="codeph">count</code> attribute is always available and specifies the number of records in the bin.
                              </p>
                           </li>
                           <li>
                              <p>Output path: The Hadoop job output path. For example: <code class="codeph">/user/oracle/bdsg/binningOutput</code></p>
                           </li>
                           <li>
                              <p>Result name: The result name. If a result exists for a template with the same name, it is overwritten. For example, Tweets test.</p>
                           </li>
                        </ol>
                        <p>Click <span class="bold">Create</span>. A URL will be displayed to track the job.
                        </p>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-2E69B928-CBB4-4EB4-B4CD-1E98C1E85914" name="GUID-2E69B928-CBB4-4EB4-B4CD-1E98C1E85914"></a><h4 id="BDSPA-GUID-2E69B928-CBB4-4EB4-B4CD-1E98C1E85914" class="sect4"><span class="enumeration_section">2.12.14 </span>Viewing the Binning Results
                  </h4>
                  <div>
                     <div class="section">
                        <p>To view the binning results, follow these steps.</p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li><span>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.</span></li>
                        <li><span>Click <span class="bold">Binning</span>, then <span class="bold">Results</span>.</span></li>
                        <li><span>Click any of the Results displayed.</span></li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-144C9A5A-5FCB-4391-80CF-9D80070BFB2E" name="GUID-144C9A5A-5FCB-4391-80CF-9D80070BFB2E"></a><h4 id="BDSPA-GUID-144C9A5A-5FCB-4391-80CF-9D80070BFB2E" class="sect4"><span class="enumeration_section">2.12.15 </span>Saving Binning Results to a File
                  </h4>
                  <div>
                     <div class="section">
                        <p>You can save binning results to a file on your local system, for later uploading and use. To save the binning results to a file, follow these steps.</p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li><span>Open <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045/spatialviewer/?root=vector</code>.</span></li>
                        <li><span>Click <span class="bold">Binning</span>, then <span class="bold">View Results</span>.</span></li>
                        <li><span>Click the icon for saving the results.</span></li>
                        <li><span>Specify the SRID of the geometries. For example: 8307</span></li>
                        <li><span>Specify the thematic attribute, which must be a property of the features in the result. For example, the count attribute can be used to create results depending on the number of results per bin.</span></li>
                        <li><span>Click <span class="bold">Choose File</span> and select the file location.</span></li>
                        <li><span>Click <span class="bold">Save</span>.</span></li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA176"></a><div class="props_rev_3"><a id="GUID-ECC8BE1E-7519-44B0-BEA1-A70833A8F213" name="GUID-ECC8BE1E-7519-44B0-BEA1-A70833A8F213"></a><h4 id="BDSPA-GUID-ECC8BE1E-7519-44B0-BEA1-A70833A8F213" class="sect4"><span class="enumeration_section">2.12.16 </span>Running a Job to Create an Index Using the Command Line
                  </h4>
                  <div>
                     <p>To create a spatial index, use a command in the following format:</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH&gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SpatialIndexing [generic options] input=&lt;path|comma_separated_paths|path_pattern&gt; output=&lt;path&gt; inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt; [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;minX,minY,maxX,maxY&gt;] [indexName=&lt;index_name&gt;] [indexMetadataDir=&lt;path&gt;] [overwriteIndexMetadata=&lt;true|false&gt;] [  mvsLocation=&lt;path|URL&gt; [mvsMatchLayers=&lt;comma_separated_layers&gt;][mvsMatchCountry=&lt;country_name&gt;][mvsSpatialResponse=&lt;[NONE, FEATURE_GEOMETRY, FEATURE_CENTROID]&gt;][mvsInterfaceType=&lt;LOCAL, WEB&gt;][mvsIsRepository=&lt;true|false&gt;][rebuildMVSIndex=&lt;true|false&gt;][mvsPersistentLocation=&lt;hdfs_path&gt;][mvsOverwritePersistentLocation=&lt;true|false&gt;] ]</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.SpatialIndexing</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.SpatialIndexing</code>.
                     </p>
                     <p>Input/output arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">output</code>: the path where the spatial index will be stored
                           </p>
                        </li>
                     </ul>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">boundaries</code> (optional, default=unbounded): the minimum and maximum values for each dimension, expressed as comma separated values in the form: minX,minY,maxX,maxY
                           </p>
                        </li>
                     </ul>
                     <p>Spatial index metadata arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">indexName</code> (optional, default=output folder name):The name of the index to be generated.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">indexMetadataDir</code> (optional, default=hdfs://server:port/user/&lt;current_user&gt;/oracle_spatial/index_metadata/): the directory where the spatial index metadata will be stored.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">overwriteIndexMetadata</code> (optional, default=false) boolean argument that indicates whether the index metadata can be overwritten if an index with the same name already exists. 
                           </p>
                        </li>
                     </ul>
                     <p><code class="codeph">MVSuggest</code> arguments:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">mvsLocation</code>: The path to the MVSuggest directory or repository for local standalone instances of MVSuggest or the service URL when working with a remote instance. This argument is required when working with MVSuggest.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsMatchLayers</code> (optional, default=all): comma separated list of layers. When provided, MVSuggest will only use these layers to perform the search. 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsMatchCountry</code> (optional, default=none): a country name which MVSuggest will give higher priority when performing matches.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsSpatialResponse</code> (optional, default=CENTROID): the type of the spatial results contained in each returned match. It can be one of the following values: NONE, FEATURE_GEOMETRY, FEATURE_CENTROID.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsInterfaceType</code> (optional: default=LOCAL): the type of MVSuggest service used, it can be LOCAL or WEB.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsIsRepository</code> (optional: default=false) (LOCAL only): boolean value which specifies whether mvsLocation points to a whole MVS directory(false) or only to a repository(true). An MVS repository contains only JSON templates; it may or not contain a _config_ and _geonames_ folder.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsRebuildIndex</code> (optional, default=false)(LOCAL only):boolean value specifying whether the repository index should be rebuilt or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsPersistentLocation</code> (optional, default=none)(LOCAL only): an HDFS path where the MVSuggest directory will be saved.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsIsOverwritePersistentLocation</code> (optional, default=false): boolean argument that indicates whether an existing mvsPersistentLocation must be overwritten in case it already exists. 
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Create a spatial index called <code class="codeph">indexExample</code>. The index metadata will be stored in the HDFS directory <code class="codeph">spatialMetadata</code>.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SpatialIndexing input="/user/hdfs/demo_vector/tweets/part*" output=/user/hdfs/demo_vector/tweets/spatial_index inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider srid=8307 geodetic=true tolerance=0.5 indexName=indexExample indexMetadataDir=indexMetadataDir overwriteIndexMetadata=true</code></pre><p><span class="bold">Example</span>: Create a spatial index using <code class="codeph">MVSuggest</code> to assign a spatial location to records that do not contain geometries.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SpatialIndexing input="/user/hdfs/demo_vector/tweets/part*" output=/user/hdfs/demo_vector/tweets/spatial_index inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=mypackage.Simple LocationRecordInfoProvider srid=8307 geodetic=true tolerance=0.5 indexName=indexExample indexMetadataDir=indexMetadataDir overwriteIndexMetadata=true mvsLocation=file:///local_folder/mvs_dir/oraclemaps_pub/ mvsRepository=true</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-C6FF86B5-B29B-4594-82F6-9469E82064C5" name="GUID-C6FF86B5-B29B-4594-82F6-9469E82064C5"></a><h4 id="BDSPA-GUID-C6FF86B5-B29B-4594-82F6-9469E82064C5" class="sect4"><span class="enumeration_section">2.12.17 </span>Running a Job to Create a Categorization Result
                  </h4>
                  <div>
                     <p>To create a categorization result, use a command in one of the following formats.</p>
                     <p><span class="bold">With a Spatial Index</span></p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Categorization [generic options] <span class="bold">( indexName=&lt;indexName&gt; [indexMetadataDir=&lt;path&gt;] )</span>  | ( input=&lt;path|comma_separated_paths|path_pattern&gt; isInputIndex=true [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  ) output=&lt;path&gt; hierarchyIndex=&lt;hdfs_hierarchy_index_path&gt; hierarchyInfo=&lt;HierarchyInfo_subclass&gt; [hierarchyDataPaths=&lt;level1_path,level2_path,,levelN_path&gt;] spatialOperation=&lt;[None, IsInside, AnyInteract]&gt;</pre><p><span class="bold">Without a Spatial Index</span></p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Categorization [generic options] input=&lt;path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt; [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  output=&lt;path&gt; hierarchyIndex=&lt;hdfs_hierarchy_index_path&gt; hierarchyInfo=&lt;HierarchyInfo_subclass&gt;  hierarchyDataPaths=&lt;level1_path,level2_path,,levelN_path&gt;] spatialOperation=&lt;[None, IsInside, AnyInteract]&gt;</pre><p><span class="bold">Using MVSuggest</span></p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Categorization [generic options] (indexName=&lt;indexName&gt; [indexMetadataDir=&lt;path&gt;])  | 
( 
(input=&lt;path|comma_separated_paths|path_pattern&gt; isInputIndex=true)  | (input=&lt;path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;LocalizableRecordInfoProvider_subclass&gt;)
[srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  
) output=&lt;path&gt; 
mvsLocation=&lt;path|URL&gt; [mvsMatchLayers=&lt;comma_separated_layers&gt;] [mvsMatchCountry=&lt;country_name&gt;] [mvsSpatialResponse=&lt;[NONE, FEATURE_GEOMETRY, FEATURE_CENTROID]&gt;] [mvsInterfaceType=&lt;[UNDEFINED, LOCAL, WEB]&gt;] [mvsIsRepository=&lt;true|false&gt;] [mvsRebuildIndex=&lt;true|false&gt;] [mvsPersistentLocation=&lt;hdfs_path&gt;] [mvsOverwritePersistentLocation=&lt;true|false&gt;] [mvsMaxRequestRecords=&lt;integer_number&gt;]  hierarchyIndex=&lt;hdfs_hierarchy_index_path&gt; hierarchyInfo=&lt;HierarchyInfo_subclass&gt;
</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.Categorization</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.Categorization</code>.
                     </p>
                     <p>Input/output arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">indexName</code>: the name of an existing spatial index. The index information will be looked at the path given by indexMetadataDir. When used, the argument <code class="codeph">input</code> is ignored.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">indexMetadataDir</code> (optional, default=hdfs://server:port/user/&lt;current_user&gt;/oracle_spatial/index_metadata/): the directory where the spatial index metadata is located 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">output</code>: the path where the spatial index will be stored
                           </p>
                        </li>
                     </ul>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">boundaries</code> (optional, default=unbounded): the minimum and maximum values for each dimension, expressed as comma separated values in the form: minX,minY,maxX,maxY
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">spatialOperation</code>: the spatial operation to perform between the input data set and the hierarchical data set. Allowed values are <code class="codeph">IsInside</code> and <code class="codeph">AnyInteract</code>.
                           </p>
                        </li>
                     </ul>
                     <p>Hierarchical data set arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">hierarchyIndex</code>: the HDFS path of an existing hierarchical index or where it can be stored if it needs to be generated.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">hierarchyInfo</code>: the fully qualified name of a <code class="codeph">HierarchyInfo</code> subclass which is used to describe the hierarchical data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">hierarchyDataPaths</code> (optional, default=none): a comma separated list of paths of the hierarchy data. The paths should be sorted in ascending way by hierarchy level. If a hierarchy index path does not exist for the given hierarchy data, this argument is required.
                           </p>
                        </li>
                     </ul>
                     <p><code class="codeph">MVSuggest</code> arguments:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">mvsLocation</code>: The path to the MVSuggest directory or repository for local standalone instances of MVSuggest or the service URL when working with a remote instance. This argument is required when working with MVSuggest.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsMatchLayers</code> (optional, default=all): comma separated list of layers. When provided, MVSuggest will only use these layers to perform the search. 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsMatchCountry</code> (optional, default=none): a country name which MVSuggest will give higher priority when performing matches.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsSpatialResponse</code> (optional, default=CENTROID): the type of the spatial results contained in each returned match. It can be one of the following values: NONE, FEATURE_GEOMETRY, FEATURE_CENTROID.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsInterfaceType</code> (optional: default=LOCAL): the type of MVSuggest service used, it can be LOCAL or WEB.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsIsRepository</code> (optional: default=false) (LOCAL only): Boolean value that specifies whether <code class="codeph">mvsLocation</code> points to a whole MVS directory(false) or only to a repository(true). An MVS repository contains only JSON templates; it may or not contain a <code class="codeph">_config_</code> and <code class="codeph">_geonames_</code> folder.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsRebuildIndex</code> (optional, default=false)(LOCAL only):boolean value specifying whether the repository index should be rebuilt or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsPersistentLocation</code> (optional, default=none)(LOCAL only): an HDFS path where the MVSuggest directory will be saved.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsIsOverwritePersistentLocation</code> (optional, default=false): boolean argument that indicates whether an existing <code class="codeph">mvsPersistentLocation</code> must be overwritten in case it already exists. 
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Run a Categorization job to create a summary containing the records counts by continent, country, and state/provinces. The input is an existing spatial index called <code class="codeph">indexExample</code>. The hierarchical data will be indexed and stored in HDFS at the path <code class="codeph">hierarchyIndex</code>.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Categorization indexName= indexExample  output=/user/hdfs/demo_vector/tweets/hier_count_spatial hierarchyInfo=vectoranalysis.categorization.WorldAdminHierarchyInfo hierarchyIndex=hierarchyIndex  hierarchyDataPaths=file:///templates/world_continents.json,file:///templates/world_countries.json,file:///templates/world_states_provinces.json spatialOperation=IsInside</code></pre><p><span class="bold">Example</span>: Run a Categorization job to create a summary of tweet counts per continent, country, states/provinces, and cities using <code class="codeph">MVSuggest</code>.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Categorization input="/user/hdfs/demo_vector/tweets/part*" inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;LocalizableRecordInfoProvider_subclass&gt;  output=/user/hdfs/demo_vector/tweets/hier_count_mvs hierarchyInfo=vectoranalysis.categorization.WorldAdminHierarchyInfo hierarchyIndex=hierarchyIndex mvsLocation=file:///mvs_dir mvsMatchLayers=world_continents,world_countries,world_states_provinces spatialOperation=IsInside</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-8AD2EAD2-4593-4C62-88F6-5B040346956F" name="GUID-8AD2EAD2-4593-4C62-88F6-5B040346956F"></a><h4 id="BDSPA-GUID-8AD2EAD2-4593-4C62-88F6-5B040346956F" class="sect4"><span class="enumeration_section">2.12.18 </span>Running a Job to Create a Clustering Result
                  </h4>
                  <div>
                     <p>To create a clustering result, use a command in the following format:</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.KMeansClustering [generic options] input=&lt;path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt; output=&lt;path&gt; [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  k=&lt;number_of_clusters&gt; [clustersPoints=&lt;comma_separated_points_ordinates&gt;] [deleteClusterFiles=&lt;true|false&gt;] [maxIterations=&lt;integer_value&gt;] [critFunClass=&lt;CriterionFunction_subclass&gt;] [shapeGenClass=&lt;ClusterShapeGenerator_subclass&gt;] [maxMemberDistance=&lt;double_value&gt;]</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.KMeansClustering</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.KMeansClustering</code>.
                     </p>
                     <p>Input/output arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">output</code>: the path where the spatial index will be stored
                           </p>
                        </li>
                     </ul>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): Boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">boundaries</code> (optional, default=unbounded): the minimum and maximum values for each dimension, expressed as comma separated values in the form: minX,minY,maxX,maxY
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">spatialOperation</code>: the spatial operation to perform between the input data set and the hierarchical data set. Allowed values are <code class="codeph">IsInside</code> and <code class="codeph">AnyInteract</code>.
                           </p>
                        </li>
                     </ul>
                     <p>Clustering arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">k</code>: the number of clusters to be found.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">clusterPoints</code> (optional, default=none): the initial cluster centers as a comma-separated list of point ordinates in the form: p1_x,p1_y,p2_x,p2_y,…,pk_x,pk_y
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">deleteClusterFiles</code> (optional, default=true): Boolean arguments that specifies whether the intermediate cluster files generated between iterations should be deleted or not
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">maxIterations</code> (optional, default=calculated based on the number k): the maximum number of iterations allowed before the job completes. 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">critFunClass</code> (optional, default=oracle.spatial.hadoop.vector.cluster.kmeans. SquaredErrorCriterionFunction) a fully qualified name of a <code class="codeph">CriterionFunction</code> subclass.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">shapeGenClass</code> (optional, default= oracle.spatial.hadoop.vector.cluster.kmeans. ConvexHullClusterShapeGenerator) a fully qualified name of a <code class="codeph">ClusterShapeGenerator</code>  subclass used to generate the geometry of the clusters.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">maxMemberDistance</code> (optional, default=undefined): a double value that specifies the maximum distance between a cluster center and a cluster member.
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Run a Clustering job to generate 5 clusters. The generated clusters geometries will be the convex hull of all .
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.KMeansClustering input="/user/hdfs/demo_vector/tweets/part*" output=/user/hdfs/demo_vector/tweets/result inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider srid=8307 geodetic=true tolerance=0.5 k=5 shapeGenClass=oracle.spatial.hadoop.vector.cluster.kmeans.ConvexHullClusterShapeGenerator</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-A50010C2-47B9-49FA-A421-84A9486F51F6" name="GUID-A50010C2-47B9-49FA-A421-84A9486F51F6"></a><h4 id="BDSPA-GUID-A50010C2-47B9-49FA-A421-84A9486F51F6" class="sect4"><span class="enumeration_section">2.12.19 </span>Running a Job to Create a Binning Result
                  </h4>
                  <div>
                     <p>To create a binning result, use a command in the following format:</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Binning [generic options] (indexName=&lt;INDEX_NAME&gt; [indexMetadataDir=&lt;INDEX_METADATA_DIRECTORY&gt;]) | (input=&lt;DATA_PATH&gt; inputFormat=&lt;INPUT_FORMAT_CLASS&gt; recordInfoProvider=&lt;RECORD_INFO_PROVIDER_CLASS&gt; [srid=&lt;SRID&gt;] [geodetic=&lt;GEODETIC&gt;] [tolerance=&lt;TOLERANCE&gt;]) output=&lt;RESULT_PATH&gt; cellSize=&lt;CELL_SIZE&gt; gridMbr=&lt;GRID_MBR&gt; [cellShape=&lt;CELL_SHAPE&gt;] [aggrFields=&lt;EXTRA_FIELDS&gt;]</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.Binning</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.Binning</code>.
                     </p>
                     <p>Input/output arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">indexName</code>: the name of an existing spatial index. The index information will be looked at the path given by indexMetadataDir. When used, the argument <code class="codeph">input</code> is ignored.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">indexMetadataDir</code> (optional, default=hdfs://server:port/user/&lt;current_user&gt;/oracle_spatial/index_metadata/): the directory where the spatial index metadata is located 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">output</code>: the path where the spatial index will be stored
                           </p>
                        </li>
                     </ul>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): Boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                     </ul>
                     <p>Binning arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">cellSize</code>: the size of the cells in the format: width,height
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">gridMbr</code> : the minimum and maximum dimension values for the grid in the form: minX,minY,maxX,maxY 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">cellShape</code> (optional, default=RECTANGLE): the shape of the cells. It can be RECTANGLE or HEXAGON
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">aggrFields</code> (optional, default=none): a comma-separated list of field names that will be aggregated.
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Run a spatial binning job to generate a grid of hexagonal cells and aggregate the value of the field SALES..
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Binning indexName=indexExample indexMetadataDir=indexMetadataDir output=/user/hdfs/demo_vector/result cellShape=HEXAGON cellSize=5 gridMbr=-175,-85,175,85 aggrFields=SALES</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="BDSPA448"></a><div class="props_rev_3"><a id="GUID-7ACFE882-F09D-4751-B2DE-70DC865A183C" name="GUID-7ACFE882-F09D-4751-B2DE-70DC865A183C"></a><h4 id="BDSPA-GUID-7ACFE882-F09D-4751-B2DE-70DC865A183C" class="sect4"><span class="enumeration_section">2.12.20 </span>Running a Job to Perform Spatial Filtering
                  </h4>
                  <div>
                     <p>To perform spatial filtering, use a command in the following format:</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SpatialFilter [generic options] ( indexName=&lt;indexName&gt; [indexMetadataDir=&lt;path&gt;] )  | 
( 
(input=&lt;path|comma_separated_paths|path_pattern&gt; isInputIndex=true)  | (input=&lt;path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt;)
[srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]
) output=&lt;path&gt;  spatialOperation=&lt;[IsInside, AnyInteract]&gt; queryWindow=&lt;json-geometry&gt;
</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.SpatialFilter</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.SpatialFilter</code>.
                     </p>
                     <p>Input/output arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">indexName</code>: the name of an existing spatial index. The index information will be looked at the path given by indexMetadataDir. When used, the argument <code class="codeph">input</code> is ignored.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">indexMetadataDir</code> (optional, default=hdfs://server:port/user/&lt;current_user&gt;/oracle_spatial/index_metadata/): the directory where the spatial index metadata is located 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">output</code>: the path where the spatial index will be stored
                           </p>
                        </li>
                     </ul>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): Boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                     </ul>
                     <p>Binning arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">cellSize</code>: the size of the cells in the format: width,height
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">gridMbr</code> : the minimum and maximum dimension values for the grid in the form: minX,minY,maxX,maxY 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">cellShape</code> (optional, default=RECTANGLE): the shape of the cells. It can be RECTANGLE or HEXAGON
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">aggrFields</code> (optional, default=none): a comma-separated list of field names that will be aggregated.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">boundaries</code> (optional, default=unbounded): the minimum and maximum values for each dimension, expressed as comma separated values in the form: minx,minY,maxX,maxY
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">spatialOperation</code>: the operation to be applied between the queryWindow and the geometries from the input data set
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">queryWindow</code>: the geometry used to filter the input dataset.
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Perform a spatial filtering operation.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SpatialFilter indexName=indexExample indexMetadataDir=indexMetadataDir output=/user/hdfs/demo_vector/result spatialOperation=IsInside queryWindow='{"type":"Polygon", "coordinates":[[-106, 25, -106, 30, -104, 30, -104, 25, -106, 25]]}'</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-D3914D3E-A3EF-44DA-8CFC-08915C1F24DF" name="GUID-D3914D3E-A3EF-44DA-8CFC-08915C1F24DF"></a><h4 id="BDSPA-GUID-D3914D3E-A3EF-44DA-8CFC-08915C1F24DF" class="sect4"><span class="enumeration_section">2.12.21 </span>Running a Job to Get Location Suggestions
                  </h4>
                  <div>
                     <p>To create a job to get location suggestions, use a command in the following format.</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SuggestService [generic options] input=&lt;path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt; output=&lt;path&gt; mvsLocation=&lt;path|URL&gt; [mvsMatchLayers=&lt;comma_separated_layers&gt;] [mvsMatchCountry=&lt;country_name&gt;] [mvsSpatialResponse=&lt;[NONE, FEATURE_GEOMETRY, FEATURE_CENTROID]&gt;] [mvsInterfaceType=&lt;[UNDEFINED, LOCAL, WEB]&gt;] [mvsIsRepository=&lt;true|false&gt;] [mvsRebuildIndex=&lt;true|false&gt;] [mvsPersistentLocation=&lt;hdfs_path&gt;] [mvsOverwritePersistentLocation=&lt;true|false&gt;] [mvsMaxRequestRecords=&lt;integer_number&gt;]</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.SuggestService</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.SuggestService</code>.
                     </p>
                     <p>Input/output arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">output</code>: the path where the spatial index will be stored
                           </p>
                        </li>
                     </ul>
                     <p><code class="codeph">MVSuggest</code> arguments:
                     </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">mvsLocation</code>: The path to the MVSuggest directory or repository for local standalone instances of MVSuggest or the service URL when working with a remote instance. This argument is required when working with MVSuggest.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsMatchLayers</code> (optional, default=all): comma separated list of layers. When provided, MVSuggest will only use these layers to perform the search. 
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsMatchCountry</code> (optional, default=none): a country name which MVSuggest will give higher priority when performing matches.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsSpatialResponse</code> (optional, default=CENTROID): the type of the spatial results contained in each returned match. It can be one of the following values: NONE, FEATURE_GEOMETRY, FEATURE_CENTROID.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsInterfaceType</code> (optional: default=LOCAL): the type of MVSuggest service used, it can be LOCAL or WEB.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsIsRepository</code> (optional: default=false) (LOCAL only): Boolean value that specifies whether <code class="codeph">mvsLocation</code> points to a whole MVS directory(false) or only to a repository(true). An MVS repository contains only JSON templates; it may or not contain a <code class="codeph">_config_</code> and <code class="codeph">_geonames_</code> folder.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsRebuildIndex</code> (optional, default=false)(LOCAL only):boolean value specifying whether the repository index should be rebuilt or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsPersistentLocation</code> (optional, default=none)(LOCAL only): an HDFS path where the MVSuggest directory will be saved.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">mvsIsOverwritePersistentLocation</code> (optional, default=false): boolean argument that indicates whether an existing <code class="codeph">mvsPersistentLocation</code> must be overwritten in case it already exists. 
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Get suggestions based on location texts from the input data set..
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SuggestService input="/user/hdfs/demo_vector/tweets/part*" inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;LocalizableRecordInfoProvider_subclass&gt; output=/user/hdfs/demo_vector/tweets/suggest_res mvsLocation=file:///mvs_dir mvsMatchLayers=world_continents,world_countries,world_states_provinces</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-AB021393-03B6-48F8-98D2-45878F568CAF" name="GUID-AB021393-03B6-48F8-98D2-45878F568CAF"></a><h4 id="BDSPA-GUID-AB021393-03B6-48F8-98D2-45878F568CAF" class="sect4"><span class="enumeration_section">2.12.22 </span>Running a Job to Perform a Spatial Join
                  </h4>
                  <div>
                     <p>To perform a spatial join operation on two data sets, use a command in the following format.</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job. SpatialJoin [generic options] 
inputList={ 
 { 
  ( indexName=&lt;dataset1_spatial_index_name&gt;  indexMetadataDir=&lt;dataset1_spatial_index_metadata_dir_path&gt; ) 
  |  
  ( input=&lt;dataset1_path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;dataset1_InputFormat_subclass&gt; recordInfoProvider=&lt;dataset1_RecordInfoProvider_subclass&gt; )  
  [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  
 }  
 { 
  (indexName=&lt;dataset2_spatial_index_name&gt; indexMetadataDir=&lt;dataset2_spatial_index_metadata_dir_path&gt; 
  ) 
  |  
  ( input=&lt;dataset2_path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;dataset2_InputFormat_subclass&gt; recordInfoProvider=&lt;dataset2_RecordInfoProvider_subclass&gt; 
  )  
  [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  
 } 
} output=&lt;path&gt;[srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] boundaries=&lt;min_x,min_y,max_x,max_y&gt; spatialOperation=&lt;AnyInteract|IsInside|WithinDistance&gt; [distance=&lt;double_value&gt;] [samplingRatio=&lt;decimal_value_between_0_and_1&gt; | partitioningResult=&lt;path&gt;]
</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.SpatialJoin</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.SpatialJoin</code>.
                     </p>
                     <p><code class="codeph">InputList</code>: A list of two input data sets. The list is enclosed by curly braces ({}). Each list element is an input data set, which is enclosed by curly braces. An input data set can contain the following information, depending on whether the data set is specified as a spatial index.
                     </p>
                     <p>If specified as a spatial index:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">indexName</code>: the name of an existing spatial index.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">indexMetadataDir</code> : the directory where the spatial index metadata is located 
                           </p>
                        </li>
                     </ul>
                     <p>If not specified as a spatial index:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                     </ul>
                     <p><code class="codeph">output</code>: the path where the results will be stored
                     </p>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">boundaries</code> (optional, default=unbounded): the minimum and maximum values for each dimension, expressed as comma separated values in the form: minX,minY,maxX,maxY
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">spatialOperation</code>: the spatial operation to perform between the input data set and the hierarchical data set. Allowed values are <code class="codeph">IsInside</code> and <code class="codeph">AnyInteract</code>.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">distance</code>: distance used for <code class="codeph">WithinDistance</code> operations.
                           </p>
                        </li>
                     </ul>
                     <p>Partitioning arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">samplingRatio</code> (optional, default=0.1): ratio used to sample the data sets when partitioning needs to be performed
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">partitioningResult</code> (optional, default=none): Path to a previously generated partitioning result file
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Perform a spatial join on two data sets.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.SpatialJoin inputList="{{input=/user/hdfs/demo_vector/world_countries.json inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider} {input=file="/user/hdfs/demo_vector/tweets/part*” inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider}}" output=/user/hdfs/demo_vector/spatial_join srid=8307 spatialOperation=AnyInteract boundaries=-180,-90,180,90</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-A72097FA-D4DE-43D2-9C67-3791195D79E9" name="GUID-A72097FA-D4DE-43D2-9C67-3791195D79E9"></a><h4 id="BDSPA-GUID-A72097FA-D4DE-43D2-9C67-3791195D79E9" class="sect4"><span class="enumeration_section">2.12.23 </span>Running a Job to Perform Partitioning
                  </h4>
                  <div>
                     <p>To perform a spatial partitioning, use a command in the following format.</p><pre class="oac_no_warn" dir="ltr">hadoop jar &lt;HADOOP_LIB_PATH &gt;/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job. SpatialJoin [generic options] 
inputList={ 
 { 
  ( indexName=&lt;dataset1_spatial_index_name&gt;  indexMetadataDir=&lt;dataset1_spatial_index_metadata_dir_path&gt; ) 
  |  
  ( input=&lt;dataset1_path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;dataset1_InputFormat_subclass&gt; recordInfoProvider=&lt;dataset1_RecordInfoProvider_subclass&gt; )  
  [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  
 }
[  
 { 
  (indexName=&lt;dataset2_spatial_index_name&gt; indexMetadataDir=&lt;dataset2_spatial_index_metadata_dir_path&gt; 
  ) 
  |  
  ( input=&lt;dataset2_path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;dataset2_InputFormat_subclass&gt; recordInfoProvider=&lt;dataset2_RecordInfoProvider_subclass&gt; 
  )  
  [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  
 }
  ……
 { 
  (indexName=&lt;datasetN_spatial_index_name&gt; indexMetadataDir=&lt;datasetN_spatial_index_metadata_dir_path&gt; 
  ) 
  |  
  ( input=&lt;datasetN_path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;datasetN_InputFormat_subclass&gt; recordInfoProvider=&lt;datasetN_RecordInfoProvider_subclass&gt; 
  )  
  [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]  
 }
 
}
] output=&lt;path&gt;[srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] boundaries=&lt;min_x,min_y,max_x,max_y&gt; [samplingRatio=&lt;decimal_value_between_0_and_1&gt;]
</pre><p>To use the new Hadoop API format, replace <code class="codeph">oracle.spatial.hadoop.vector.<span class="codeinlineitalic">mapred</span>.job.Partitioning</code> with <code class="codeph">oracle.spatial.hadoop.vector.<span class="bold">mapreduce</span>.job.Partitioning</code>.
                     </p>
                     <p><code class="codeph">InputList</code>: A list of two input data sets. The list is enclosed by curly braces ({}). Each list element is an input data set, which is enclosed by curly braces. An input data set can contain the following information, depending on whether the data set is specified as a spatial index.
                     </p>
                     <p>If specified as a spatial index:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">indexName</code>: the name of an existing spatial index.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">indexMetadataDir</code> : the directory where the spatial index metadata is located 
                           </p>
                        </li>
                     </ul>
                     <p>If not specified as a spatial index:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">input</code> : the location of the input data. It can be expressed as a path, a comma separated list of paths, or a regular expression. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">inputFormat</code>: the <code class="codeph">inputFormat</code> class implementation used to read the input data. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">recordInfoProvider</code>: the <code class="codeph">recordInfoProvider</code> implementation used to extract information from the records read by the <code class="codeph">InputFormat</code> class. (Ignored if <code class="codeph">indexName</code> is specified.)
                           </p>
                        </li>
                     </ul>
                     <p><code class="codeph">output</code>: the path where the results will be stored
                     </p>
                     <p>Spatial arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">srid</code> (optional, default=0): the spatial reference system (coordinate system) ID of the spatial data.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">geodetic</code> (optional, default depends on the srid): boolean value that indicates whether the geometries are geodetic or not.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">tolerance</code> (optional, default=0.0): double value that represents the tolerance used when performing spatial operations.
                           </p>
                        </li>
                        <li>
                           <p><code class="codeph">boundaries</code> (optional, default=unbounded): the minimum and maximum values for each dimension, expressed as comma separated values in the form: minX,minY,maxX,maxY
                           </p>
                        </li>
                     </ul>
                     <p>Partitioning arguments:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><code class="codeph">samplingRatio</code> (optional, default=0.1): ratio used to sample the data sets when partitioning needs to be performed
                           </p>
                        </li>
                     </ul>
                     <p><span class="bold">Example</span>: Partition two data sets.
                     </p><pre class="pre codeblock"><code>hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop/lib/sdohadoop-vector.jar oracle.spatial.hadoop.vector.mapred.job.Partitioning inputList="{{input=/user/hdfs/demo_vector/world_countries.json inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider} {input=file="/user/hdfs/demo_vector/tweets/part*” inputFormat=oracle.spatial.hadoop.vector.geojson.mapred.GeoJsonInputFormat recordInfoProvider=oracle.spatial.hadoop.vector.geojson.GeoJsonRecordInfoProvider}}" output=/user/hdfs/demo_vector/partitioning srid=8307 boundaries=-180,-90,180,90</code></pre></div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-39A85E2C-7F5C-47F0-8CC5-11D355A9DC66" name="GUID-39A85E2C-7F5C-47F0-8CC5-11D355A9DC66"></a><h4 id="BDSPA-GUID-39A85E2C-7F5C-47F0-8CC5-11D355A9DC66" class="sect4"><span class="enumeration_section">2.12.24 </span>Using Multiple Inputs
                  </h4>
                  <div>
                     <p>Multiple input data sets can be specified to a Vector job through the command line interface using the <code class="codeph">inputList</code> parameter. The <code class="codeph">inputList</code> parameter value is a group of input data sets. The <code class="codeph">inputList</code> parameter format is as follows:
                     </p><pre class="oac_no_warn" dir="ltr">inputList={ {input_data_set_1_params} {input_data_set_2_params} … {input_data_set_N_params} }</pre><p>Each individual input data set can be one of the following input data sets:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Non-file input data set: <code class="codeph">inputFormat=&lt;InputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt; [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]</code></p>
                        </li>
                        <li>
                           <p>File input data set: <code class="codeph">input=&lt;path|comma_separated_paths|path_pattern&gt; inputFormat=&lt;FileInputFormat_subclass&gt; recordInfoProvider=&lt;RecordInfoProvider_subclass&gt; [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]</code></p>
                        </li>
                        <li>
                           <p>Spatial index input data set: <code class="codeph">( ( indexName=&lt;&lt;indexName&gt;&gt; [indexMetadataDir=&lt;&lt;path&gt;&gt;])  |  ( isInputIndex=&lt;true&gt; input=&lt;path|comma_separated_paths|path_pattern&gt; ) ) [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]</code></p>
                        </li>
                        <li>
                           <p>NoSQL input data set: <code class="codeph">kvStore=&lt;kv store name&gt; kvStoreHosts=&lt;comma separated list of hosts&gt; kvParentKey=&lt;parent key&gt; [kvConsistency=&lt;Absolute|NoneRequired|NoneRequiredNoMaster&gt;] [kvBatchSize=&lt;integer value&gt;] [kvDepth=&lt;CHILDREN_ONLY|DESCENDANTS_ONLY|PARENT_AND_CHILDREN|PARENT_AND_DESCENDANTS&gt;] [kvFormatterClass=&lt;fully qualified class name&gt;] [kvSecurity=&lt;properties file path&gt;] [kvTimeOut=&lt;long value&gt;] [kvDefaultEntryProcessor=&lt;fully qualified class name&gt;] [kvEntryGrouper=&lt;fully qualified class name&gt;] [ kvResultEntries={ { minor key 1: a minor key name relative to the major key [fully qualified class name: a subclass of NoSQLEntryProcessor class used to process the entry with the given key] } * } ]  [srid=&lt;integer_value&gt;] [geodetic=&lt;true|false&gt;] [tolerance=&lt;double_value&gt;] [boundaries=&lt;min_x,min_y,max_x,max_y&gt;]</code></p>
                        </li>
                     </ul>
                     <p>Notes:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>A Categorization job does not support multiple input data sets.</p>
                        </li>
                        <li>
                           <p>A SpatialJoin job only supports two input data sets.</p>
                        </li>
                        <li>
                           <p>A SpatialIndexing job does not accept input data sets of type spatial index.</p>
                        </li>
                        <li>
                           <p>NoSQL input data sets can only be used when kvstore.jar is present in the classpath.</p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4" name="GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4"></a><h4 id="BDSPA-GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4" class="sect4"><span class="enumeration_section">2.12.25 </span>Loading Images from the Local Server to the HDFS Hadoop Cluster
                  </h4>
                  <div>
                     <ol>
                        <li class="stepexpand"><span>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045</code>.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Raster</span> tab.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Select File or Path</span> and browse to the demo folder that contains a set of Hawaii images (<code class="codeph">/opt/shareddir/spatial/data/rasters</code>).</span></li>
                        <li class="stepexpand"><span>By default, Spark is selected. If you want to use Hadoop, click the <span class="bold">Use Spar</span>k button to change it to <span class="bold">Use Hadoop</span>.</span></li>
                        <li class="stepexpand"><span>Select the <code class="codeph">rasters</code> folder and click <span class="bold">Load images</span>.</span><div>
                              <p>You will receive a message about the job being accepted, with a tracking URL. You can track the job status using that URL.</p>
                              <p>After the job finishes, you can see the uploaded images in the globe in the Viewer tab.</p>
                           </div>
                        </li>
                     </ol>
                     <div class="section">
                        <div class="infoboxnote" id="GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4__GUID-D49EE463-80B9-4708-A20D-D306FCB1DBEC">
                           <p class="notep1">Note:</p>
                           <p>If you cannot find the raster files, you can copy them to the shared directory folder created during the installation: check the Admin tab for the directory location, then copy the raster files into it.</p>
                           <p>If you receive an error, check the Raster Configuration details. If GDAL native library is not set-up correctly, much of the raster functionality of the web application will not work.</p>
                        </div>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-95B0C667-3D27-4225-8796-7C8F78CE624F" name="GUID-95B0C667-3D27-4225-8796-7C8F78CE624F"></a><h4 id="BDSPA-GUID-95B0C667-3D27-4225-8796-7C8F78CE624F" class="sect4"><span class="enumeration_section">2.12.26 </span>Visualizing Rasters in the Globe
                  </h4>
                  <div>
                     <div class="p">
                        <p>Before you can visualize the rasters in the globe, you must upload the raster files to HDFS, as explained in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4">Loading Images from the Local Server to the HDFS Hadoop Cluster</a>.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045</code>.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Raster</span> tab.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Hadoop Viewer</span> tab.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Refresh Footprints</span> to update the footprints in the globe, and wait until all footprints are displayed on the globe. </span><div>
                              <p>Identical rasters are displayed with a yellow edge</p>
                           </div>
                        </li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-BDBA610E-0C5D-4A20-924A-629CE8ACF48F" name="GUID-BDBA610E-0C5D-4A20-924A-629CE8ACF48F"></a><h4 id="BDSPA-GUID-BDBA610E-0C5D-4A20-924A-629CE8ACF48F" class="sect4"><span class="enumeration_section">2.12.27 </span>Processing a Raster or Multiple Rasters with the Same MBR
                  </h4>
                  <div>
                     <div class="p">
                        <p>Before you can visualize the rasters in the globe, you must upload the raster files to HDFS, as explained in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4">Loading Images from the Local Server to the HDFS Hadoop Cluster</a>.
                        </p>
                        <p>Before processing rasters with the same MBR (minimum bounding rectangle), you must upload the raster files to HDFS, as explained in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4">Loading Images from the Local Server to the HDFS Hadoop Cluster</a>, and visualize the rasters, as explained in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-95B0C667-3D27-4225-8796-7C8F78CE624F">Visualizing Rasters in the Globe</a>.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Right click over a raster. If you select a raster with a red or yellow edge, a tooltip with a list of rasters may appear.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Process Rasters with Same MBR</span>. You can exclude rasters from the process by clicking the X button on the left side of every row. If single raster was select, click Process Image (No Mosaic).</span><div>The Raster Process dialog box is displayed.</div>
                        </li>
                        <li class="stepexpand"><span>By default, Spark is selected to process the job. To use Hadoop instead, click <span class="bold">Use Spark</span> to toggle the button to <span class="bold">Use Hadoop</span>.</span></li>
                        <li class="stepexpand"><span>In the Raster Process dialog, scroll down and click <span class="bold">Create Mosaic</span>.</span><div>Wait until the raster processing is finished. The result will displayed in the Result tab.</div>
                        </li>
                        <li class="stepexpand"><span>Optionally, download the result by clicking <span class="bold">Download Full Size Image</span> below the result image.</span></li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-4BB63E8A-80DE-4D3F-A04F-8C0F4D56B419" name="GUID-4BB63E8A-80DE-4D3F-A04F-8C0F4D56B419"></a><h4 id="BDSPA-GUID-4BB63E8A-80DE-4D3F-A04F-8C0F4D56B419" class="sect4"><span class="enumeration_section">2.12.28 </span>Creating a Mosaic Directly from the Globe
                  </h4>
                  <div>
                     <div class="p">
                        <p>Before you can create the mosaic image, you must upload the raster files to HDFS, as explained in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4">Loading Images from the Local Server to the HDFS Hadoop Cluster</a>.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045</code>.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Raster</span> tab.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Hadoop Viewer</span> tab.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Refresh Footprints</span> to update the footprints in the globe, and wait until all footprints are displayed on the globe. </span><div>
                              <p>Identical rasters are displayed with a yellow edge</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Click <span class="bold">Select and crop coordinates of Footprints</span>.</span></li>
                        <li class="stepexpand"><span>Draw a rectangle that wraps the rasters (at least one) and desired area, zooming in or out as necessary.</span></li>
                        <li class="stepexpand"><span>Right-click on the map and select <span class="bold">Generate Mosaic</span>.</span><div>The raster process dialog is displayed. </div>
                        </li>
                        <li class="stepexpand"><span>By default, Spark is select to process the job. To use Hadoop instead, click <span class="bold">Use Spark</span> to toggle the button to <span class="bold">Use Hadoop</span>.</span></li>
                        <li class="stepexpand"><span>In the raster process dialog, scroll down and click <span class="bold">Create Mosaic</span>.</span><div>
                              <p>Wait until the raster processing is finished. The result will displayed in the Result tab.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Optionally, download the result by clicking <span class="bold">Download Full Size Image</span>.</span></li>
                     </ol>
                     <div class="section">
                        <div class="infoboxnote" id="GUID-4BB63E8A-80DE-4D3F-A04F-8C0F4D56B419__GUID-0DFF1E1A-490B-4C16-8CBC-15FBA93B1FE3">
                           <p class="notep1">Note:</p>
                           <p>Spark raster processing does not yet support all the options provided for Hadoop raster processing. For Spark raster processing, you must specify additional configuration parameters in the Spark Configuration section of the Admin tab:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><code class="codeph">spark.driver.extraClassPath, spark.executor.extraClassPath</code>: Specify your hive library installation using these keys. Example:<code class="codeph"> /usr/lib/hive/lib/*</code></p>
                              </li>
                              <li>
                                 <p><code class="codeph">spark.kryoserializer.buffer.max</code>: Enter a value to support the kryo serialization. Example: <code class="codeph">160m</code></p>
                              </li>
                           </ul>
                        </div>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-9E4A4947-C9F7-435F-B318-1CBC00B12BE0" name="GUID-9E4A4947-C9F7-435F-B318-1CBC00B12BE0"></a><h4 id="BDSPA-GUID-9E4A4947-C9F7-435F-B318-1CBC00B12BE0" class="sect4"><span class="enumeration_section">2.12.29 </span>Adding Operations for Raster Processing
                  </h4>
                  <div>
                     <div class="p">
                        <p>Before you add algebra operations for raster processing or image mosaic creation, follow the instructions in  <a href="using-big-data-spatial-graph-spatial-data.html#GUID-BDBA610E-0C5D-4A20-924A-629CE8ACF48F">Processing a Raster or Multiple Rasters with the Same MBR</a> until you have the raster processing dialog displayed. Before clicking Create Mosaic, perform these steps:
                        </p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Click <span class="bold">Advanced options</span>.</span><div>
                              <p>A group of new elements is displayed for adding add the advanced options.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Scroll down until you see the raster operations.</span></li>
                        <li class="stepexpand"><span>Choose a raster operation from the list. If you want to add a complex operation, toggle the <span class="bold">Hide Complex Operations</span> checkbox.</span><div>
                              <p>Only one complex operation is allowed per raster processing action.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>After you select an operation from the list on the left, add it to the process by clicking the right arrow. </span><div>
                              <p>Some operations also require parameters.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Add more operations if you want.</span><div>
                              <p>To remove an operation, select it in the list on the right and click the left arrow. You can also remove all operations in the list.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>By default, Spark is selected to process the job. To use Hadoop instead, click <span class="bold">Use Spark</span> to toggle the button to <span class="bold">Use Hadoop</span>.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Create Mosaic</span>.</span><div>
                              <p>Wait until the raster processing is finished. The result will displayed in the Result tab.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Optionally, download the result by clicking <span class="bold">Download Full Size Image</span>.</span></li>
                     </ol>
                     <div class="section">
                        <div class="infoboxnote" id="GUID-9E4A4947-C9F7-435F-B318-1CBC00B12BE0__SPARKRASTERPROCESSINGDOESNOTYETSUPP-74887170">
                           <p class="notep1">Note:</p>
                           <p>For some raster process operations using spark, you need to supply memory details to the spark drivers and executors, with the details depending of the size and details of the rasters in the process. For Spark raster processing, you must specify additional configuration parameters in the Spark Configuration section of the Admin tab:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><code class="codeph">spark.driver.extraClassPath, spark.executor.extraClassPath</code>: Specify your hive library installation using these keys. Example:<code class="codeph"> /usr/lib/hive/lib/*</code></p>
                              </li>
                              <li>
                                 <p><code class="codeph">spark.kryoserializer.buffer.max</code>: Enter a value to support the kryo serialization. Example: <code class="codeph">160m</code></p>
                              </li>
                           </ul>
                        </div>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-B0FE7112-6744-40E0-892A-C90D823E75C9" name="GUID-B0FE7112-6744-40E0-892A-C90D823E75C9"></a><h4 id="BDSPA-GUID-B0FE7112-6744-40E0-892A-C90D823E75C9" class="sect4"><span class="enumeration_section">2.12.30 </span>Creating a Slope Image from the Globe
                  </h4>
                  <div>
                     <div class="p">
                        <p>Before you can create the mosaic image, you must upload the raster files to HDFS, as explained in <a href="using-big-data-spatial-graph-spatial-data.html#GUID-79375E95-7528-4353-9B0D-2C60DD45C8A4">Loading Images from the Local Server to the HDFS Hadoop Cluster</a>.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Open the console: <code class="codeph">http://&lt;oracle_big_data_spatial_vector_console&gt;:8045</code>.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Raster</span> tab.</span></li>
                        <li class="stepexpand"><span>Click the <span class="bold">Hadoop Viewer</span> tab.</span></li>
                        <li class="stepexpand"><span>Click <span class="bold">Refresh Footprints</span> to update the footprints in the globe, and wait until all footprints are displayed on the globe. </span><div>
                              <p>Identical rasters are displayed with a yellow edge</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Click <span class="bold">Select and crop coordinates of Footprints</span>.</span></li>
                        <li class="stepexpand"><span>Draw a rectangle that wraps the rasters (at least one) and desired area, zooming in or out as necessary.</span></li>
                        <li class="stepexpand"><span>Right-click on the map and select <span class="bold">Generate Mosaic</span>.</span><div>The raster process dialog is displayed. </div>
                        </li>
                        <li class="stepexpand"><span>By default, Spark is select to process the job. To use Hadoop instead, click <span class="bold">Use Spark</span> to toggle the button to <span class="bold">Use Hadoop</span>.</span></li>
                        <li class="stepexpand"><span>Select the appropriate <span class="bold">Pixel Type</span></span><div>Usually these images are Float 32 Bits.</div>
                        </li>
                        <li class="stepexpand"><span>Click <span class="bold">Advanced Options</span>.</span><div>You will see a group of new elements to add as advanced options.</div>
                        </li>
                        <li class="stepexpand"><span>Scroll down until you see the Process Classes controls.</span></li>
                        <li class="stepexpand"><span>Specify the <span class="bold">Fully Qualified Class Name</span>, then click <span class="bold">Add</span>.</span><div>The framework provides a default process class for slope: <code class="codeph">oracle.spatial.hadoop.imageprocessor.process.ImageSlope</code></div>
                        </li>
                        <li class="stepexpand"><span>Click <span class="bold">Create Mosaic</span></span><div>Wait until the raster processing is finished.</div>
                           <div>The result will displayed in the Result tab.</div>
                        </li>
                     </ol>
                     <div class="section">
                        <div class="infoboxnote" id="GUID-B0FE7112-6744-40E0-892A-C90D823E75C9__GUID-30904BFE-6984-4D0E-9EBF-E5A1D5337485">
                           <p class="notep1">Note:</p>
                           <p>Spark raster processing does not yet support custom process classes.</p>
                        </div>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="props_rev_3"><a id="GUID-46977902-9C1D-42CE-B7C9-A69A2258491F" name="GUID-46977902-9C1D-42CE-B7C9-A69A2258491F"></a><h4 id="BDSPA-GUID-46977902-9C1D-42CE-B7C9-A69A2258491F" class="sect4"><span class="enumeration_section">2.12.31 </span>Changing the Image File Format from the Globe
                  </h4>
                  <div>
                     <div class="p">
                        <p>Before you can change the image file format, follow the instructions in  <a href="using-big-data-spatial-graph-spatial-data.html#GUID-BDBA610E-0C5D-4A20-924A-629CE8ACF48F">Processing a Raster or Multiple Rasters with the Same MBR</a> until you have the raster processing dialog displayed. Before clicking Create Mosaic, perform these steps:
                        </p>
                     </div>
                     <!-- class="section" -->
                     <ol>
                        <li class="stepexpand"><span>Select the the desired image <span class="bold">Output Format</span>.</span></li>
                        <li class="stepexpand"><span>By default, Spark is select to process the job. To use Hadoop instead, click <span class="bold">Use Spark</span> to toggle the button to <span class="bold">Use Hadoop</span>.</span></li>
                        <li class="stepexpand"><span>Scroll down and click <span class="bold">Create Mosaic</span>.</span><div>
                              <p>Wait until the raster processing is finished. The result will displayed in the Result tab.</p>
                           </div>
                        </li>
                        <li class="stepexpand"><span>Optionally, download the result by clicking <span class="bold">Download Full Size Image</span>.</span></li>
                     </ol>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="using-big-data-spatial-graph-spatial-data.html#GUID-05782BDF-6EBE-44A7-A5DB-A0713C19F7E6" title="You can use the Oracle Big Data SpatialViewer Web Application (SpatialViewer) to perform a variety of tasks.">Using the Oracle Big Data SpatialViewer Web Application</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div>
         </div>
      </article>
   </body>
</html>